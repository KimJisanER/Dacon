{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPahbpGm3nKSjshNqhxzcaA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KimJisanER/Dacon/blob/main/Dacon_Metabolism_0911.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLibrHSkqUsI",
        "outputId": "70bed7e5-aebb-4345-9e00-b936ee0d63df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m‚ú®üç∞‚ú® Everything looks OK!\n",
            "‚ú®üç∞‚ú® Everything looks OK!\n",
            "\n",
            "                  __    __    __    __\n",
            "                 /  \\  /  \\  /  \\  /  \\\n",
            "                /    \\/    \\/    \\/    \\\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà/  /‚ñà‚ñà/  /‚ñà‚ñà/  /‚ñà‚ñà/  /‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "              /  / \\   / \\   / \\   / \\  \\____\n",
            "             /  /   \\_/   \\_/   \\_/   \\    o \\__,\n",
            "            / _/                       \\_____/  `\n",
            "            |/\n",
            "        ‚ñà‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó\n",
            "        ‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó\n",
            "        ‚ñà‚ñà‚ïî‚ñà‚ñà‚ñà‚ñà‚ïî‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ñà‚ñà‚ñà‚ñà‚ïî‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë\n",
            "        ‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïë\n",
            "        ‚ñà‚ñà‚ïë ‚ïö‚ïê‚ïù ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë ‚ïö‚ïê‚ïù ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë\n",
            "        ‚ïö‚ïê‚ïù     ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù     ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù\n",
            "\n",
            "        mamba (1.4.1) supported by @QuantStack\n",
            "\n",
            "        GitHub:  https://github.com/mamba-org/mamba\n",
            "        Twitter: https://twitter.com/QuantStack\n",
            "\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "\n",
            "\n",
            "Looking for: ['rdkit']\n",
            "\n",
            "\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.1s\n",
            "conda-forge/linux-64  ‚£æ  \n",
            "conda-forge/noarch    ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.2s\n",
            "conda-forge/linux-64  ‚£æ  \n",
            "conda-forge/noarch    ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.3s\n",
            "conda-forge/linux-64  ‚£æ  \n",
            "conda-forge/noarch    ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.4s\n",
            "conda-forge/linux-64  ‚£æ  \n",
            "conda-forge/noarch    ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.5s\n",
            "conda-forge/linux-64  ‚£æ  \n",
            "conda-forge/noarch    ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.6s\n",
            "conda-forge/linux-64  ‚£æ  \n",
            "conda-forge/noarch    ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.7s\n",
            "conda-forge/linux-64  ‚£æ  \n",
            "conda-forge/noarch    ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.8s\n",
            "conda-forge/linux-64  ‚£æ  \n",
            "conda-forge/noarch    ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.9s\n",
            "conda-forge/linux-64  ‚£æ  \n",
            "conda-forge/noarch    ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.0s\n",
            "conda-forge/linux-64  ‚£æ  \n",
            "conda-forge/noarch    ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.1s\n",
            "conda-forge/linux-64  ‚£æ  \n",
            "conda-forge/noarch    ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.2s\n",
            "conda-forge/linux-64  ‚£æ  \n",
            "conda-forge/noarch    ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.3s\n",
            "conda-forge/linux-64  ‚£æ  \n",
            "conda-forge/noarch    ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.4s\n",
            "conda-forge/linux-64  ‚£æ  \n",
            "conda-forge/noarch    ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.5s\n",
            "conda-forge/linux-64  ‚£æ  \n",
            "conda-forge/noarch    ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.6s\n",
            "conda-forge/linux-64  ‚£æ  \n",
            "conda-forge/noarch    ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.7s\n",
            "conda-forge/linux-64  ‚£æ  \n",
            "conda-forge/noarch    ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.8s\n",
            "conda-forge/linux-64  ‚£æ  \n",
            "conda-forge/noarch    ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.9s\n",
            "conda-forge/linux-64  ‚£æ  \n",
            "conda-forge/noarch    ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.0s\n",
            "conda-forge/linux-64  ‚£æ  \n",
            "conda-forge/noarch    ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.1s\n",
            "conda-forge/linux-64  ‚£æ  \n",
            "conda-forge/noarch    ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.2s\n",
            "conda-forge/linux-64  ‚£æ  \n",
            "conda-forge/noarch    ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.3s\n",
            "conda-forge/linux-64  ‚£æ  \n",
            "conda-forge/noarch    ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.4s\n",
            "conda-forge/linux-64  ‚£æ  \n",
            "conda-forge/noarch    ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.5s\n",
            "conda-forge/linux-64  ‚£æ  \n",
            "conda-forge/noarch    ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.6s\n",
            "conda-forge/linux-64  ‚£æ  \n",
            "conda-forge/noarch    ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.7s\n",
            "conda-forge/linux-64  ‚£æ  \n",
            "conda-forge/noarch    ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.8s\n",
            "conda-forge/linux-64  ‚£æ  \n",
            "conda-forge/noarch    ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.9s\n",
            "conda-forge/linux-64  ‚£æ  \n",
            "conda-forge/noarch    ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.0s\n",
            "conda-forge/linux-64  ‚£æ  \n",
            "conda-forge/noarch    ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.1s\n",
            "conda-forge/linux-64  ‚£æ  \n",
            "conda-forge/noarch    ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.2s\n",
            "conda-forge/linux-64  ‚£æ  \n",
            "conda-forge/noarch    ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.3s\n",
            "conda-forge/linux-64  ‚£æ  \n",
            "conda-forge/noarch    ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.4s\n",
            "conda-forge/linux-64  ‚£æ  \n",
            "conda-forge/noarch    ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.5s\n",
            "conda-forge/linux-64  ‚£æ  \n",
            "conda-forge/noarch    ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.6s\n",
            "conda-forge/linux-64  ‚£æ  \n",
            "conda-forge/noarch   100%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.7s\n",
            "conda-forge/linux-64  ‚£æ  \n",
            "conda-forge/noarch   100%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.8s\n",
            "conda-forge/linux-64  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.9s\n",
            "conda-forge/linux-64  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.0s\n",
            "conda-forge/linux-64  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.1s\n",
            "conda-forge/linux-64  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.2s\n",
            "conda-forge/linux-64  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0Gconda-forge/noarch                                \n",
            "[+] 4.3s\n",
            "conda-forge/linux-64  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.4s\n",
            "conda-forge/linux-64  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.5s\n",
            "conda-forge/linux-64  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.6s\n",
            "conda-forge/linux-64  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.7s\n",
            "conda-forge/linux-64  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.8s\n",
            "conda-forge/linux-64  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.9s\n",
            "conda-forge/linux-64  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.0s\n",
            "conda-forge/linux-64  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.1s\n",
            "conda-forge/linux-64  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.2s\n",
            "conda-forge/linux-64  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.3s\n",
            "conda-forge/linux-64  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.4s\n",
            "conda-forge/linux-64  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.5s\n",
            "conda-forge/linux-64  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.6s\n",
            "conda-forge/linux-64  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.7s\n",
            "conda-forge/linux-64  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.8s\n",
            "conda-forge/linux-64  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.9s\n",
            "conda-forge/linux-64  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.0s\n",
            "conda-forge/linux-64  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.1s\n",
            "conda-forge/linux-64  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.2s\n",
            "conda-forge/linux-64  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.3s\n",
            "conda-forge/linux-64  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.4s\n",
            "conda-forge/linux-64  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.5s\n",
            "conda-forge/linux-64  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.6s\n",
            "conda-forge/linux-64  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.7s\n",
            "conda-forge/linux-64  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.8s\n",
            "conda-forge/linux-64  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.9s\n",
            "conda-forge/linux-64  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.0s\n",
            "conda-forge/linux-64  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.1s\n",
            "conda-forge/linux-64  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.2s\n",
            "conda-forge/linux-64  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.3s\n",
            "conda-forge/linux-64  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.4s\n",
            "conda-forge/linux-64  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.5s\n",
            "conda-forge/linux-64  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.6s\n",
            "conda-forge/linux-64  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.7s\n",
            "conda-forge/linux-64  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.8s\n",
            "conda-forge/linux-64  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.9s\n",
            "conda-forge/linux-64  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.0s\n",
            "conda-forge/linux-64  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.1s\n",
            "conda-forge/linux-64  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.2s\n",
            "conda-forge/linux-64  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.3s\n",
            "conda-forge/linux-64  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.4s\n",
            "conda-forge/linux-64  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.5s\n",
            "conda-forge/linux-64 100%\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.6s\n",
            "conda-forge/linux-64 100%\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.7s\n",
            "conda-forge/linux-64 100%\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.8s\n",
            "conda-forge/linux-64 100%\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.9s\n",
            "conda-forge/linux-64 100%\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.0s\n",
            "conda-forge/linux-64 100%\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.1s\n",
            "conda-forge/linux-64 100%\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.2s\n",
            "conda-forge/linux-64 100%\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.3s\n",
            "conda-forge/linux-64 100%\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.4s\n",
            "conda-forge/linux-64 100%\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.5s\n",
            "conda-forge/linux-64 100%\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.6s\n",
            "conda-forge/linux-64 100%\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.7s\n",
            "conda-forge/linux-64 100%\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.8s\n",
            "conda-forge/linux-64 100%\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.9s\n",
            "conda-forge/linux-64 100%\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.0s\n",
            "conda-forge/linux-64 100%\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.1s\n",
            "conda-forge/linux-64 100%\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.2s\n",
            "conda-forge/linux-64 100%\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.3s\n",
            "conda-forge/linux-64 100%\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.4s\n",
            "conda-forge/linux-64 100%\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.5s\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[0Gconda-forge/linux-64                              \n",
            "\u001b[?25h\n",
            "Pinned packages:\n",
            "  - python 3.10.*\n",
            "  - python 3.10.*\n",
            "  - python_abi 3.10.* *cp310*\n",
            "  - cudatoolkit 11.8.*\n",
            "\n",
            "\n",
            "Transaction\n",
            "\n",
            "  Prefix: /usr/local\n",
            "\n",
            "  Updating specs:\n",
            "\n",
            "   - rdkit\n",
            "   - ca-certificates\n",
            "   - certifi\n",
            "   - openssl\n",
            "\n",
            "\n",
            "  Package                           Version  Build                Channel                   Size\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "  Install:\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "\n",
            "  \u001b[32m+ boost                    \u001b[0m        1.78.0  py310hc4a4660_4      conda-forge/linux-64     363kB\n",
            "  \u001b[32m+ boost-cpp                \u001b[0m        1.78.0  h6582d0a_3           conda-forge/linux-64      16MB\n",
            "  \u001b[32m+ brotli                   \u001b[0m         1.1.0  hd590300_0           conda-forge/linux-64      19kB\n",
            "  \u001b[32m+ brotli-bin               \u001b[0m         1.1.0  hd590300_0           conda-forge/linux-64      19kB\n",
            "  \u001b[32m+ cairo                    \u001b[0m        1.16.0  hbbf8b49_1016        conda-forge/linux-64       1MB\n",
            "  \u001b[32m+ contourpy                \u001b[0m         1.1.0  py310hd41b1e2_0      conda-forge/linux-64     221kB\n",
            "  \u001b[32m+ cycler                   \u001b[0m        0.11.0  pyhd8ed1ab_0         conda-forge/noarch        10kB\n",
            "  \u001b[32m+ expat                    \u001b[0m         2.5.0  hcb278e6_1           conda-forge/linux-64     137kB\n",
            "  \u001b[32m+ font-ttf-dejavu-sans-mono\u001b[0m          2.37  hab24e00_0           conda-forge/noarch       397kB\n",
            "  \u001b[32m+ font-ttf-inconsolata     \u001b[0m         3.000  h77eed37_0           conda-forge/noarch        97kB\n",
            "  \u001b[32m+ font-ttf-source-code-pro \u001b[0m         2.038  h77eed37_0           conda-forge/noarch       701kB\n",
            "  \u001b[32m+ font-ttf-ubuntu          \u001b[0m          0.83  hab24e00_0           conda-forge/noarch         2MB\n",
            "  \u001b[32m+ fontconfig               \u001b[0m        2.14.2  h14ed4e7_0           conda-forge/linux-64     272kB\n",
            "  \u001b[32m+ fonts-conda-ecosystem    \u001b[0m             1  0                    conda-forge/noarch         4kB\n",
            "  \u001b[32m+ fonts-conda-forge        \u001b[0m             1  0                    conda-forge/noarch         4kB\n",
            "  \u001b[32m+ fonttools                \u001b[0m        4.42.1  py310h2372a71_0      conda-forge/linux-64       2MB\n",
            "  \u001b[32m+ freetype                 \u001b[0m        2.12.1  hca18f0e_1           conda-forge/linux-64     626kB\n",
            "  \u001b[32m+ freetype-py              \u001b[0m         2.3.0  pyhd8ed1ab_0         conda-forge/noarch        59kB\n",
            "  \u001b[32m+ gettext                  \u001b[0m        0.21.1  h27087fc_0           conda-forge/linux-64       4MB\n",
            "  \u001b[32m+ greenlet                 \u001b[0m         2.0.2  py310hc6cd4ac_1      conda-forge/linux-64     191kB\n",
            "  \u001b[32m+ kiwisolver               \u001b[0m         1.4.5  py310hd41b1e2_0      conda-forge/linux-64      73kB\n",
            "  \u001b[32m+ lcms2                    \u001b[0m          2.15  haa2dc70_1           conda-forge/linux-64     242kB\n",
            "  \u001b[32m+ lerc                     \u001b[0m         4.0.0  h27087fc_0           conda-forge/linux-64     282kB\n",
            "  \u001b[32m+ libblas                  \u001b[0m         3.9.0  18_linux64_openblas  conda-forge/linux-64      15kB\n",
            "  \u001b[32m+ libbrotlicommon          \u001b[0m         1.1.0  hd590300_0           conda-forge/linux-64      69kB\n",
            "  \u001b[32m+ libbrotlidec             \u001b[0m         1.1.0  hd590300_0           conda-forge/linux-64      33kB\n",
            "  \u001b[32m+ libbrotlienc             \u001b[0m         1.1.0  hd590300_0           conda-forge/linux-64     282kB\n",
            "  \u001b[32m+ libcblas                 \u001b[0m         3.9.0  18_linux64_openblas  conda-forge/linux-64      14kB\n",
            "  \u001b[32m+ libdeflate               \u001b[0m          1.18  h0b41bf4_0           conda-forge/linux-64      65kB\n",
            "  \u001b[32m+ libexpat                 \u001b[0m         2.5.0  hcb278e6_1           conda-forge/linux-64      78kB\n",
            "  \u001b[32m+ libgfortran-ng           \u001b[0m        13.2.0  h69a702a_0           conda-forge/linux-64      23kB\n",
            "  \u001b[32m+ libgfortran5             \u001b[0m        13.2.0  ha4646dd_0           conda-forge/linux-64       1MB\n",
            "  \u001b[32m+ libglib                  \u001b[0m        2.78.0  hebfc3b9_0           conda-forge/linux-64       3MB\n",
            "  \u001b[32m+ libjpeg-turbo            \u001b[0m       2.1.5.1  h0b41bf4_0           conda-forge/linux-64     491kB\n",
            "  \u001b[32m+ liblapack                \u001b[0m         3.9.0  18_linux64_openblas  conda-forge/linux-64      14kB\n",
            "  \u001b[32m+ libopenblas              \u001b[0m        0.3.24  pthreads_h413a1c8_0  conda-forge/linux-64       5MB\n",
            "  \u001b[32m+ libpng                   \u001b[0m        1.6.39  h753d276_0           conda-forge/linux-64     283kB\n",
            "  \u001b[32m+ libtiff                  \u001b[0m         4.5.1  h8b53f26_1           conda-forge/linux-64     417kB\n",
            "  \u001b[32m+ libwebp-base             \u001b[0m         1.3.1  hd590300_0           conda-forge/linux-64     400kB\n",
            "  \u001b[32m+ libxcb                   \u001b[0m          1.15  h0b41bf4_0           conda-forge/linux-64     384kB\n",
            "  \u001b[32m+ matplotlib-base          \u001b[0m         3.7.2  py310hf38f957_0      conda-forge/linux-64       7MB\n",
            "  \u001b[32m+ munkres                  \u001b[0m         1.1.4  pyh9f0ad1d_0         conda-forge/noarch        12kB\n",
            "  \u001b[32m+ numpy                    \u001b[0m        1.25.2  py310ha4c1d20_0      conda-forge/linux-64       7MB\n",
            "  \u001b[32m+ openjpeg                 \u001b[0m         2.5.0  hfec8fc6_2           conda-forge/linux-64     352kB\n",
            "  \u001b[32m+ packaging                \u001b[0m          23.1  pyhd8ed1ab_0         conda-forge/noarch        46kB\n",
            "  \u001b[32m+ pandas                   \u001b[0m         2.1.0  py310hcc13569_0      conda-forge/linux-64      13MB\n",
            "  \u001b[32m+ pcre2                    \u001b[0m         10.40  hc3806b6_0           conda-forge/linux-64       2MB\n",
            "  \u001b[32m+ pillow                   \u001b[0m        10.0.0  py310h582fbeb_0      conda-forge/linux-64      47MB\n",
            "  \u001b[32m+ pixman                   \u001b[0m        0.40.0  h36c2ea0_0           conda-forge/linux-64     643kB\n",
            "  \u001b[32m+ pthread-stubs            \u001b[0m           0.4  h36c2ea0_1001        conda-forge/linux-64       6kB\n",
            "  \u001b[32m+ pycairo                  \u001b[0m        1.24.0  py310hda9f760_0      conda-forge/linux-64     113kB\n",
            "  \u001b[32m+ pyparsing                \u001b[0m         3.0.9  pyhd8ed1ab_0         conda-forge/noarch        81kB\n",
            "  \u001b[32m+ python-dateutil          \u001b[0m         2.8.2  pyhd8ed1ab_0         conda-forge/noarch       246kB\n",
            "  \u001b[32m+ python-tzdata            \u001b[0m        2023.3  pyhd8ed1ab_0         conda-forge/noarch       143kB\n",
            "  \u001b[32m+ pytz                     \u001b[0m  2023.3.post1  pyhd8ed1ab_0         conda-forge/noarch       187kB\n",
            "  \u001b[32m+ rdkit                    \u001b[0m     2023.03.3  py310h399bcf7_0      conda-forge/linux-64      36MB\n",
            "  \u001b[32m+ reportlab                \u001b[0m         4.0.4  py310h2372a71_0      conda-forge/linux-64       2MB\n",
            "  \u001b[32m+ rlpycairo                \u001b[0m         0.2.0  pyhd8ed1ab_0         conda-forge/noarch        15kB\n",
            "  \u001b[32m+ six                      \u001b[0m        1.16.0  pyh6c4a22f_0         conda-forge/noarch        14kB\n",
            "  \u001b[32m+ sqlalchemy               \u001b[0m        2.0.20  py310h2372a71_0      conda-forge/linux-64       3MB\n",
            "  \u001b[32m+ typing-extensions        \u001b[0m         4.7.1  hd8ed1ab_0           conda-forge/noarch        10kB\n",
            "  \u001b[32m+ typing_extensions        \u001b[0m         4.7.1  pyha770c72_0         conda-forge/noarch        36kB\n",
            "  \u001b[32m+ unicodedata2             \u001b[0m        15.0.0  py310h5764c6d_0      conda-forge/linux-64     512kB\n",
            "  \u001b[32m+ xorg-kbproto             \u001b[0m         1.0.7  h7f98852_1002        conda-forge/linux-64      27kB\n",
            "  \u001b[32m+ xorg-libice              \u001b[0m         1.1.1  hd590300_0           conda-forge/linux-64      58kB\n",
            "  \u001b[32m+ xorg-libsm               \u001b[0m         1.2.4  h7391055_0           conda-forge/linux-64      27kB\n",
            "  \u001b[32m+ xorg-libx11              \u001b[0m         1.8.6  h8ee46fc_0           conda-forge/linux-64     829kB\n",
            "  \u001b[32m+ xorg-libxau              \u001b[0m        1.0.11  hd590300_0           conda-forge/linux-64      14kB\n",
            "  \u001b[32m+ xorg-libxdmcp            \u001b[0m         1.1.3  h7f98852_0           conda-forge/linux-64      19kB\n",
            "  \u001b[32m+ xorg-libxext             \u001b[0m         1.3.4  h0b41bf4_2           conda-forge/linux-64      50kB\n",
            "  \u001b[32m+ xorg-libxrender          \u001b[0m        0.9.11  hd590300_0           conda-forge/linux-64      38kB\n",
            "  \u001b[32m+ xorg-renderproto         \u001b[0m        0.11.1  h7f98852_1002        conda-forge/linux-64      10kB\n",
            "  \u001b[32m+ xorg-xextproto           \u001b[0m         7.3.0  h0b41bf4_1003        conda-forge/linux-64      30kB\n",
            "  \u001b[32m+ xorg-xproto              \u001b[0m        7.0.31  h7f98852_1007        conda-forge/linux-64      75kB\n",
            "  \u001b[32m+ zlib                     \u001b[0m        1.2.13  h166bdaf_4           conda-forge/linux-64      94kB\n",
            "\n",
            "  Upgrade:\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "\n",
            "  \u001b[31m- ca-certificates          \u001b[0m     2022.12.7  ha878542_0           conda-forge                   \n",
            "  \u001b[32m+ ca-certificates          \u001b[0m     2023.7.22  hbcca054_0           conda-forge/linux-64     150kB\n",
            "  \u001b[31m- certifi                  \u001b[0m     2022.12.7  pyhd8ed1ab_0         conda-forge                   \n",
            "  \u001b[32m+ certifi                  \u001b[0m     2023.7.22  pyhd8ed1ab_0         conda-forge/noarch       154kB\n",
            "  \u001b[31m- openssl                  \u001b[0m         3.1.0  h0b41bf4_0           conda-forge                   \n",
            "  \u001b[32m+ openssl                  \u001b[0m         3.1.2  hd590300_0           conda-forge/linux-64       3MB\n",
            "\n",
            "  Summary:\n",
            "\n",
            "  Install: 75 packages\n",
            "  Upgrade: 3 packages\n",
            "\n",
            "  Total download: 165MB\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "\n",
            "\n",
            "\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
            "Downloading        0%\n",
            "Extracting         0%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gca-certificates                                    149.5kB @   2.6MB/s  0.1s\n",
            "zlib                                                94.1kB @   1.2MB/s  0.1s\n",
            "pixman                                             642.5kB @   7.5MB/s  0.1s\n",
            "xorg-libxau                                         14.5kB @ 167.2kB/s  0.0s\n",
            "[+] 0.1s\n",
            "Downloading  (5)   1%\n",
            "Extracting   (4)  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibpng                                             282.6kB @   2.5MB/s  0.1s\n",
            "xorg-xextproto                                      30.3kB @ 249.8kB/s  0.0s\n",
            "xorg-libice                                         58.5kB @ 417.6kB/s  0.1s\n",
            "unicodedata2                                       512.2kB @   3.4MB/s  0.1s\n",
            "xorg-renderproto                                     9.6kB @  63.7kB/s  0.0s\n",
            "xorg-xproto                                         74.9kB @ 494.8kB/s  0.0s\n",
            "boost-cpp                                           15.9MB @  90.0MB/s  0.2s\n",
            "libtiff                                            416.5kB @   2.4MB/s  0.0s\n",
            "expat                                              136.8kB @ 737.2kB/s  0.0s\n",
            "xorg-libsm                                          27.4kB @ 147.6kB/s  0.0s\n",
            "libbrotlidec                                        32.6kB @ 169.7kB/s  0.0s\n",
            "[+] 0.2s\n",
            "Downloading  (5)  12%\n",
            "Extracting  (13)  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gxorg-libx11                                        828.5kB @   4.0MB/s  0.0s\n",
            "libcblas                                            14.5kB @  66.8kB/s  0.0s\n",
            "liblapack                                           14.5kB @  66.8kB/s  0.0s\n",
            "font-ttf-dejavu-sans-mono                          397.4kB @   1.8MB/s  0.0s\n",
            "pytz                                               187.5kB @ 780.1kB/s  0.0s\n",
            "six                                                 14.3kB @  56.9kB/s  0.0s\n",
            "pyparsing                                           81.3kB @ 316.5kB/s  0.0s\n",
            "freetype-py                                         58.9kB @ 225.2kB/s  0.0s\n",
            "typing-extensions                                   10.1kB @  37.3kB/s  0.0s\n",
            "rlpycairo                                           14.9kB @  51.3kB/s  0.0s\n",
            "[+] 0.3s\n",
            "Downloading  (5)  23%\n",
            "Extracting  (23)  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gcairo                                                1.1MB @   3.5MB/s  0.1s\n",
            "libwebp-base                                       399.9kB @   1.3MB/s  0.1s\n",
            "kiwisolver                                          73.2kB @ 225.7kB/s  0.0s\n",
            "libexpat                                            78.0kB @ 220.3kB/s  0.1s\n",
            "xorg-libxdmcp                                       19.1kB @  54.0kB/s  0.0s\n",
            "[+] 0.4s\n",
            "Downloading  (5)  35%\n",
            "Extracting  (25)  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibgfortran-ng                                      23.3kB @  58.5kB/s  0.1s\n",
            "libbrotlienc                                       282.2kB @ 692.4kB/s  0.1s\n",
            "pandas                                              12.7MB @  30.5MB/s  0.2s\n",
            "gettext                                              4.3MB @  10.3MB/s  0.1s\n",
            "brotli-bin                                          19.0kB @  43.7kB/s  0.0s\n",
            "brotli                                              19.4kB @  41.7kB/s  0.0s\n",
            "xorg-libxrender                                     37.8kB @  81.3kB/s  0.0s\n",
            "python-tzdata                                      143.1kB @ 294.9kB/s  0.0s\n",
            "munkres                                             12.5kB @  25.2kB/s  0.0s\n",
            "[+] 0.5s\n",
            "Downloading  (5)  48%\n",
            "Extracting  (28)  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibopenblas                                          5.5MB @  10.9MB/s  0.1s\n",
            "packaging                                           46.1kB @  88.5kB/s  0.1s\n",
            "fonts-conda-ecosystem                                3.7kB @   7.0kB/s  0.0s\n",
            "pillow                                              46.6MB @  86.8MB/s  0.4s\n",
            "reportlab                                            2.3MB @   4.3MB/s  0.0s\n",
            "libgfortran5                                         1.4MB @   2.5MB/s  0.0s\n",
            "sqlalchemy                                           2.6MB @   4.5MB/s  0.1s\n",
            "libdeflate                                          65.2kB @ 113.9kB/s  0.0s\n",
            "xorg-kbproto                                        27.3kB @  47.5kB/s  0.0s\n",
            "libglib                                              2.7MB @   4.6MB/s  0.0s\n",
            "[+] 0.6s\n",
            "Downloading  (5)  62%\n",
            "Extracting  (35)  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibblas                                             14.5kB @  24.2kB/s  0.0s\n",
            "lcms2                                              242.1kB @ 401.1kB/s  0.0s\n",
            "xorg-libxext                                        50.1kB @  82.2kB/s  0.0s\n",
            "cycler                                              10.3kB @  16.6kB/s  0.0s\n",
            "typing_extensions                                   36.3kB @  58.0kB/s  0.0s\n",
            "pycairo                                            113.5kB @ 180.2kB/s  0.0s\n",
            "libbrotlicommon                                     69.4kB @ 106.1kB/s  0.0s\n",
            "fonttools                                            2.2MB @   3.4MB/s  0.1s\n",
            "pthread-stubs                                        5.6kB @   8.5kB/s  0.0s\n",
            "libxcb                                             384.2kB @ 570.2kB/s  0.1s\n",
            "certifi                                            153.8kB @ 222.3kB/s  0.0s\n",
            "font-ttf-source-code-pro                           700.8kB @   1.0MB/s  0.0s\n",
            "python-dateutil                                    246.0kB @ 354.3kB/s  0.0s\n",
            "[+] 0.7s\n",
            "Downloading  (5)  67%\n",
            "Extracting  (41)  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gnumpy                                                6.9MB @   9.6MB/s  0.1s\n",
            "lerc                                               281.8kB @ 385.4kB/s  0.0s\n",
            "openssl                                              2.6MB @   3.6MB/s  0.0s\n",
            "greenlet                                           190.7kB @ 257.8kB/s  0.0s\n",
            "freetype                                           625.7kB @ 825.2kB/s  0.0s\n",
            "openjpeg                                           352.0kB @ 462.8kB/s  0.0s\n",
            "pcre2                                                2.4MB @   3.1MB/s  0.1s\n",
            "font-ttf-inconsolata                                96.5kB @ 124.5kB/s  0.0s\n",
            "[+] 0.8s\n",
            "Downloading  (5)  73%\n",
            "Extracting  (49)  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibjpeg-turbo                                      490.5kB @ 613.5kB/s  0.0s\n",
            "boost                                              362.6kB @ 441.5kB/s  0.1s\n",
            "fontconfig                                         272.0kB @ 320.4kB/s  0.1s\n",
            "font-ttf-ubuntu                                      2.0MB @   2.3MB/s  0.1s\n",
            "fonts-conda-forge                                    4.1kB @   4.8kB/s  0.1s\n",
            "[+] 0.9s\n",
            "Downloading  (3)  77%\n",
            "Extracting  (51)  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gcontourpy                                          220.9kB @ 247.9kB/s  0.1s\n",
            "matplotlib-base                                      6.7MB @   7.5MB/s  0.2s\n",
            "[+] 1.0s\n",
            "Downloading  (1)  90%\n",
            "Extracting  (51)  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Grdkit                                               36.4MB @  35.0MB/s  0.3s\n",
            "[+] 1.1s\n",
            "Downloading      100%\n",
            "Extracting  (47)  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.2s\n",
            "Downloading      100%\n",
            "Extracting  (43)  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.3s\n",
            "Downloading      100%\n",
            "Extracting  (41)  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.4s\n",
            "Downloading      100%\n",
            "Extracting  (38)  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.5s\n",
            "Downloading      100%\n",
            "Extracting  (36)  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.6s\n",
            "Downloading      100%\n",
            "Extracting  (32)  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.7s\n",
            "Downloading      100%\n",
            "Extracting  (30)  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.8s\n",
            "Downloading      100%\n",
            "Extracting  (27)  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.9s\n",
            "Downloading      100%\n",
            "Extracting  (24)  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.0s\n",
            "Downloading      100%\n",
            "Extracting  (22)  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.1s\n",
            "Downloading      100%\n",
            "Extracting  (18)  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.2s\n",
            "Downloading      100%\n",
            "Extracting  (17)  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.3s\n",
            "Downloading      100%\n",
            "Extracting  (14)  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.4s\n",
            "Downloading      100%\n",
            "Extracting   (9)  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.5s\n",
            "Downloading      100%\n",
            "Extracting   (6)  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.6s\n",
            "Downloading      100%\n",
            "Extracting   (1)  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.7s\n",
            "Downloading      100%\n",
            "Extracting   (1)  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.8s\n",
            "Downloading      100%\n",
            "Extracting       100%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G\u001b[?25h\n",
            "Downloading and Extracting Packages\n",
            "\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Verifying transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Executing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n"
          ]
        }
      ],
      "source": [
        " !pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "\n",
        "import sys\n",
        "sys.path\n",
        "\n",
        "import condacolab\n",
        "condacolab.check()\n",
        "\n",
        "!mamba install -c conda-forge rdkit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxm3E4G_q5-F",
        "outputId": "e21bd7be-4f1f-4782-b6d5-aa4066170faa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mordred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDp7RIdGsB8V",
        "outputId": "08c13458-1aaf-422e-d242-78752e16390a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mordred\n",
            "  Downloading mordred-1.2.0.tar.gz (128 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m128.8/128.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six==1.* in /usr/local/lib/python3.10/site-packages (from mordred) (1.16.0)\n",
            "Requirement already satisfied: numpy==1.* in /usr/local/lib/python3.10/site-packages (from mordred) (1.25.2)\n",
            "Collecting networkx==2.*\n",
            "  Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: mordred\n",
            "  Building wheel for mordred (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mordred: filename=mordred-1.2.0-py3-none-any.whl size=176723 sha256=641bbc2cc11986a7cd6f85fa0631685f27f407a1686ade0c3556f09466b2f1a6\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/4f/b8/d4c6591f6ac944aaced7865b349477695f662388ad958743c7\n",
            "Successfully built mordred\n",
            "Installing collected packages: networkx, mordred\n",
            "Successfully installed mordred-1.2.0 networkx-2.8.8\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import PandasTools\n",
        "from rdkit.Chem import AllChem\n",
        "import rdkit\n",
        "from rdkit.Chem.Draw import IPythonConsole\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from rdkit.Chem import Descriptors\n",
        "from mordred import Calculator, descriptors\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import ChemicalFeatures\n",
        "from rdkit import RDConfig"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9LVzsm7qsFU",
        "outputId": "149363ef-62eb-47b6-9efc-bf7ca1fde413"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Descriptor Ìï®Ïàò Ï†ïÏùò"
      ],
      "metadata": {
        "id": "LaLzbxYKxSrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1\n",
        "def getMolDescriptors(mol, missingVal=None):\n",
        "    res = {}\n",
        "    for nm,fn in Descriptors._descList:\n",
        "        # some of the descriptor fucntions can throw errors if they fail, catch those here:\n",
        "        try:\n",
        "            val = fn(mol)\n",
        "        except:\n",
        "            # print the error message:\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            # and set the descriptor value to whatever missingVal is\n",
        "            val = missingVal\n",
        "        res[nm] = val\n",
        "    return res\n",
        "\n",
        "#2\n",
        "def extract_fragments(smiles, hybridization_type=None, exclude_ring=False):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        return None\n",
        "\n",
        "    fragments = []\n",
        "    for atom in mol.GetAtoms():\n",
        "        hybridization = atom.GetHybridization()\n",
        "        if (hybridization_type is None or hybridization == hybridization_type) and (not exclude_ring or not atom.IsInRing()):\n",
        "            neighbors = atom.GetNeighbors()\n",
        "            fragment = Chem.EditableMol(Chem.Mol())\n",
        "            atom_idx = fragment.AddAtom(atom)\n",
        "            for neighbor in neighbors:\n",
        "                bond = mol.GetBondBetweenAtoms(atom.GetIdx(), neighbor.GetIdx())\n",
        "                if bond:\n",
        "                    bond_order = bond.GetBondType()\n",
        "                    neighbor_idx = fragment.AddAtom(neighbor)\n",
        "                    fragment.AddBond(atom_idx, neighbor_idx, bond_order)\n",
        "            fragments.append(fragment.GetMol())\n",
        "\n",
        "    return fragments\n",
        "\n",
        "def count_fragments(full, column_prefix, hybridization_type=None, exclude_ring=False):\n",
        "    fragment_counts = {}\n",
        "    for index, row in full.iterrows():\n",
        "        smiles = row['SMILES']\n",
        "        fragments = extract_fragments(smiles, hybridization_type, exclude_ring)\n",
        "\n",
        "        fragment_count = {}\n",
        "        for idx, fragment in enumerate(fragments):\n",
        "            fragment_smiles = Chem.MolToSmiles(fragment)\n",
        "            if fragment_smiles in fragment_count:\n",
        "                fragment_count[fragment_smiles] += 1\n",
        "            else:\n",
        "                fragment_count[fragment_smiles] = 1\n",
        "\n",
        "        fragment_counts[index] = fragment_count\n",
        "\n",
        "    result_data = []\n",
        "    for index, counts in fragment_counts.items():\n",
        "        counts['SMILES'] = full.loc[index, 'SMILES']\n",
        "        result_data.append(counts)\n",
        "\n",
        "    result_df = pd.DataFrame(result_data).fillna(0).drop(columns='SMILES')\n",
        "    result_df.columns = [f'{column_prefix}_{column}' for column in result_df.columns]\n",
        "\n",
        "    return result_df\n",
        "\n",
        "#3\n",
        "def calculate_molecular_properties(full):\n",
        "    def calculate_stereocenters(smiles):\n",
        "        mol = Chem.MolFromSmiles(smiles)\n",
        "        if mol is None:\n",
        "            return None\n",
        "        chiral_centers = Chem.FindMolChiralCenters(mol, includeUnassigned=True)\n",
        "        return len(chiral_centers)\n",
        "\n",
        "    def calculate_aromatic_proportion(smiles):\n",
        "        mol = Chem.MolFromSmiles(smiles)\n",
        "        if mol is None:\n",
        "            return None\n",
        "        aromatic_atoms = [atom for atom in mol.GetAtoms() if atom.GetIsAromatic()]\n",
        "        total_atoms = mol.GetNumAtoms()\n",
        "        if total_atoms == 0:\n",
        "            return None\n",
        "        return len(aromatic_atoms) / total_atoms\n",
        "\n",
        "    def calculate_formal_charge(smiles):\n",
        "        mol = Chem.MolFromSmiles(smiles)\n",
        "        if mol is None:\n",
        "            return None\n",
        "        return Chem.rdmolops.GetFormalCharge(mol)\n",
        "\n",
        "    properties_data = []\n",
        "\n",
        "    for index, row in full.iterrows():\n",
        "        smiles = row['SMILES']\n",
        "        stereocenters = calculate_stereocenters(smiles)\n",
        "        proportion = calculate_aromatic_proportion(smiles)\n",
        "        charge = calculate_formal_charge(smiles)\n",
        "\n",
        "        if stereocenters is not None and proportion is not None and charge is not None:\n",
        "            properties_data.append({\n",
        "                \"stereocenters\": stereocenters,\n",
        "                \"aromatic_proportion\": proportion,\n",
        "                \"formal_charge\": charge\n",
        "            })\n",
        "\n",
        "    properties_df = pd.DataFrame(properties_data)\n",
        "\n",
        "    return properties_df"
      ],
      "metadata": {
        "id": "4L3pk99NsFBG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Îç∞Ïù¥ÌÑ∞ Í∞ÄÍ≥µ"
      ],
      "metadata": {
        "id": "IF_UDga7xZWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"/content/drive/MyDrive/metabolism_dacon/train.csv\")\n",
        "train[\"AlogP\"] = np.where(pd.isna(train[\"AlogP\"]), train[\"LogD\"], train[\"AlogP\"])\n",
        "\n",
        "#ChEMBL data\n",
        "MLM = pd.read_csv(\"/content/drive/MyDrive/metabolism_dacon/train_aug_MLM_0906.csv\")\n",
        "HLM = pd.read_csv(\"/content/drive/MyDrive/metabolism_dacon/train_aug_HLM_0906.csv\")\n",
        "\n",
        "test = pd.read_csv(\"/content/drive/MyDrive/metabolism_dacon/test.csv\")\n",
        "test[\"AlogP\"] = np.where(pd.isna(test[\"AlogP\"]), test[\"LogD\"], test[\"AlogP\"])\n",
        "\n",
        "full = pd.concat([train, test, MLM, HLM], axis = 0).reset_index(drop=True)\n",
        "full['Molecule'] = full['SMILES'].apply(Chem.MolFromSmiles)"
      ],
      "metadata": {
        "id": "WoDt-hh4vxvG"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "duplicates = full[full.duplicated(subset='SMILES', keep=False)].sort_values(by='SMILES').reset_index(drop=True)\n",
        "prop = calculate_molecular_properties(duplicates).reset_index(drop=True)\n",
        "dupli_df = pd.concat([duplicates, prop], axis=1)[['SMILES', 'MLM', 'HLM', 'stereocenters']]\n",
        "\n",
        "# 'stereocenters' Ïª¨Îüº Í∞íÏù¥ 0Ïù∏ Îç∞Ïù¥ÌÑ∞ ÌïÑÌÑ∞ÎßÅ\n",
        "filtered_df = dupli_df[dupli_df['stereocenters'] == 0]\n",
        "\n",
        "# 'SMILES'Î•º Í∏∞Ï§ÄÏúºÎ°ú Í∑∏Î£πÌôîÌïòÍ≥† 'MLM'Í≥º 'HLM'Ïùò ÌèâÍ∑† Í≥ÑÏÇ∞\n",
        "mean_mlm = filtered_df.groupby('SMILES')['MLM'].mean().reset_index()\n",
        "mean_hlm = filtered_df.groupby('SMILES')['HLM'].mean().reset_index()\n",
        "\n",
        "# ÏõêÎ≥∏ DataFrameÏùÑ ÏàòÏ†ï\n",
        "for index, row in mean_mlm.iterrows():\n",
        "    smiles = row['SMILES']\n",
        "    mlm_mean = row['MLM']\n",
        "    hlm_mean = mean_hlm[mean_hlm['SMILES'] == smiles]['HLM'].values[0]\n",
        "    dupli_df.loc[dupli_df['SMILES'] == smiles, 'MLM'] = mlm_mean\n",
        "    dupli_df.loc[dupli_df['SMILES'] == smiles, 'HLM'] = hlm_mean\n",
        "\n",
        "mean_duplicate = dupli_df.drop_duplicates().reset_index(drop=True)\n",
        "\n",
        "# ÏûÖÏ≤¥Ïù¥ÏÑ±ÏßàÏ≤¥ ÏóÜÎäî Í≤ΩÏö∞ ÎèôÏùº Î∂ÑÏûêÏùò Ïã§ÌóòÍ∞íÎì§ÏùÑ meanÏúºÎ°ú Ï≤òÎ¶¨.\n",
        "for index, row in mean_duplicate.iterrows():\n",
        "    s_value = row['SMILES']\n",
        "    matching_indices = full[full['SMILES'] == s_value].index\n",
        "    for full_index in matching_indices:\n",
        "        full.at[full_index, 'MLM'] = row['MLM']\n",
        "        full.at[full_index, 'HLM'] = row['HLM']\n",
        "\n",
        "filtered_full = full.drop_duplicates(subset=['SMILES', 'HLM', 'MLM'], keep='first').reset_index(drop=True)"
      ],
      "metadata": {
        "id": "jrkzzQ7mw71Y"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "Sy5IZ2mBH5cX",
        "outputId": "320b7563-2cc4-47e0-e469-9a7480f21640"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 id                                             SMILES  \\\n",
              "0        TRAIN_0000    CCOc1ccc(CNC(=O)c2cc(-c3sc(C)nc3C)n[nH]2)cc1OCC   \n",
              "1        TRAIN_0001               Cc1nc(C)c(CN2CC(C)C(=O)Nc3ccccc32)s1   \n",
              "2        TRAIN_0002                   CCCN1CCN(c2nn3nnnc3c3ccccc23)CC1   \n",
              "3        TRAIN_0003  Cc1ccc(-c2ccc(-n3nc(C)c(S(=O)(=O)N4CCN(C5CCCCC...   \n",
              "4        TRAIN_0004                Cc1ccc2c(c1)N(C(=O)c1ccncc1)CC(C)O2   \n",
              "...             ...                                                ...   \n",
              "6245  CHEMBL3286701           Cc1[nH]c2ccccc2c1CCNC(=O)c1ccc(N(C)C)cc1   \n",
              "6246   CHEMBL215387       O=C(O)CCCCCCCCCCCNC(=O)NC12CC3CC(CC(C3)C1)C2   \n",
              "6247   CHEMBL242459  O=C(NC12CC3CC(CC(C3)C1)C2)N[C@H]1CC[C@H](Oc2cc...   \n",
              "6248  CHEMBL3735279       CCOC(=O)c1nc(C)c2c(c1N)C(=O)N(Cc1ccccc1)C2=O   \n",
              "6249  CHEMBL3353541  C[C@]1(C(=O)N(CCCC(=O)O)Cc2cccc(Cl)c2)CCN1C(=O...   \n",
              "\n",
              "         MLM     HLM  AlogP  Molecular_Weight  Num_H_Acceptors  Num_H_Donors  \\\n",
              "0     26.010  50.680  3.259           400.495                5             2   \n",
              "1     29.270  50.590  2.169           301.407                2             1   \n",
              "2      5.586  80.892  1.593           297.358                5             0   \n",
              "3      5.710   2.000  4.771           494.652                6             0   \n",
              "4     93.270  99.990  2.335           268.310                3             0   \n",
              "...      ...     ...    ...               ...              ...           ...   \n",
              "6245   0.000  17.000  3.510           321.420                2             2   \n",
              "6246     NaN  83.500  5.240           392.580                2             3   \n",
              "6247     NaN  83.000  4.340           412.530                3             3   \n",
              "6248     NaN  14.000  1.950           339.350                6             1   \n",
              "6249     NaN  76.300  5.050           485.010                4             1   \n",
              "\n",
              "      Num_RotatableBonds     LogD  Molecular_PolarSurfaceArea  \\\n",
              "0                      8  3.25900                      117.37   \n",
              "1                      2  2.17200                       73.47   \n",
              "2                      3  1.58500                       62.45   \n",
              "3                      5  3.47500                       92.60   \n",
              "4                      1  2.33700                       42.43   \n",
              "...                  ...      ...                         ...   \n",
              "6245                   5  3.51482                         NaN   \n",
              "6246                  13  5.24000                         NaN   \n",
              "6247                   5  4.34280                         NaN   \n",
              "6248                   4  1.94512                         NaN   \n",
              "6249                   8  5.05290                         NaN   \n",
              "\n",
              "                                              Molecule  \n",
              "0     <rdkit.Chem.rdchem.Mol object at 0x7be41781e960>  \n",
              "1     <rdkit.Chem.rdchem.Mol object at 0x7be41781e9d0>  \n",
              "2     <rdkit.Chem.rdchem.Mol object at 0x7be41781ea40>  \n",
              "3     <rdkit.Chem.rdchem.Mol object at 0x7be41781eab0>  \n",
              "4     <rdkit.Chem.rdchem.Mol object at 0x7be41781eb20>  \n",
              "...                                                ...  \n",
              "6245  <rdkit.Chem.rdchem.Mol object at 0x7be4180d6dc0>  \n",
              "6246  <rdkit.Chem.rdchem.Mol object at 0x7be4180d6e30>  \n",
              "6247  <rdkit.Chem.rdchem.Mol object at 0x7be4180d6ea0>  \n",
              "6248  <rdkit.Chem.rdchem.Mol object at 0x7be4180d6f10>  \n",
              "6249  <rdkit.Chem.rdchem.Mol object at 0x7be4180d6f80>  \n",
              "\n",
              "[6250 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c60d704a-fde6-48f8-ad65-a22551e58fb4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>SMILES</th>\n",
              "      <th>MLM</th>\n",
              "      <th>HLM</th>\n",
              "      <th>AlogP</th>\n",
              "      <th>Molecular_Weight</th>\n",
              "      <th>Num_H_Acceptors</th>\n",
              "      <th>Num_H_Donors</th>\n",
              "      <th>Num_RotatableBonds</th>\n",
              "      <th>LogD</th>\n",
              "      <th>Molecular_PolarSurfaceArea</th>\n",
              "      <th>Molecule</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TRAIN_0000</td>\n",
              "      <td>CCOc1ccc(CNC(=O)c2cc(-c3sc(C)nc3C)n[nH]2)cc1OCC</td>\n",
              "      <td>26.010</td>\n",
              "      <td>50.680</td>\n",
              "      <td>3.259</td>\n",
              "      <td>400.495</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>3.25900</td>\n",
              "      <td>117.37</td>\n",
              "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x7be41781e960&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TRAIN_0001</td>\n",
              "      <td>Cc1nc(C)c(CN2CC(C)C(=O)Nc3ccccc32)s1</td>\n",
              "      <td>29.270</td>\n",
              "      <td>50.590</td>\n",
              "      <td>2.169</td>\n",
              "      <td>301.407</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2.17200</td>\n",
              "      <td>73.47</td>\n",
              "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x7be41781e9d0&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TRAIN_0002</td>\n",
              "      <td>CCCN1CCN(c2nn3nnnc3c3ccccc23)CC1</td>\n",
              "      <td>5.586</td>\n",
              "      <td>80.892</td>\n",
              "      <td>1.593</td>\n",
              "      <td>297.358</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1.58500</td>\n",
              "      <td>62.45</td>\n",
              "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x7be41781ea40&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TRAIN_0003</td>\n",
              "      <td>Cc1ccc(-c2ccc(-n3nc(C)c(S(=O)(=O)N4CCN(C5CCCCC...</td>\n",
              "      <td>5.710</td>\n",
              "      <td>2.000</td>\n",
              "      <td>4.771</td>\n",
              "      <td>494.652</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>3.47500</td>\n",
              "      <td>92.60</td>\n",
              "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x7be41781eab0&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TRAIN_0004</td>\n",
              "      <td>Cc1ccc2c(c1)N(C(=O)c1ccncc1)CC(C)O2</td>\n",
              "      <td>93.270</td>\n",
              "      <td>99.990</td>\n",
              "      <td>2.335</td>\n",
              "      <td>268.310</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2.33700</td>\n",
              "      <td>42.43</td>\n",
              "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x7be41781eb20&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6245</th>\n",
              "      <td>CHEMBL3286701</td>\n",
              "      <td>Cc1[nH]c2ccccc2c1CCNC(=O)c1ccc(N(C)C)cc1</td>\n",
              "      <td>0.000</td>\n",
              "      <td>17.000</td>\n",
              "      <td>3.510</td>\n",
              "      <td>321.420</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>3.51482</td>\n",
              "      <td>NaN</td>\n",
              "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x7be4180d6dc0&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6246</th>\n",
              "      <td>CHEMBL215387</td>\n",
              "      <td>O=C(O)CCCCCCCCCCCNC(=O)NC12CC3CC(CC(C3)C1)C2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>83.500</td>\n",
              "      <td>5.240</td>\n",
              "      <td>392.580</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>5.24000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x7be4180d6e30&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6247</th>\n",
              "      <td>CHEMBL242459</td>\n",
              "      <td>O=C(NC12CC3CC(CC(C3)C1)C2)N[C@H]1CC[C@H](Oc2cc...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>83.000</td>\n",
              "      <td>4.340</td>\n",
              "      <td>412.530</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>4.34280</td>\n",
              "      <td>NaN</td>\n",
              "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x7be4180d6ea0&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6248</th>\n",
              "      <td>CHEMBL3735279</td>\n",
              "      <td>CCOC(=O)c1nc(C)c2c(c1N)C(=O)N(Cc1ccccc1)C2=O</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14.000</td>\n",
              "      <td>1.950</td>\n",
              "      <td>339.350</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1.94512</td>\n",
              "      <td>NaN</td>\n",
              "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x7be4180d6f10&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6249</th>\n",
              "      <td>CHEMBL3353541</td>\n",
              "      <td>C[C@]1(C(=O)N(CCCC(=O)O)Cc2cccc(Cl)c2)CCN1C(=O...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>76.300</td>\n",
              "      <td>5.050</td>\n",
              "      <td>485.010</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>5.05290</td>\n",
              "      <td>NaN</td>\n",
              "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x7be4180d6f80&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6250 rows √ó 12 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c60d704a-fde6-48f8-ad65-a22551e58fb4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c60d704a-fde6-48f8-ad65-a22551e58fb4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c60d704a-fde6-48f8-ad65-a22551e58fb4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-db16f18d-5c67-482b-851c-72ea8bc85358\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-db16f18d-5c67-482b-851c-72ea8bc85358')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-db16f18d-5c67-482b-851c-72ea8bc85358 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_full"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "jLrgL9ZpDrT9",
        "outputId": "0ed349ad-84b4-4305-c298-a9afaaa9e699"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 id                                             SMILES  \\\n",
              "0        TRAIN_0000    CCOc1ccc(CNC(=O)c2cc(-c3sc(C)nc3C)n[nH]2)cc1OCC   \n",
              "1        TRAIN_0001               Cc1nc(C)c(CN2CC(C)C(=O)Nc3ccccc32)s1   \n",
              "2        TRAIN_0002                   CCCN1CCN(c2nn3nnnc3c3ccccc23)CC1   \n",
              "3        TRAIN_0003  Cc1ccc(-c2ccc(-n3nc(C)c(S(=O)(=O)N4CCN(C5CCCCC...   \n",
              "4        TRAIN_0004                Cc1ccc2c(c1)N(C(=O)c1ccncc1)CC(C)O2   \n",
              "...             ...                                                ...   \n",
              "5742  CHEMBL3810411  Cc1cc(CCC#N)cc(C)c1Oc1cc(Nc2ccc(C#N)cc2)c(N)cc...   \n",
              "5743  CHEMBL3092907   Cc1nc(N2CCN(C)CC2)c2nc(-c3ccccc3Cl)n(CCO)c2n1.Cl   \n",
              "5744  CHEMBL2177757  O=C(Cc1ccccc1)Nc1nnc(CCSCCc2nnc(NC(=O)Cc3ccccc...   \n",
              "5745  CHEMBL3735279       CCOC(=O)c1nc(C)c2c(c1N)C(=O)N(Cc1ccccc1)C2=O   \n",
              "5746  CHEMBL3353541  C[C@]1(C(=O)N(CCCC(=O)O)Cc2cccc(Cl)c2)CCN1C(=O...   \n",
              "\n",
              "         MLM     HLM  AlogP  Molecular_Weight  Num_H_Acceptors  Num_H_Donors  \\\n",
              "0     26.010  50.680  3.259           400.495                5             2   \n",
              "1     29.270  50.590  2.169           301.407                2             1   \n",
              "2      5.586  80.892  1.593           297.358                5             0   \n",
              "3      5.710   2.000  4.771           494.652                6             0   \n",
              "4     93.270  99.990  2.335           268.310                3             0   \n",
              "...      ...     ...    ...               ...              ...           ...   \n",
              "5742     NaN  78.400  6.000           451.570                6             3   \n",
              "5743     NaN  13.000  2.200           423.350                7             1   \n",
              "5744     NaN  56.000  4.270           524.700                9             2   \n",
              "5745     NaN  14.000  1.950           339.350                6             1   \n",
              "5746     NaN  76.300  5.050           485.010                4             1   \n",
              "\n",
              "      Num_RotatableBonds     LogD  Molecular_PolarSurfaceArea  \\\n",
              "0                      8  3.25900                      117.37   \n",
              "1                      2  2.17200                       73.47   \n",
              "2                      3  1.58500                       62.45   \n",
              "3                      5  3.47500                       92.60   \n",
              "4                      1  2.33700                       42.43   \n",
              "...                  ...      ...                         ...   \n",
              "5742                   9  6.00140                         NaN   \n",
              "5743                   4  2.62102                         NaN   \n",
              "5744                  12  4.27040                         NaN   \n",
              "5745                   4  1.94512                         NaN   \n",
              "5746                   8  5.05290                         NaN   \n",
              "\n",
              "                                              Molecule  \n",
              "0     <rdkit.Chem.rdchem.Mol object at 0x7be41781e960>  \n",
              "1     <rdkit.Chem.rdchem.Mol object at 0x7be41781e9d0>  \n",
              "2     <rdkit.Chem.rdchem.Mol object at 0x7be41781ea40>  \n",
              "3     <rdkit.Chem.rdchem.Mol object at 0x7be41781eab0>  \n",
              "4     <rdkit.Chem.rdchem.Mol object at 0x7be41781eb20>  \n",
              "...                                                ...  \n",
              "5742  <rdkit.Chem.rdchem.Mol object at 0x7be4180d6c00>  \n",
              "5743  <rdkit.Chem.rdchem.Mol object at 0x7be4180d6c70>  \n",
              "5744  <rdkit.Chem.rdchem.Mol object at 0x7be4180d6ce0>  \n",
              "5745  <rdkit.Chem.rdchem.Mol object at 0x7be4180d6f10>  \n",
              "5746  <rdkit.Chem.rdchem.Mol object at 0x7be4180d6f80>  \n",
              "\n",
              "[5747 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b22039bd-081e-4147-9a5d-5ed5839758ba\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>SMILES</th>\n",
              "      <th>MLM</th>\n",
              "      <th>HLM</th>\n",
              "      <th>AlogP</th>\n",
              "      <th>Molecular_Weight</th>\n",
              "      <th>Num_H_Acceptors</th>\n",
              "      <th>Num_H_Donors</th>\n",
              "      <th>Num_RotatableBonds</th>\n",
              "      <th>LogD</th>\n",
              "      <th>Molecular_PolarSurfaceArea</th>\n",
              "      <th>Molecule</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TRAIN_0000</td>\n",
              "      <td>CCOc1ccc(CNC(=O)c2cc(-c3sc(C)nc3C)n[nH]2)cc1OCC</td>\n",
              "      <td>26.010</td>\n",
              "      <td>50.680</td>\n",
              "      <td>3.259</td>\n",
              "      <td>400.495</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>3.25900</td>\n",
              "      <td>117.37</td>\n",
              "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x7be41781e960&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TRAIN_0001</td>\n",
              "      <td>Cc1nc(C)c(CN2CC(C)C(=O)Nc3ccccc32)s1</td>\n",
              "      <td>29.270</td>\n",
              "      <td>50.590</td>\n",
              "      <td>2.169</td>\n",
              "      <td>301.407</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2.17200</td>\n",
              "      <td>73.47</td>\n",
              "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x7be41781e9d0&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TRAIN_0002</td>\n",
              "      <td>CCCN1CCN(c2nn3nnnc3c3ccccc23)CC1</td>\n",
              "      <td>5.586</td>\n",
              "      <td>80.892</td>\n",
              "      <td>1.593</td>\n",
              "      <td>297.358</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1.58500</td>\n",
              "      <td>62.45</td>\n",
              "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x7be41781ea40&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TRAIN_0003</td>\n",
              "      <td>Cc1ccc(-c2ccc(-n3nc(C)c(S(=O)(=O)N4CCN(C5CCCCC...</td>\n",
              "      <td>5.710</td>\n",
              "      <td>2.000</td>\n",
              "      <td>4.771</td>\n",
              "      <td>494.652</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>3.47500</td>\n",
              "      <td>92.60</td>\n",
              "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x7be41781eab0&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TRAIN_0004</td>\n",
              "      <td>Cc1ccc2c(c1)N(C(=O)c1ccncc1)CC(C)O2</td>\n",
              "      <td>93.270</td>\n",
              "      <td>99.990</td>\n",
              "      <td>2.335</td>\n",
              "      <td>268.310</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2.33700</td>\n",
              "      <td>42.43</td>\n",
              "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x7be41781eb20&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5742</th>\n",
              "      <td>CHEMBL3810411</td>\n",
              "      <td>Cc1cc(CCC#N)cc(C)c1Oc1cc(Nc2ccc(C#N)cc2)c(N)cc...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>78.400</td>\n",
              "      <td>6.000</td>\n",
              "      <td>451.570</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>6.00140</td>\n",
              "      <td>NaN</td>\n",
              "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x7be4180d6c00&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5743</th>\n",
              "      <td>CHEMBL3092907</td>\n",
              "      <td>Cc1nc(N2CCN(C)CC2)c2nc(-c3ccccc3Cl)n(CCO)c2n1.Cl</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13.000</td>\n",
              "      <td>2.200</td>\n",
              "      <td>423.350</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2.62102</td>\n",
              "      <td>NaN</td>\n",
              "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x7be4180d6c70&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5744</th>\n",
              "      <td>CHEMBL2177757</td>\n",
              "      <td>O=C(Cc1ccccc1)Nc1nnc(CCSCCc2nnc(NC(=O)Cc3ccccc...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>56.000</td>\n",
              "      <td>4.270</td>\n",
              "      <td>524.700</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>4.27040</td>\n",
              "      <td>NaN</td>\n",
              "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x7be4180d6ce0&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5745</th>\n",
              "      <td>CHEMBL3735279</td>\n",
              "      <td>CCOC(=O)c1nc(C)c2c(c1N)C(=O)N(Cc1ccccc1)C2=O</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14.000</td>\n",
              "      <td>1.950</td>\n",
              "      <td>339.350</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1.94512</td>\n",
              "      <td>NaN</td>\n",
              "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x7be4180d6f10&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5746</th>\n",
              "      <td>CHEMBL3353541</td>\n",
              "      <td>C[C@]1(C(=O)N(CCCC(=O)O)Cc2cccc(Cl)c2)CCN1C(=O...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>76.300</td>\n",
              "      <td>5.050</td>\n",
              "      <td>485.010</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>5.05290</td>\n",
              "      <td>NaN</td>\n",
              "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x7be4180d6f80&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5747 rows √ó 12 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b22039bd-081e-4147-9a5d-5ed5839758ba')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b22039bd-081e-4147-9a5d-5ed5839758ba button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b22039bd-081e-4147-9a5d-5ed5839758ba');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bd8c0915-9154-41b0-8b83-503cd55ed962\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bd8c0915-9154-41b0-8b83-503cd55ed962')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bd8c0915-9154-41b0-8b83-503cd55ed962 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mordred\n",
        "calc = Calculator(descriptors, ignore_3D=True)\n",
        "mord_desc_df = calc.pandas([Chem.MolFromSmiles(x) for x in filtered_full.SMILES])\n",
        "mord_desc_df.columns = ['mord_'+ column for column in mord_desc_df.columns]\n",
        "# object ÌòïÏãù Ïó¥ ÏÇ≠Ï†ú\n",
        "mord_desc_df.drop(columns=mord_desc_df.select_dtypes(include=['object']).columns, inplace=True)\n",
        "\n",
        "# bool ÌòïÏãù Ïó¥ÏùÑ 0Í≥º 1Î°ú Ïù∏ÏΩîÎî©\n",
        "bool_columns = mord_desc_df.select_dtypes(include=['bool']).columns\n",
        "mord_desc_df[bool_columns] = mord_desc_df[bool_columns].astype(int)\n",
        "\n",
        "print(mord_desc_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKwaU8RdsQJ5",
        "outputId": "de5885e6-0daa-4c8d-9a17-f7f91e87faf0"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|‚ñç         | 249/5747 [04:41<3:56:28,  2.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5434/5747 [1:46:18<06:09,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5747/5747 [1:52:50<00:00,  1.18s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    mord_ABC  mord_ABCGG  mord_nAcid  mord_nBase  mord_nAromAtom  \\\n",
            "0  21.379612   17.449011           0           0              16   \n",
            "1  16.539255   14.049653           0           0              11   \n",
            "2  17.475469   13.660693           2           1              13   \n",
            "3  27.857311   20.034364           0           1              17   \n",
            "4  15.722758   12.817176           0           0              12   \n",
            "\n",
            "   mord_nAromBond  mord_nAtom  mord_nHeavyAtom  mord_nSpiro  mord_nBridgehead  \\\n",
            "0              16          52               28            0                 0   \n",
            "1              11          40               21            0                 0   \n",
            "2              15          41               22            0                 0   \n",
            "3              17          69               35            0                 0   \n",
            "4              12          36               20            0                 0   \n",
            "\n",
            "   ...  mord_SRW09  mord_SRW10  mord_TSRW10     mord_MW  mord_AMW  mord_WPath  \\\n",
            "0  ...    7.390799   10.081676    78.761075  400.156912  7.695325        2380   \n",
            "1  ...    6.985642    9.907828    69.149596  301.124883  7.528122         870   \n",
            "2  ...    6.605298   10.144510    70.158066  297.170194  7.248054        1028   \n",
            "3  ...    7.034388   10.613467    86.199585  494.246395  7.162991        4170   \n",
            "4  ...    0.000000    9.978363    53.872357  268.121178  7.447810         762   \n",
            "\n",
            "   mord_WPol  mord_Zagreb1  mord_Zagreb2  mord_mZagreb2  \n",
            "0         40         142.0         165.0       6.361111  \n",
            "1         35         112.0         132.0       4.527778  \n",
            "2         36         120.0         145.0       4.888889  \n",
            "3         61         192.0         231.0       7.500000  \n",
            "4         32         106.0         125.0       4.361111  \n",
            "\n",
            "[5 rows x 999 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rdkit import DataStructs\n",
        "\n",
        "allDescrs = [getMolDescriptors(m) for m in filtered_full['Molecule']]\n",
        "full_Descrs = pd.DataFrame(allDescrs)"
      ],
      "metadata": {
        "id": "ZfsKLQizJdrr"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df_sp3 = count_fragments(filtered_full, 'sp3', Chem.HybridizationType.SP3)\n",
        "result_df_non_ring_sp3 = count_fragments(filtered_full, 'sp3', Chem.HybridizationType.SP3, exclude_ring=True)\n",
        "result_df_sp2 = count_fragments(filtered_full, 'sp2', Chem.HybridizationType.SP2)\n",
        "result_df_non_ring_sp2 = count_fragments(filtered_full, 'non_ring_sp2', Chem.HybridizationType.SP2, exclude_ring=True)\n",
        "result_df_sp = count_fragments(filtered_full, 'sp', Chem.HybridizationType.SP)\n",
        "\n",
        "prop_df = calculate_molecular_properties(filtered_full)"
      ],
      "metadata": {
        "id": "n99yR8XHKrhL"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df_non_ring_sp3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "22Ppk45vy24b",
        "outputId": "3eb1ecc3-29e8-435c-8243-7a503e114c51"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      sp3_CC  sp3_CCO  sp3_cCN  sp3_Cc  sp3_CCC  sp3_CCN  sp3_cS(N)(=O)=O  \\\n",
              "0        2.0      2.0      1.0     2.0      0.0      0.0              0.0   \n",
              "1        1.0      0.0      1.0     2.0      0.0      0.0              0.0   \n",
              "2        1.0      0.0      0.0     0.0      1.0      1.0              0.0   \n",
              "3        0.0      0.0      0.0     3.0      0.0      0.0              1.0   \n",
              "4        1.0      0.0      0.0     1.0      0.0      0.0              0.0   \n",
              "...      ...      ...      ...     ...      ...      ...              ...   \n",
              "5742     0.0      0.0      1.0     2.0      1.0      0.0              0.0   \n",
              "5743     0.0      1.0      0.0     1.0      0.0      0.0              0.0   \n",
              "5744     0.0      0.0      0.0     0.0      0.0      0.0              0.0   \n",
              "5745     1.0      1.0      1.0     1.0      0.0      0.0              0.0   \n",
              "5746     1.0      0.0      1.0     0.0      2.0      1.0              0.0   \n",
              "\n",
              "      sp3_CO  sp3_cF  sp3_CN  ...  sp3_NP(=O)(O)O  sp3_CC(C)[N+]  \\\n",
              "0        0.0     0.0     0.0  ...             0.0            0.0   \n",
              "1        0.0     0.0     0.0  ...             0.0            0.0   \n",
              "2        0.0     0.0     0.0  ...             0.0            0.0   \n",
              "3        0.0     0.0     0.0  ...             0.0            0.0   \n",
              "4        0.0     0.0     0.0  ...             0.0            0.0   \n",
              "...      ...     ...     ...  ...             ...            ...   \n",
              "5742     0.0     0.0     0.0  ...             0.0            0.0   \n",
              "5743     1.0     0.0     1.0  ...             0.0            0.0   \n",
              "5744     0.0     0.0     0.0  ...             0.0            0.0   \n",
              "5745     0.0     0.0     0.0  ...             0.0            0.0   \n",
              "5746     0.0     0.0     0.0  ...             0.0            0.0   \n",
              "\n",
              "      sp3_C[C@@H](C)S  sp3_O=P([O-])(O)O  sp3_[O-]P  sp3_OP  sp3_C[Si]  \\\n",
              "0                 0.0                0.0        0.0     0.0        0.0   \n",
              "1                 0.0                0.0        0.0     0.0        0.0   \n",
              "2                 0.0                0.0        0.0     0.0        0.0   \n",
              "3                 0.0                0.0        0.0     0.0        0.0   \n",
              "4                 0.0                0.0        0.0     0.0        0.0   \n",
              "...               ...                ...        ...     ...        ...   \n",
              "5742              0.0                0.0        0.0     0.0        0.0   \n",
              "5743              0.0                0.0        0.0     0.0        0.0   \n",
              "5744              0.0                0.0        0.0     0.0        0.0   \n",
              "5745              0.0                0.0        0.0     0.0        0.0   \n",
              "5746              0.0                0.0        0.0     0.0        0.0   \n",
              "\n",
              "      sp3_CC(P)P  sp3_c[Si](C)(C)C  sp3_c[C@@H](C)O  \n",
              "0            0.0               0.0              0.0  \n",
              "1            0.0               0.0              0.0  \n",
              "2            0.0               0.0              0.0  \n",
              "3            0.0               0.0              0.0  \n",
              "4            0.0               0.0              0.0  \n",
              "...          ...               ...              ...  \n",
              "5742         0.0               0.0              0.0  \n",
              "5743         0.0               0.0              0.0  \n",
              "5744         0.0               0.0              0.0  \n",
              "5745         0.0               0.0              0.0  \n",
              "5746         0.0               0.0              0.0  \n",
              "\n",
              "[5747 rows x 150 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-686a5b69-fc1f-4fc0-8385-c64fd6d6ea96\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sp3_CC</th>\n",
              "      <th>sp3_CCO</th>\n",
              "      <th>sp3_cCN</th>\n",
              "      <th>sp3_Cc</th>\n",
              "      <th>sp3_CCC</th>\n",
              "      <th>sp3_CCN</th>\n",
              "      <th>sp3_cS(N)(=O)=O</th>\n",
              "      <th>sp3_CO</th>\n",
              "      <th>sp3_cF</th>\n",
              "      <th>sp3_CN</th>\n",
              "      <th>...</th>\n",
              "      <th>sp3_NP(=O)(O)O</th>\n",
              "      <th>sp3_CC(C)[N+]</th>\n",
              "      <th>sp3_C[C@@H](C)S</th>\n",
              "      <th>sp3_O=P([O-])(O)O</th>\n",
              "      <th>sp3_[O-]P</th>\n",
              "      <th>sp3_OP</th>\n",
              "      <th>sp3_C[Si]</th>\n",
              "      <th>sp3_CC(P)P</th>\n",
              "      <th>sp3_c[Si](C)(C)C</th>\n",
              "      <th>sp3_c[C@@H](C)O</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5742</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5743</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5744</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5745</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5746</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5747 rows √ó 150 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-686a5b69-fc1f-4fc0-8385-c64fd6d6ea96')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-686a5b69-fc1f-4fc0-8385-c64fd6d6ea96 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-686a5b69-fc1f-4fc0-8385-c64fd6d6ea96');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9ac6e5a4-abb4-4e8d-ac60-83934a8e4940\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9ac6e5a4-abb4-4e8d-ac60-83934a8e4940')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9ac6e5a4-abb4-4e8d-ac60-83934a8e4940 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import ChemicalFeatures\n",
        "from rdkit import RDConfig\n",
        "import os\n",
        "\n",
        "# Define the feature definition file\n",
        "fdefName = os.path.join(RDConfig.RDDataDir, 'BaseFeatures.fdef')\n",
        "\n",
        "# Build the feature factory\n",
        "factory = ChemicalFeatures.BuildFeatureFactory(fdefName)\n",
        "\n",
        "# Initialize a dictionary to store feature counts\n",
        "feature_counts = {}\n",
        "\n",
        "def extract_features(smiles):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        return None\n",
        "\n",
        "    # Get the features for the molecule\n",
        "    feats = factory.GetFeaturesForMol(mol)\n",
        "\n",
        "    feature_count = {}\n",
        "    for feat in feats:\n",
        "        # feat_type = feat.GetFamily()\n",
        "        feat_type = feat.GetType()  # Use the feature type (or type)\n",
        "        if feat_type in feature_count:\n",
        "            feature_count[feat_type] += 1\n",
        "        else:\n",
        "            feature_count[feat_type] = 1\n",
        "\n",
        "    return feature_count\n",
        "\n",
        "# Iterate through each SMILES in the DataFrame\n",
        "for index, row in filtered_full.iterrows():\n",
        "    smiles = row['SMILES']\n",
        "    feature_count = extract_features(smiles)\n",
        "    feature_counts[index] = feature_count\n",
        "\n",
        "# Create a DataFrame from the feature counts dictionary and fill missing values with 0\n",
        "result_data = []\n",
        "for index, counts in feature_counts.items():\n",
        "    counts['SMILES'] = filtered_full.loc[index, 'SMILES']\n",
        "    result_data.append(counts)\n",
        "\n",
        "result_df_features = pd.DataFrame(result_data).fillna(0).drop(columns='SMILES')\n",
        "\n",
        "# Rename columns with a prefix\n",
        "result_df_features.columns = ['feature_' + column for column in result_df_features.columns]\n",
        "\n",
        "# Print the resulting DataFrame\n",
        "print(result_df_features)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XBlo5T4MoQT",
        "outputId": "86481d8d-ec68-43c4-de95-afd789be1bdd"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      feature_SingleAtomDonor  feature_SingleAtomAcceptor  feature_Arom5  \\\n",
            "0                         3.0                         5.0            2.0   \n",
            "1                         1.0                         2.0            1.0   \n",
            "2                         1.0                         4.0            1.0   \n",
            "3                         1.0                         5.0            1.0   \n",
            "4                         0.0                         3.0            0.0   \n",
            "...                       ...                         ...            ...   \n",
            "5742                      3.0                         1.0            0.0   \n",
            "5743                      2.0                         4.0            1.0   \n",
            "5744                      2.0                         6.0            2.0   \n",
            "5745                      2.0                         5.0            0.0   \n",
            "5746                      3.0                         4.0            1.0   \n",
            "\n",
            "      feature_Arom6  feature_ThreeWayAttach  feature_RH6_6  \\\n",
            "0               1.0                     2.0            1.0   \n",
            "1               1.0                     2.0            1.0   \n",
            "2               2.0                     2.0            1.0   \n",
            "3               2.0                     3.0            1.0   \n",
            "4               2.0                     2.0            1.0   \n",
            "...             ...                     ...            ...   \n",
            "5742            3.0                     5.0            3.0   \n",
            "5743            2.0                     2.0            1.0   \n",
            "5744            2.0                     2.0            2.0   \n",
            "5745            2.0                     3.0            1.0   \n",
            "5746            2.0                     5.0            2.0   \n",
            "\n",
            "      feature_BasicGroup  feature_ChainTwoWayAttach  feature_AcidicGroup  \\\n",
            "0                    0.0                        0.0                  0.0   \n",
            "1                    0.0                        0.0                  0.0   \n",
            "2                    1.0                        1.0                  0.0   \n",
            "3                    1.0                        0.0                  0.0   \n",
            "4                    0.0                        0.0                  0.0   \n",
            "...                  ...                        ...                  ...   \n",
            "5742                 1.0                        2.0                  0.0   \n",
            "5743                 1.0                        0.0                  0.0   \n",
            "5744                 0.0                        6.0                  0.0   \n",
            "5745                 0.0                        0.0                  0.0   \n",
            "5746                 0.0                        2.0                  1.0   \n",
            "\n",
            "      feature_ZnBinder5  ...  feature_iPropyl  feature_RH4_4  \\\n",
            "0                   0.0  ...              0.0            0.0   \n",
            "1                   0.0  ...              0.0            0.0   \n",
            "2                   0.0  ...              0.0            0.0   \n",
            "3                   0.0  ...              0.0            0.0   \n",
            "4                   0.0  ...              0.0            0.0   \n",
            "...                 ...  ...              ...            ...   \n",
            "5742                0.0  ...              0.0            0.0   \n",
            "5743                0.0  ...              0.0            0.0   \n",
            "5744                0.0  ...              0.0            0.0   \n",
            "5745                0.0  ...              0.0            0.0   \n",
            "5746                1.0  ...              0.0            0.0   \n",
            "\n",
            "      feature_Guanidine  feature_tButyl  feature_PosN  feature_RH3_3  \\\n",
            "0                   0.0             0.0           0.0            0.0   \n",
            "1                   0.0             0.0           0.0            0.0   \n",
            "2                   0.0             0.0           0.0            0.0   \n",
            "3                   0.0             0.0           0.0            0.0   \n",
            "4                   0.0             0.0           0.0            0.0   \n",
            "...                 ...             ...           ...            ...   \n",
            "5742                0.0             0.0           0.0            0.0   \n",
            "5743                0.0             0.0           0.0            0.0   \n",
            "5744                0.0             0.0           0.0            0.0   \n",
            "5745                0.0             0.0           0.0            0.0   \n",
            "5746                0.0             0.0           0.0            0.0   \n",
            "\n",
            "      feature_Nitro2  feature_ZnBinder6  feature_Arom7  feature_ZnBinder4  \n",
            "0                0.0                0.0            0.0                0.0  \n",
            "1                0.0                0.0            0.0                0.0  \n",
            "2                0.0                0.0            0.0                0.0  \n",
            "3                0.0                0.0            0.0                0.0  \n",
            "4                0.0                0.0            0.0                0.0  \n",
            "...              ...                ...            ...                ...  \n",
            "5742             0.0                0.0            0.0                0.0  \n",
            "5743             0.0                0.0            0.0                0.0  \n",
            "5744             0.0                0.0            0.0                0.0  \n",
            "5745             0.0                0.0            0.0                0.0  \n",
            "5746             0.0                0.0            0.0                0.0  \n",
            "\n",
            "[5747 rows x 22 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Data = pd.concat([filtered_full, full_Descrs,mord_desc_df,result_df_sp3, result_df_non_ring_sp3, result_df_sp2, result_df_non_ring_sp2, result_df_sp, prop_df, result_df_features], axis=1).drop(columns=['Molecule', 'MolWt', 'NumHAcceptors', 'NumHDonors', 'NumRotatableBonds', 'MolLogP'])\n",
        "Data[\"Molecular_PolarSurfaceArea\"] = np.where(pd.isna(Data[\"Molecular_PolarSurfaceArea\"]), Data[\"TPSA\"], Data[\"Molecular_PolarSurfaceArea\"])"
      ],
      "metadata": {
        "id": "eR76gc2-L0F-"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Data['beyond_Lipinski'] = 0\n",
        "\n",
        "Data.loc[Data['Molecular_Weight'] >= 500, 'beyond_Lipinski'] += 1\n",
        "Data.loc[Data['LogD'] >= 5, 'beyond_Lipinski'] += 1\n",
        "Data.loc[Data['Num_H_Donors'] >= 5, 'beyond_Lipinski'] += 1\n",
        "Data.loc[Data['Num_H_Acceptors'] >= 10, 'beyond_Lipinski'] += 1\n",
        "Data.loc[Data['Num_RotatableBonds'] >= 10, 'beyond_Lipinski'] += 1\n",
        "Data.loc[(Data['Num_H_Donors'] + Data['Num_H_Acceptors']) >= 12, 'beyond_Lipinski'] += 1\n",
        "Data.loc[Data['TPSA'] >= 140, 'beyond_Lipinski'] += 1\n",
        "Data.loc[Data['FractionCSP3'] <= 0.3, 'beyond_Lipinski'] += 1\n",
        "Data.loc[Data['NumAromaticRings'] >= 5, 'beyond_Lipinski'] += 1\n",
        "Data.loc[Data['NOCount'] >= 10, 'beyond_Lipinski'] += 1\n",
        "Data.loc[Data['NHOHCount'] >= 5, 'beyond_Lipinski'] += 1"
      ],
      "metadata": {
        "id": "iJjQWRiLNRY_"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the file path where you want to save the pickle file\n",
        "pickle_file_path = \"/content/drive/MyDrive/dacon_data_0911.pkl\"\n",
        "\n",
        "# Save the DataFrame as a pickle file\n",
        "Data.to_pickle(pickle_file_path)\n",
        "\n",
        "# Print a message to confirm that the file has been saved\n",
        "print(f\"DataFrame saved as {pickle_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Fkr7mDPNS7F",
        "outputId": "96ee6891-f4a7-4777-9cce-56b2d90bed2b"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved as /content/drive/MyDrive/dacon_data_0911.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# ÏßÄÏ†ïÎêú pickle ÌååÏùº Í≤ΩÎ°ú\n",
        "pickle_file_path = \"/content/drive/MyDrive/dacon_data_0911.pkl\"\n",
        "\n",
        "# pickle ÌååÏùºÏùÑ DataFrameÏúºÎ°ú Î°úÎìú\n",
        "Data = pd.read_pickle(pickle_file_path)\n",
        "\n",
        "# Î°úÎìúÎêú DataFrame Ï∂úÎ†• ÎòêÎäî ÏÇ¨Ïö©\n",
        "print(Data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQqms1ut62tj",
        "outputId": "2edc8951-e777-4a85-a259-52059f930467"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 id                                             SMILES  \\\n",
            "0        TRAIN_0000    CCOc1ccc(CNC(=O)c2cc(-c3sc(C)nc3C)n[nH]2)cc1OCC   \n",
            "1        TRAIN_0001               Cc1nc(C)c(CN2CC(C)C(=O)Nc3ccccc32)s1   \n",
            "2        TRAIN_0002                   CCCN1CCN(c2nn3nnnc3c3ccccc23)CC1   \n",
            "3        TRAIN_0003  Cc1ccc(-c2ccc(-n3nc(C)c(S(=O)(=O)N4CCN(C5CCCCC...   \n",
            "4        TRAIN_0004                Cc1ccc2c(c1)N(C(=O)c1ccncc1)CC(C)O2   \n",
            "...             ...                                                ...   \n",
            "5742  CHEMBL3810411  Cc1cc(CCC#N)cc(C)c1Oc1cc(Nc2ccc(C#N)cc2)c(N)cc...   \n",
            "5743  CHEMBL3092907   Cc1nc(N2CCN(C)CC2)c2nc(-c3ccccc3Cl)n(CCO)c2n1.Cl   \n",
            "5744  CHEMBL2177757  O=C(Cc1ccccc1)Nc1nnc(CCSCCc2nnc(NC(=O)Cc3ccccc...   \n",
            "5745  CHEMBL3735279       CCOC(=O)c1nc(C)c2c(c1N)C(=O)N(Cc1ccccc1)C2=O   \n",
            "5746  CHEMBL3353541  C[C@]1(C(=O)N(CCCC(=O)O)Cc2cccc(Cl)c2)CCN1C(=O...   \n",
            "\n",
            "         MLM     HLM  AlogP  Molecular_Weight  Num_H_Acceptors  Num_H_Donors  \\\n",
            "0     26.010  50.680  3.259           400.495                5             2   \n",
            "1     29.270  50.590  2.169           301.407                2             1   \n",
            "2      5.586  80.892  1.593           297.358                5             0   \n",
            "3      5.710   2.000  4.771           494.652                6             0   \n",
            "4     93.270  99.990  2.335           268.310                3             0   \n",
            "...      ...     ...    ...               ...              ...           ...   \n",
            "5742     NaN  78.400  6.000           451.570                6             3   \n",
            "5743     NaN  13.000  2.200           423.350                7             1   \n",
            "5744     NaN  56.000  4.270           524.700                9             2   \n",
            "5745     NaN  14.000  1.950           339.350                6             1   \n",
            "5746     NaN  76.300  5.050           485.010                4             1   \n",
            "\n",
            "      Num_RotatableBonds     LogD  ...  feature_RH4_4  feature_Guanidine  \\\n",
            "0                      8  3.25900  ...            0.0                0.0   \n",
            "1                      2  2.17200  ...            0.0                0.0   \n",
            "2                      3  1.58500  ...            0.0                0.0   \n",
            "3                      5  3.47500  ...            0.0                0.0   \n",
            "4                      1  2.33700  ...            0.0                0.0   \n",
            "...                  ...      ...  ...            ...                ...   \n",
            "5742                   9  6.00140  ...            0.0                0.0   \n",
            "5743                   4  2.62102  ...            0.0                0.0   \n",
            "5744                  12  4.27040  ...            0.0                0.0   \n",
            "5745                   4  1.94512  ...            0.0                0.0   \n",
            "5746                   8  5.05290  ...            0.0                0.0   \n",
            "\n",
            "      feature_tButyl  feature_PosN  feature_RH3_3  feature_Nitro2  \\\n",
            "0                0.0           0.0            0.0             0.0   \n",
            "1                0.0           0.0            0.0             0.0   \n",
            "2                0.0           0.0            0.0             0.0   \n",
            "3                0.0           0.0            0.0             0.0   \n",
            "4                0.0           0.0            0.0             0.0   \n",
            "...              ...           ...            ...             ...   \n",
            "5742             0.0           0.0            0.0             0.0   \n",
            "5743             0.0           0.0            0.0             0.0   \n",
            "5744             0.0           0.0            0.0             0.0   \n",
            "5745             0.0           0.0            0.0             0.0   \n",
            "5746             0.0           0.0            0.0             0.0   \n",
            "\n",
            "      feature_ZnBinder6  feature_Arom7  feature_ZnBinder4  beyond_Lipinski  \n",
            "0                   0.0            0.0                0.0                0  \n",
            "1                   0.0            0.0                0.0                0  \n",
            "2                   0.0            0.0                0.0                0  \n",
            "3                   0.0            0.0                0.0                0  \n",
            "4                   0.0            0.0                0.0                1  \n",
            "...                 ...            ...                ...              ...  \n",
            "5742                0.0            0.0                0.0                2  \n",
            "5743                0.0            0.0                0.0                0  \n",
            "5744                0.0            0.0                0.0                3  \n",
            "5745                0.0            0.0                0.0                1  \n",
            "5746                0.0            0.0                0.0                1  \n",
            "\n",
            "[5747 rows x 2068 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_column = [column for column in Data.columns]"
      ],
      "metadata": {
        "id": "dECWKIqqMoLU"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Desc_feature= ['MaxAbsEStateIndex','MaxEStateIndex','MinAbsEStateIndex','MinEStateIndex','qed','HeavyAtomMolWt','NumValenceElectrons',\n",
        " 'NumRadicalElectrons','MaxPartialCharge','MinPartialCharge','MaxAbsPartialCharge','MinAbsPartialCharge',\n",
        " 'FpDensityMorgan1','FpDensityMorgan2','FpDensityMorgan3','HallKierAlpha','Ipc','NHOHCount','NOCount']"
      ],
      "metadata": {
        "id": "_lhTGJs4NNzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 'id' Ïª¨ÎüºÏóê 'TEST' Î¨∏ÏûêÏó¥Ïù¥ Îì§Ïñ¥Í∞ÄÎäî ÌñâÏùÑ testsetÏúºÎ°ú ÏÑ†ÌÉù\n",
        "test = Data[Data['id'].str.contains('TEST')]\n",
        "print(len(test))\n",
        "# 'id' Ïª¨ÎüºÏóê 'TEST' Î¨∏ÏûêÏó¥Ïù¥ Îì§Ïñ¥Í∞ÄÏßÄ ÏïäÎäî ÌñâÏùÑ trainsetÏúºÎ°ú ÏÑ†ÌÉù\n",
        "train = Data[~Data['id'].str.contains('TEST')]\n",
        "print(len(train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_SlbGfqNgaj",
        "outputId": "439296d0-2228-4acb-a17b-6e90e1abab92"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "483\n",
            "5264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "\n",
        "# Ïà´ÏûêÌòïÏãù Ïª¨ÎüºÎì§Ïùò min-max Ï†ïÍ∑úÌôî\n",
        "scaler = MinMaxScaler()\n",
        "standard_scaler = StandardScaler()\n",
        "robust_scaler = RobustScaler()\n",
        "non_features = ['id', 'SMILES', 'MLM', 'HLM','Fingerprint']\n",
        "features = [column for column in train.columns if column not in non_features]\n",
        "train[features] = scaler.fit_transform(train[features])\n",
        "\n",
        "test[features] = scaler.transform(test[features])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R099_5OfNstu",
        "outputId": "ea10b952-e403-4aa3-e856-aa5dd62f2461"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if is_sparse(pd_dtype):\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if is_sparse(pd_dtype):\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
            "<ipython-input-8-238fa936b178>:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train[features] = scaler.fit_transform(train[features])\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if is_sparse(pd_dtype):\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
            "<ipython-input-8-238fa936b178>:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test[features] = scaler.transform(test[features])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_HLM = train.drop(columns=['MLM']).dropna(axis=0)\n",
        "print(len(train_HLM))\n",
        "train_MLM = train.drop(columns=['HLM']).dropna(axis=0)\n",
        "print(len(train_MLM))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAEOG7RSNwfh",
        "outputId": "f7c4942a-2040-4081-9127-ec9261046605"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4842\n",
            "4045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_HLM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "YQLekamB0S_K",
        "outputId": "8b2b1572-39cb-4078-a704-8c63aecb79fb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 id                                             SMILES  \\\n",
              "0        TRAIN_0000    CCOc1ccc(CNC(=O)c2cc(-c3sc(C)nc3C)n[nH]2)cc1OCC   \n",
              "1        TRAIN_0001               Cc1nc(C)c(CN2CC(C)C(=O)Nc3ccccc32)s1   \n",
              "2        TRAIN_0002                   CCCN1CCN(c2nn3nnnc3c3ccccc23)CC1   \n",
              "3        TRAIN_0003  Cc1ccc(-c2ccc(-n3nc(C)c(S(=O)(=O)N4CCN(C5CCCCC...   \n",
              "4        TRAIN_0004                Cc1ccc2c(c1)N(C(=O)c1ccncc1)CC(C)O2   \n",
              "...             ...                                                ...   \n",
              "5742  CHEMBL3810411  Cc1cc(CCC#N)cc(C)c1Oc1cc(Nc2ccc(C#N)cc2)c(N)cc...   \n",
              "5743  CHEMBL3092907   Cc1nc(N2CCN(C)CC2)c2nc(-c3ccccc3Cl)n(CCO)c2n1.Cl   \n",
              "5744  CHEMBL2177757  O=C(Cc1ccccc1)Nc1nnc(CCSCCc2nnc(NC(=O)Cc3ccccc...   \n",
              "5745  CHEMBL3735279       CCOC(=O)c1nc(C)c2c(c1N)C(=O)N(Cc1ccccc1)C2=O   \n",
              "5746  CHEMBL3353541  C[C@]1(C(=O)N(CCCC(=O)O)Cc2cccc(Cl)c2)CCN1C(=O...   \n",
              "\n",
              "         HLM     AlogP  Molecular_Weight  Num_H_Acceptors  Num_H_Donors  \\\n",
              "0     50.680  0.554964          0.192138         0.294118        0.1250   \n",
              "1     50.590  0.473175          0.108751         0.117647        0.0625   \n",
              "2     80.892  0.429954          0.105343         0.294118        0.0000   \n",
              "3      2.000  0.668417          0.271376         0.352941        0.0000   \n",
              "4     99.990  0.485631          0.080898         0.176471        0.0000   \n",
              "...      ...       ...               ...              ...           ...   \n",
              "5742  78.400  0.760636          0.235120         0.352941        0.1875   \n",
              "5743  13.000  0.475501          0.211371         0.411765        0.0625   \n",
              "5744  56.000  0.630825          0.296662         0.529412        0.1250   \n",
              "5745  14.000  0.456742          0.140682         0.352941        0.0625   \n",
              "5746  76.300  0.689352          0.263261         0.235294        0.0625   \n",
              "\n",
              "      Num_RotatableBonds      LogD  Molecular_PolarSurfaceArea  ...  \\\n",
              "0               0.210526  0.579660                    0.278787  ...   \n",
              "1               0.052632  0.502622                    0.171552  ...   \n",
              "2               0.078947  0.461021                    0.144633  ...   \n",
              "3               0.131579  0.594968                    0.218281  ...   \n",
              "4               0.026316  0.514316                    0.095730  ...   \n",
              "...                  ...       ...                         ...  ...   \n",
              "5742            0.236842  0.774018                    0.253188  ...   \n",
              "5743            0.105263  0.534445                    0.163833  ...   \n",
              "5744            0.315789  0.651339                    0.260198  ...   \n",
              "5745            0.105263  0.486543                    0.242684  ...   \n",
              "5746            0.210526  0.706797                    0.182422  ...   \n",
              "\n",
              "      feature_RH4_4  feature_Guanidine  feature_tButyl  feature_PosN  \\\n",
              "0               0.0                0.0             0.0           0.0   \n",
              "1               0.0                0.0             0.0           0.0   \n",
              "2               0.0                0.0             0.0           0.0   \n",
              "3               0.0                0.0             0.0           0.0   \n",
              "4               0.0                0.0             0.0           0.0   \n",
              "...             ...                ...             ...           ...   \n",
              "5742            0.0                0.0             0.0           0.0   \n",
              "5743            0.0                0.0             0.0           0.0   \n",
              "5744            0.0                0.0             0.0           0.0   \n",
              "5745            0.0                0.0             0.0           0.0   \n",
              "5746            0.0                0.0             0.0           0.0   \n",
              "\n",
              "      feature_RH3_3  feature_Nitro2  feature_ZnBinder6  feature_Arom7  \\\n",
              "0               0.0             0.0                0.0            0.0   \n",
              "1               0.0             0.0                0.0            0.0   \n",
              "2               0.0             0.0                0.0            0.0   \n",
              "3               0.0             0.0                0.0            0.0   \n",
              "4               0.0             0.0                0.0            0.0   \n",
              "...             ...             ...                ...            ...   \n",
              "5742            0.0             0.0                0.0            0.0   \n",
              "5743            0.0             0.0                0.0            0.0   \n",
              "5744            0.0             0.0                0.0            0.0   \n",
              "5745            0.0             0.0                0.0            0.0   \n",
              "5746            0.0             0.0                0.0            0.0   \n",
              "\n",
              "      feature_ZnBinder4  beyond_Lipinski  \n",
              "0                   0.0              0.0  \n",
              "1                   0.0              0.0  \n",
              "2                   0.0              0.0  \n",
              "3                   0.0              0.0  \n",
              "4                   0.0              0.1  \n",
              "...                 ...              ...  \n",
              "5742                0.0              0.2  \n",
              "5743                0.0              0.0  \n",
              "5744                0.0              0.3  \n",
              "5745                0.0              0.1  \n",
              "5746                0.0              0.1  \n",
              "\n",
              "[4842 rows x 2067 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-93703698-9010-4d71-9475-330ae7676faa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>SMILES</th>\n",
              "      <th>HLM</th>\n",
              "      <th>AlogP</th>\n",
              "      <th>Molecular_Weight</th>\n",
              "      <th>Num_H_Acceptors</th>\n",
              "      <th>Num_H_Donors</th>\n",
              "      <th>Num_RotatableBonds</th>\n",
              "      <th>LogD</th>\n",
              "      <th>Molecular_PolarSurfaceArea</th>\n",
              "      <th>...</th>\n",
              "      <th>feature_RH4_4</th>\n",
              "      <th>feature_Guanidine</th>\n",
              "      <th>feature_tButyl</th>\n",
              "      <th>feature_PosN</th>\n",
              "      <th>feature_RH3_3</th>\n",
              "      <th>feature_Nitro2</th>\n",
              "      <th>feature_ZnBinder6</th>\n",
              "      <th>feature_Arom7</th>\n",
              "      <th>feature_ZnBinder4</th>\n",
              "      <th>beyond_Lipinski</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TRAIN_0000</td>\n",
              "      <td>CCOc1ccc(CNC(=O)c2cc(-c3sc(C)nc3C)n[nH]2)cc1OCC</td>\n",
              "      <td>50.680</td>\n",
              "      <td>0.554964</td>\n",
              "      <td>0.192138</td>\n",
              "      <td>0.294118</td>\n",
              "      <td>0.1250</td>\n",
              "      <td>0.210526</td>\n",
              "      <td>0.579660</td>\n",
              "      <td>0.278787</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TRAIN_0001</td>\n",
              "      <td>Cc1nc(C)c(CN2CC(C)C(=O)Nc3ccccc32)s1</td>\n",
              "      <td>50.590</td>\n",
              "      <td>0.473175</td>\n",
              "      <td>0.108751</td>\n",
              "      <td>0.117647</td>\n",
              "      <td>0.0625</td>\n",
              "      <td>0.052632</td>\n",
              "      <td>0.502622</td>\n",
              "      <td>0.171552</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TRAIN_0002</td>\n",
              "      <td>CCCN1CCN(c2nn3nnnc3c3ccccc23)CC1</td>\n",
              "      <td>80.892</td>\n",
              "      <td>0.429954</td>\n",
              "      <td>0.105343</td>\n",
              "      <td>0.294118</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.078947</td>\n",
              "      <td>0.461021</td>\n",
              "      <td>0.144633</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TRAIN_0003</td>\n",
              "      <td>Cc1ccc(-c2ccc(-n3nc(C)c(S(=O)(=O)N4CCN(C5CCCCC...</td>\n",
              "      <td>2.000</td>\n",
              "      <td>0.668417</td>\n",
              "      <td>0.271376</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.131579</td>\n",
              "      <td>0.594968</td>\n",
              "      <td>0.218281</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TRAIN_0004</td>\n",
              "      <td>Cc1ccc2c(c1)N(C(=O)c1ccncc1)CC(C)O2</td>\n",
              "      <td>99.990</td>\n",
              "      <td>0.485631</td>\n",
              "      <td>0.080898</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.026316</td>\n",
              "      <td>0.514316</td>\n",
              "      <td>0.095730</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5742</th>\n",
              "      <td>CHEMBL3810411</td>\n",
              "      <td>Cc1cc(CCC#N)cc(C)c1Oc1cc(Nc2ccc(C#N)cc2)c(N)cc...</td>\n",
              "      <td>78.400</td>\n",
              "      <td>0.760636</td>\n",
              "      <td>0.235120</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.1875</td>\n",
              "      <td>0.236842</td>\n",
              "      <td>0.774018</td>\n",
              "      <td>0.253188</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5743</th>\n",
              "      <td>CHEMBL3092907</td>\n",
              "      <td>Cc1nc(N2CCN(C)CC2)c2nc(-c3ccccc3Cl)n(CCO)c2n1.Cl</td>\n",
              "      <td>13.000</td>\n",
              "      <td>0.475501</td>\n",
              "      <td>0.211371</td>\n",
              "      <td>0.411765</td>\n",
              "      <td>0.0625</td>\n",
              "      <td>0.105263</td>\n",
              "      <td>0.534445</td>\n",
              "      <td>0.163833</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5744</th>\n",
              "      <td>CHEMBL2177757</td>\n",
              "      <td>O=C(Cc1ccccc1)Nc1nnc(CCSCCc2nnc(NC(=O)Cc3ccccc...</td>\n",
              "      <td>56.000</td>\n",
              "      <td>0.630825</td>\n",
              "      <td>0.296662</td>\n",
              "      <td>0.529412</td>\n",
              "      <td>0.1250</td>\n",
              "      <td>0.315789</td>\n",
              "      <td>0.651339</td>\n",
              "      <td>0.260198</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5745</th>\n",
              "      <td>CHEMBL3735279</td>\n",
              "      <td>CCOC(=O)c1nc(C)c2c(c1N)C(=O)N(Cc1ccccc1)C2=O</td>\n",
              "      <td>14.000</td>\n",
              "      <td>0.456742</td>\n",
              "      <td>0.140682</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.0625</td>\n",
              "      <td>0.105263</td>\n",
              "      <td>0.486543</td>\n",
              "      <td>0.242684</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5746</th>\n",
              "      <td>CHEMBL3353541</td>\n",
              "      <td>C[C@]1(C(=O)N(CCCC(=O)O)Cc2cccc(Cl)c2)CCN1C(=O...</td>\n",
              "      <td>76.300</td>\n",
              "      <td>0.689352</td>\n",
              "      <td>0.263261</td>\n",
              "      <td>0.235294</td>\n",
              "      <td>0.0625</td>\n",
              "      <td>0.210526</td>\n",
              "      <td>0.706797</td>\n",
              "      <td>0.182422</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4842 rows √ó 2067 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-93703698-9010-4d71-9475-330ae7676faa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-93703698-9010-4d71-9475-330ae7676faa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-93703698-9010-4d71-9475-330ae7676faa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-eedcc79c-09ef-4b72-8900-bd4203bc3e0f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eedcc79c-09ef-4b72-8900-bd4203bc3e0f')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-eedcc79c-09ef-4b72-8900-bd4203bc3e0f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dgl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3WvLqaSQaMY",
        "outputId": "19ad26aa-fb84-4e6f-cdbe-f6fe47ba50e3"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dgl in /usr/local/lib/python3.10/site-packages (1.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from dgl) (4.65.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/site-packages (from dgl) (2.28.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/site-packages (from dgl) (1.11.2)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/site-packages (from dgl) (2.8.8)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/site-packages (from dgl) (1.25.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/site-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests>=2.19.0->dgl) (2023.7.22)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests>=2.19.0->dgl) (3.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests>=2.19.0->dgl) (3.1.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests>=2.19.0->dgl) (1.26.15)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, BatchNormalization, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.metrics import RootMeanSquaredError\n",
        "import keras\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import math\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "from keras.regularizers import l2\n",
        "\n",
        "# Define features and targets\n",
        "non_features = ['id', 'SMILES', 'MLM', 'HLM', 'Fingerprint']\n",
        "features = [column for column in train.columns if column not in non_features]\n",
        "mlm_target = \"MLM\"\n",
        "hlm_target = \"HLM\"\n",
        "\n",
        "# Initialize KFold\n",
        "seed = 42\n",
        "n_splits = 20\n",
        "kf = KFold(n_splits=n_splits, random_state=seed, shuffle=True)\n",
        "\n",
        "# Initialize arrays to store models and scores\n",
        "reg_mlms = []\n",
        "reg_hlms = []\n",
        "\n",
        "# Initialize arrays to store RMSE scores\n",
        "mlm_rmse_scores = []\n",
        "hlm_rmse_scores = []\n",
        "\n",
        "# Loop through KFold splits\n",
        "for i, (train_index, valid_index) in enumerate(kf.split(train_HLM)):\n",
        "    df_train = train_HLM.iloc[train_index]\n",
        "    df_valid = train_HLM.iloc[valid_index]\n",
        "\n",
        "    x_train_num = df_train[features].values\n",
        "\n",
        "    y_hlm_train = df_train[hlm_target].values\n",
        "\n",
        "    x_valid_num = df_valid[features].values\n",
        "\n",
        "    y_hlm_valid = df_valid[hlm_target].values\n",
        "\n",
        "\n",
        "    # Ïù¥ÎØ∏ÏßÄ ÏûÖÎ†• Í≤ΩÎ°ú\n",
        "    x1_input = keras.Input(shape=(x_train_num.shape[1],))\n",
        "    x1 = layers.Dense(1024, activation='relu')(x1_input)\n",
        "    x1 = layers.BatchNormalization()(x1)\n",
        "    x1 = layers.Dropout(0.2)(x1)\n",
        "    merged = layers.Dense(1024, activation='relu')(x1)\n",
        "    merged = layers.BatchNormalization()(merged)\n",
        "    merged = layers.Dropout(0.2)(merged)\n",
        "    merged = layers.Dense(512, activation='relu')(merged)\n",
        "    merged = layers.BatchNormalization()(merged)\n",
        "    merged = layers.Dropout(0.2)(merged)\n",
        "    merged = layers.Dense(256, activation='relu')(merged)\n",
        "    merged = layers.BatchNormalization()(merged)\n",
        "    merged = layers.Dropout(0.2)(merged)\n",
        "    merged = layers.Dense(128, activation='relu')(merged)\n",
        "    merged = layers.BatchNormalization()(merged)\n",
        "\n",
        "    # ÌöåÍ∑Ä Î™®Îç∏ Ï∂úÎ†• Î†àÏù¥Ïñ¥ Ï∂îÍ∞Ä\n",
        "    outputs = layers.Dense(1, kernel_regularizer='l1_l2')(merged)\n",
        "\n",
        "    # Î™®Îç∏ ÏÉùÏÑ±\n",
        "    model_hlm = keras.Model(inputs=x1_input, outputs=outputs)\n",
        "\n",
        "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.001,\n",
        "    decay_steps=8,\n",
        "    decay_rate=0.98)\n",
        "    optimizer_decay = keras.optimizers.SGD(learning_rate=lr_schedule)\n",
        "\n",
        "    model_hlm.compile(optimizer=optimizer_decay, loss='mean_squared_error', metrics=[RootMeanSquaredError()])\n",
        "\n",
        "    checkpoint_hlm = ModelCheckpoint(f'model_hlm_fold{i}.h5', monitor='val_loss', verbose=0, save_best_only=True)\n",
        "    early_stopping_hlm = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "\n",
        "    model_hlm.fit(x_train_num, y_hlm_train, epochs=500, batch_size=16, verbose=1, validation_data=(x_valid_num, y_hlm_valid),\n",
        "                  callbacks=[checkpoint_hlm, early_stopping_hlm])\n",
        "\n",
        "    reg_hlms.append(model_hlm)\n",
        "\n",
        "    # Calculate RMSE for HLM predictions\n",
        "    y_hlm_pred = model_hlm.predict(x_valid_num)\n",
        "    hlm_rmse = math.sqrt(mean_squared_error(y_hlm_valid, y_hlm_pred))\n",
        "    print(hlm_rmse)\n",
        "    hlm_rmse_scores.append(hlm_rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsKsV7chN8pM",
        "outputId": "6b55143c-4352-4034-bcaf-7c56fb190e84"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "288/288 [==============================] - 4s 7ms/step - loss: 1291.3960 - root_mean_squared_error: 35.9225 - val_loss: 912.0453 - val_root_mean_squared_error: 30.1837\n",
            "Epoch 2/500\n",
            " 10/288 [>.............................] - ETA: 1s - loss: 981.8726 - root_mean_squared_error: 31.3187 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "288/288 [==============================] - 2s 6ms/step - loss: 966.7283 - root_mean_squared_error: 31.0761 - val_loss: 898.9067 - val_root_mean_squared_error: 29.9655\n",
            "Epoch 3/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 894.0826 - root_mean_squared_error: 29.8845 - val_loss: 826.2173 - val_root_mean_squared_error: 28.7263\n",
            "Epoch 4/500\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 870.4010 - root_mean_squared_error: 29.4855 - val_loss: 808.1194 - val_root_mean_squared_error: 28.4094\n",
            "Epoch 5/500\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 836.1818 - root_mean_squared_error: 28.8993 - val_loss: 804.5114 - val_root_mean_squared_error: 28.3460\n",
            "Epoch 6/500\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 812.5217 - root_mean_squared_error: 28.4870 - val_loss: 800.1597 - val_root_mean_squared_error: 28.2691\n",
            "Epoch 7/500\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 801.3748 - root_mean_squared_error: 28.2906 - val_loss: 799.2723 - val_root_mean_squared_error: 28.2534\n",
            "Epoch 8/500\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 793.5137 - root_mean_squared_error: 28.1513 - val_loss: 798.0961 - val_root_mean_squared_error: 28.2326\n",
            "Epoch 9/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 800.3743 - root_mean_squared_error: 28.2729 - val_loss: 800.2083 - val_root_mean_squared_error: 28.2700\n",
            "Epoch 10/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 794.4160 - root_mean_squared_error: 28.1673 - val_loss: 801.4080 - val_root_mean_squared_error: 28.2912\n",
            "Epoch 11/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 800.1333 - root_mean_squared_error: 28.2686 - val_loss: 799.6221 - val_root_mean_squared_error: 28.2596\n",
            "Epoch 12/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 816.9207 - root_mean_squared_error: 28.5640 - val_loss: 801.1586 - val_root_mean_squared_error: 28.2868\n",
            "Epoch 13/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 799.8928 - root_mean_squared_error: 28.2644 - val_loss: 799.5743 - val_root_mean_squared_error: 28.2588\n",
            "Epoch 14/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 813.1064 - root_mean_squared_error: 28.4972 - val_loss: 799.2678 - val_root_mean_squared_error: 28.2533\n",
            "Epoch 15/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 787.1422 - root_mean_squared_error: 28.0379 - val_loss: 799.0656 - val_root_mean_squared_error: 28.2498\n",
            "Epoch 16/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 797.1387 - root_mean_squared_error: 28.2156 - val_loss: 800.0496 - val_root_mean_squared_error: 28.2672\n",
            "Epoch 17/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 800.5157 - root_mean_squared_error: 28.2754 - val_loss: 800.0099 - val_root_mean_squared_error: 28.2665\n",
            "Epoch 18/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 797.9378 - root_mean_squared_error: 28.2298 - val_loss: 799.7380 - val_root_mean_squared_error: 28.2616\n",
            "Epoch 19/500\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 801.3340 - root_mean_squared_error: 28.2899 - val_loss: 798.0445 - val_root_mean_squared_error: 28.2317\n",
            "Epoch 20/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 796.5394 - root_mean_squared_error: 28.2050 - val_loss: 799.0886 - val_root_mean_squared_error: 28.2502\n",
            "Epoch 21/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 802.5906 - root_mean_squared_error: 28.3121 - val_loss: 800.3440 - val_root_mean_squared_error: 28.2724\n",
            "Epoch 22/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 805.4460 - root_mean_squared_error: 28.3625 - val_loss: 800.5218 - val_root_mean_squared_error: 28.2755\n",
            "Epoch 23/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 794.6571 - root_mean_squared_error: 28.1716 - val_loss: 799.0688 - val_root_mean_squared_error: 28.2498\n",
            "Epoch 24/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 794.1182 - root_mean_squared_error: 28.1621 - val_loss: 798.5751 - val_root_mean_squared_error: 28.2411\n",
            "Epoch 25/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 784.5850 - root_mean_squared_error: 27.9923 - val_loss: 797.8426 - val_root_mean_squared_error: 28.2281\n",
            "Epoch 26/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 795.0044 - root_mean_squared_error: 28.1778 - val_loss: 799.6829 - val_root_mean_squared_error: 28.2607\n",
            "Epoch 27/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 803.4907 - root_mean_squared_error: 28.3280 - val_loss: 798.5326 - val_root_mean_squared_error: 28.2403\n",
            "Epoch 28/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 802.4968 - root_mean_squared_error: 28.3104 - val_loss: 800.9594 - val_root_mean_squared_error: 28.2832\n",
            "Epoch 29/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 802.0809 - root_mean_squared_error: 28.3031 - val_loss: 800.9030 - val_root_mean_squared_error: 28.2822\n",
            "Epoch 30/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 798.4412 - root_mean_squared_error: 28.2387 - val_loss: 800.5551 - val_root_mean_squared_error: 28.2761\n",
            "Epoch 31/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 819.0328 - root_mean_squared_error: 28.6010 - val_loss: 800.7537 - val_root_mean_squared_error: 28.2796\n",
            "Epoch 32/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 790.0660 - root_mean_squared_error: 28.0900 - val_loss: 799.2828 - val_root_mean_squared_error: 28.2536\n",
            "Epoch 33/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 798.7667 - root_mean_squared_error: 28.2445 - val_loss: 800.4844 - val_root_mean_squared_error: 28.2749\n",
            "Epoch 34/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 809.6176 - root_mean_squared_error: 28.4359 - val_loss: 800.9620 - val_root_mean_squared_error: 28.2833\n",
            "Epoch 35/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 801.2368 - root_mean_squared_error: 28.2882 - val_loss: 798.8447 - val_root_mean_squared_error: 28.2458\n",
            "Epoch 36/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 791.1971 - root_mean_squared_error: 28.1101 - val_loss: 800.5164 - val_root_mean_squared_error: 28.2754\n",
            "Epoch 37/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 790.4626 - root_mean_squared_error: 28.0971 - val_loss: 801.1674 - val_root_mean_squared_error: 28.2869\n",
            "Epoch 38/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 792.0039 - root_mean_squared_error: 28.1245 - val_loss: 801.7778 - val_root_mean_squared_error: 28.2977\n",
            "Epoch 39/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 803.5516 - root_mean_squared_error: 28.3290 - val_loss: 799.9993 - val_root_mean_squared_error: 28.2663\n",
            "Epoch 40/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 812.4357 - root_mean_squared_error: 28.4854 - val_loss: 800.4870 - val_root_mean_squared_error: 28.2749\n",
            "Epoch 41/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 807.8163 - root_mean_squared_error: 28.4042 - val_loss: 802.7348 - val_root_mean_squared_error: 28.3146\n",
            "Epoch 42/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 812.0438 - root_mean_squared_error: 28.4785 - val_loss: 798.5721 - val_root_mean_squared_error: 28.2410\n",
            "Epoch 43/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 810.4871 - root_mean_squared_error: 28.4512 - val_loss: 798.4146 - val_root_mean_squared_error: 28.2382\n",
            "Epoch 44/500\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 807.6066 - root_mean_squared_error: 28.4005 - val_loss: 797.2616 - val_root_mean_squared_error: 28.2178\n",
            "Epoch 45/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 809.5624 - root_mean_squared_error: 28.4349 - val_loss: 801.7730 - val_root_mean_squared_error: 28.2976\n",
            "Epoch 46/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 797.6622 - root_mean_squared_error: 28.2249 - val_loss: 800.6976 - val_root_mean_squared_error: 28.2786\n",
            "Epoch 47/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 798.4850 - root_mean_squared_error: 28.2395 - val_loss: 800.6572 - val_root_mean_squared_error: 28.2779\n",
            "Epoch 48/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 799.5240 - root_mean_squared_error: 28.2579 - val_loss: 799.2884 - val_root_mean_squared_error: 28.2537\n",
            "Epoch 49/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 804.9201 - root_mean_squared_error: 28.3532 - val_loss: 799.5986 - val_root_mean_squared_error: 28.2592\n",
            "Epoch 50/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 808.1731 - root_mean_squared_error: 28.4105 - val_loss: 798.7411 - val_root_mean_squared_error: 28.2440\n",
            "Epoch 51/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 807.1250 - root_mean_squared_error: 28.3920 - val_loss: 798.3572 - val_root_mean_squared_error: 28.2372\n",
            "Epoch 52/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 802.5738 - root_mean_squared_error: 28.3118 - val_loss: 801.0305 - val_root_mean_squared_error: 28.2845\n",
            "Epoch 53/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 794.3341 - root_mean_squared_error: 28.1659 - val_loss: 800.5567 - val_root_mean_squared_error: 28.2761\n",
            "Epoch 54/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 809.4100 - root_mean_squared_error: 28.4322 - val_loss: 798.8150 - val_root_mean_squared_error: 28.2453\n",
            "Epoch 55/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 791.2648 - root_mean_squared_error: 28.1113 - val_loss: 797.7247 - val_root_mean_squared_error: 28.2260\n",
            "Epoch 56/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 808.0752 - root_mean_squared_error: 28.4088 - val_loss: 798.9425 - val_root_mean_squared_error: 28.2476\n",
            "Epoch 57/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 800.2051 - root_mean_squared_error: 28.2699 - val_loss: 800.5764 - val_root_mean_squared_error: 28.2765\n",
            "Epoch 58/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 818.9650 - root_mean_squared_error: 28.5998 - val_loss: 798.9677 - val_root_mean_squared_error: 28.2480\n",
            "Epoch 59/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 801.3774 - root_mean_squared_error: 28.2906 - val_loss: 800.8527 - val_root_mean_squared_error: 28.2814\n",
            "Epoch 60/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 805.7394 - root_mean_squared_error: 28.3676 - val_loss: 799.7233 - val_root_mean_squared_error: 28.2614\n",
            "Epoch 61/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 799.2000 - root_mean_squared_error: 28.2521 - val_loss: 801.2968 - val_root_mean_squared_error: 28.2892\n",
            "Epoch 62/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 802.7860 - root_mean_squared_error: 28.3155 - val_loss: 799.1903 - val_root_mean_squared_error: 28.2520\n",
            "Epoch 63/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 804.6594 - root_mean_squared_error: 28.3486 - val_loss: 799.8141 - val_root_mean_squared_error: 28.2630\n",
            "Epoch 64/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 814.9661 - root_mean_squared_error: 28.5298 - val_loss: 801.9048 - val_root_mean_squared_error: 28.3000\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "28.217803243163182\n",
            "Epoch 1/500\n",
            "288/288 [==============================] - 4s 8ms/step - loss: 1290.9822 - root_mean_squared_error: 35.9171 - val_loss: 1246.4917 - val_root_mean_squared_error: 35.2912\n",
            "Epoch 2/500\n",
            " 10/288 [>.............................] - ETA: 1s - loss: 942.0477 - root_mean_squared_error: 30.6765"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "288/288 [==============================] - 2s 7ms/step - loss: 952.9602 - root_mean_squared_error: 30.8540 - val_loss: 989.0490 - val_root_mean_squared_error: 31.4335\n",
            "Epoch 3/500\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 905.3743 - root_mean_squared_error: 30.0730 - val_loss: 895.5146 - val_root_mean_squared_error: 29.9084\n",
            "Epoch 4/500\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 852.3433 - root_mean_squared_error: 29.1779 - val_loss: 894.2679 - val_root_mean_squared_error: 29.8875\n",
            "Epoch 5/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 818.9998 - root_mean_squared_error: 28.6008 - val_loss: 899.9042 - val_root_mean_squared_error: 29.9816\n",
            "Epoch 6/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 813.3651 - root_mean_squared_error: 28.5019 - val_loss: 897.2601 - val_root_mean_squared_error: 29.9376\n",
            "Epoch 7/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 808.9669 - root_mean_squared_error: 28.4247 - val_loss: 899.7137 - val_root_mean_squared_error: 29.9785\n",
            "Epoch 8/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 791.2454 - root_mean_squared_error: 28.1113 - val_loss: 897.7377 - val_root_mean_squared_error: 29.9455\n",
            "Epoch 9/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 783.8235 - root_mean_squared_error: 27.9789 - val_loss: 896.2997 - val_root_mean_squared_error: 29.9215\n",
            "Epoch 10/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 812.5872 - root_mean_squared_error: 28.4883 - val_loss: 895.3093 - val_root_mean_squared_error: 29.9049\n",
            "Epoch 11/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 785.3999 - root_mean_squared_error: 28.0071 - val_loss: 895.2250 - val_root_mean_squared_error: 29.9035\n",
            "Epoch 12/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 787.4824 - root_mean_squared_error: 28.0442 - val_loss: 897.2581 - val_root_mean_squared_error: 29.9375\n",
            "Epoch 13/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 792.7613 - root_mean_squared_error: 28.1382 - val_loss: 895.1918 - val_root_mean_squared_error: 29.9030\n",
            "Epoch 14/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 799.4476 - root_mean_squared_error: 28.2568 - val_loss: 900.7065 - val_root_mean_squared_error: 29.9950\n",
            "Epoch 15/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 809.5388 - root_mean_squared_error: 28.4348 - val_loss: 897.5524 - val_root_mean_squared_error: 29.9424\n",
            "Epoch 16/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 790.1086 - root_mean_squared_error: 28.0910 - val_loss: 896.1959 - val_root_mean_squared_error: 29.9198\n",
            "Epoch 17/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 797.5025 - root_mean_squared_error: 28.2223 - val_loss: 896.7502 - val_root_mean_squared_error: 29.9290\n",
            "Epoch 18/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 800.1306 - root_mean_squared_error: 28.2688 - val_loss: 897.7784 - val_root_mean_squared_error: 29.9462\n",
            "Epoch 19/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 797.6215 - root_mean_squared_error: 28.2244 - val_loss: 893.5485 - val_root_mean_squared_error: 29.8755\n",
            "Epoch 20/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 788.3531 - root_mean_squared_error: 28.0597 - val_loss: 893.8660 - val_root_mean_squared_error: 29.8808\n",
            "Epoch 21/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 772.8650 - root_mean_squared_error: 27.7824 - val_loss: 895.9791 - val_root_mean_squared_error: 29.9161\n",
            "Epoch 22/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 791.5117 - root_mean_squared_error: 28.1160 - val_loss: 895.4545 - val_root_mean_squared_error: 29.9074\n",
            "Epoch 23/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 795.0807 - root_mean_squared_error: 28.1794 - val_loss: 898.3798 - val_root_mean_squared_error: 29.9562\n",
            "Epoch 24/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 786.8726 - root_mean_squared_error: 28.0334 - val_loss: 898.7375 - val_root_mean_squared_error: 29.9622\n",
            "Epoch 25/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 795.6449 - root_mean_squared_error: 28.1894 - val_loss: 897.9920 - val_root_mean_squared_error: 29.9498\n",
            "Epoch 26/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 787.3423 - root_mean_squared_error: 28.0417 - val_loss: 896.8784 - val_root_mean_squared_error: 29.9312\n",
            "Epoch 27/500\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 797.1857 - root_mean_squared_error: 28.2167 - val_loss: 892.9100 - val_root_mean_squared_error: 29.8648\n",
            "Epoch 28/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 788.1547 - root_mean_squared_error: 28.0562 - val_loss: 898.2136 - val_root_mean_squared_error: 29.9535\n",
            "Epoch 29/500\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 795.2627 - root_mean_squared_error: 28.1826 - val_loss: 892.6619 - val_root_mean_squared_error: 29.8606\n",
            "Epoch 30/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 783.4913 - root_mean_squared_error: 27.9730 - val_loss: 899.8105 - val_root_mean_squared_error: 29.9801\n",
            "Epoch 31/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 797.6182 - root_mean_squared_error: 28.2244 - val_loss: 896.2505 - val_root_mean_squared_error: 29.9207\n",
            "Epoch 32/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 782.8027 - root_mean_squared_error: 27.9607 - val_loss: 894.6162 - val_root_mean_squared_error: 29.8934\n",
            "Epoch 33/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 796.4501 - root_mean_squared_error: 28.2037 - val_loss: 895.9081 - val_root_mean_squared_error: 29.9150\n",
            "Epoch 34/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 791.2070 - root_mean_squared_error: 28.1106 - val_loss: 899.9180 - val_root_mean_squared_error: 29.9819\n",
            "Epoch 35/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 791.8035 - root_mean_squared_error: 28.1212 - val_loss: 897.4901 - val_root_mean_squared_error: 29.9414\n",
            "Epoch 36/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 800.0825 - root_mean_squared_error: 28.2680 - val_loss: 895.2934 - val_root_mean_squared_error: 29.9047\n",
            "Epoch 37/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 790.3092 - root_mean_squared_error: 28.0946 - val_loss: 893.0340 - val_root_mean_squared_error: 29.8669\n",
            "Epoch 38/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 793.0349 - root_mean_squared_error: 28.1430 - val_loss: 898.0181 - val_root_mean_squared_error: 29.9502\n",
            "Epoch 39/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 777.6309 - root_mean_squared_error: 27.8680 - val_loss: 895.4541 - val_root_mean_squared_error: 29.9074\n",
            "Epoch 40/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 790.5624 - root_mean_squared_error: 28.0991 - val_loss: 893.5919 - val_root_mean_squared_error: 29.8762\n",
            "Epoch 41/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 786.9384 - root_mean_squared_error: 28.0345 - val_loss: 894.2055 - val_root_mean_squared_error: 29.8865\n",
            "Epoch 42/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 790.6171 - root_mean_squared_error: 28.1001 - val_loss: 895.4833 - val_root_mean_squared_error: 29.9079\n",
            "Epoch 43/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 783.0660 - root_mean_squared_error: 27.9654 - val_loss: 893.4242 - val_root_mean_squared_error: 29.8734\n",
            "Epoch 44/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 807.8984 - root_mean_squared_error: 28.4059 - val_loss: 895.1682 - val_root_mean_squared_error: 29.9026\n",
            "Epoch 45/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 800.0051 - root_mean_squared_error: 28.2666 - val_loss: 897.8394 - val_root_mean_squared_error: 29.9472\n",
            "Epoch 46/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 795.7766 - root_mean_squared_error: 28.1917 - val_loss: 899.7721 - val_root_mean_squared_error: 29.9795\n",
            "Epoch 47/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 791.5967 - root_mean_squared_error: 28.1175 - val_loss: 899.0917 - val_root_mean_squared_error: 29.9681\n",
            "Epoch 48/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 787.1408 - root_mean_squared_error: 28.0381 - val_loss: 895.8209 - val_root_mean_squared_error: 29.9135\n",
            "Epoch 49/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 797.8477 - root_mean_squared_error: 28.2284 - val_loss: 897.0139 - val_root_mean_squared_error: 29.9334\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "29.860649917633587\n",
            "Epoch 1/500\n",
            "288/288 [==============================] - 5s 8ms/step - loss: 1292.2946 - root_mean_squared_error: 35.9348 - val_loss: 1167.4396 - val_root_mean_squared_error: 34.1526\n",
            "Epoch 2/500\n",
            " 10/288 [>.............................] - ETA: 1s - loss: 1205.3812 - root_mean_squared_error: 34.7038"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "288/288 [==============================] - 2s 7ms/step - loss: 980.9037 - root_mean_squared_error: 31.3031 - val_loss: 1044.8076 - val_root_mean_squared_error: 32.3079\n",
            "Epoch 3/500\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 897.7974 - root_mean_squared_error: 29.9462 - val_loss: 1008.4758 - val_root_mean_squared_error: 31.7407\n",
            "Epoch 4/500\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 858.2556 - root_mean_squared_error: 29.2785 - val_loss: 944.2845 - val_root_mean_squared_error: 30.7125\n",
            "Epoch 5/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 812.5490 - root_mean_squared_error: 28.4872 - val_loss: 948.6865 - val_root_mean_squared_error: 30.7840\n",
            "Epoch 6/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 809.5222 - root_mean_squared_error: 28.4339 - val_loss: 942.1581 - val_root_mean_squared_error: 30.6778\n",
            "Epoch 7/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 811.9003 - root_mean_squared_error: 28.4757 - val_loss: 942.7408 - val_root_mean_squared_error: 30.6873\n",
            "Epoch 8/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 797.6318 - root_mean_squared_error: 28.2241 - val_loss: 942.7712 - val_root_mean_squared_error: 30.6878\n",
            "Epoch 9/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 796.4852 - root_mean_squared_error: 28.2038 - val_loss: 941.5436 - val_root_mean_squared_error: 30.6677\n",
            "Epoch 10/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 785.5400 - root_mean_squared_error: 28.0091 - val_loss: 941.6260 - val_root_mean_squared_error: 30.6691\n",
            "Epoch 11/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 779.6747 - root_mean_squared_error: 27.9041 - val_loss: 940.9402 - val_root_mean_squared_error: 30.6579\n",
            "Epoch 12/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 792.5347 - root_mean_squared_error: 28.1336 - val_loss: 941.4728 - val_root_mean_squared_error: 30.6666\n",
            "Epoch 13/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 799.2052 - root_mean_squared_error: 28.2519 - val_loss: 941.1063 - val_root_mean_squared_error: 30.6606\n",
            "Epoch 14/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 790.8489 - root_mean_squared_error: 28.1037 - val_loss: 942.2191 - val_root_mean_squared_error: 30.6787\n",
            "Epoch 15/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 805.0276 - root_mean_squared_error: 28.3548 - val_loss: 941.1119 - val_root_mean_squared_error: 30.6607\n",
            "Epoch 16/500\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 792.0768 - root_mean_squared_error: 28.1255 - val_loss: 940.0640 - val_root_mean_squared_error: 30.6436\n",
            "Epoch 17/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 790.3627 - root_mean_squared_error: 28.0950 - val_loss: 942.0052 - val_root_mean_squared_error: 30.6753\n",
            "Epoch 18/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 797.2543 - root_mean_squared_error: 28.2174 - val_loss: 941.6387 - val_root_mean_squared_error: 30.6693\n",
            "Epoch 19/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 799.4389 - root_mean_squared_error: 28.2561 - val_loss: 940.3774 - val_root_mean_squared_error: 30.6487\n",
            "Epoch 20/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 796.1179 - root_mean_squared_error: 28.1972 - val_loss: 942.5146 - val_root_mean_squared_error: 30.6836\n",
            "Epoch 21/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 787.2663 - root_mean_squared_error: 28.0398 - val_loss: 939.8434 - val_root_mean_squared_error: 30.6400\n",
            "Epoch 22/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 808.6376 - root_mean_squared_error: 28.4184 - val_loss: 941.9830 - val_root_mean_squared_error: 30.6749\n",
            "Epoch 23/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 787.0157 - root_mean_squared_error: 28.0354 - val_loss: 942.8168 - val_root_mean_squared_error: 30.6885\n",
            "Epoch 24/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 782.9191 - root_mean_squared_error: 27.9622 - val_loss: 943.1751 - val_root_mean_squared_error: 30.6943\n",
            "Epoch 25/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 802.1846 - root_mean_squared_error: 28.3046 - val_loss: 942.2963 - val_root_mean_squared_error: 30.6800\n",
            "Epoch 26/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 793.5408 - root_mean_squared_error: 28.1515 - val_loss: 942.8589 - val_root_mean_squared_error: 30.6892\n",
            "Epoch 27/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 788.7631 - root_mean_squared_error: 28.0665 - val_loss: 944.6599 - val_root_mean_squared_error: 30.7185\n",
            "Epoch 28/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 794.0702 - root_mean_squared_error: 28.1609 - val_loss: 941.9179 - val_root_mean_squared_error: 30.6738\n",
            "Epoch 29/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 794.8812 - root_mean_squared_error: 28.1753 - val_loss: 943.0079 - val_root_mean_squared_error: 30.6916\n",
            "Epoch 30/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 796.5963 - root_mean_squared_error: 28.2057 - val_loss: 942.2061 - val_root_mean_squared_error: 30.6785\n",
            "Epoch 31/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 802.9198 - root_mean_squared_error: 28.3176 - val_loss: 943.0197 - val_root_mean_squared_error: 30.6918\n",
            "Epoch 32/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 786.7982 - root_mean_squared_error: 28.0315 - val_loss: 943.0636 - val_root_mean_squared_error: 30.6925\n",
            "Epoch 33/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 797.6342 - root_mean_squared_error: 28.2241 - val_loss: 943.3058 - val_root_mean_squared_error: 30.6965\n",
            "Epoch 34/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 798.8840 - root_mean_squared_error: 28.2463 - val_loss: 941.9357 - val_root_mean_squared_error: 30.6741\n",
            "Epoch 35/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 791.1069 - root_mean_squared_error: 28.1082 - val_loss: 941.4232 - val_root_mean_squared_error: 30.6658\n",
            "Epoch 36/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 797.0134 - root_mean_squared_error: 28.2131 - val_loss: 941.8650 - val_root_mean_squared_error: 30.6730\n",
            "Epoch 37/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 804.5750 - root_mean_squared_error: 28.3468 - val_loss: 944.4675 - val_root_mean_squared_error: 30.7154\n",
            "Epoch 38/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 790.2056 - root_mean_squared_error: 28.0922 - val_loss: 941.3013 - val_root_mean_squared_error: 30.6638\n",
            "Epoch 39/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 790.7190 - root_mean_squared_error: 28.1013 - val_loss: 944.1083 - val_root_mean_squared_error: 30.7095\n",
            "Epoch 40/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 801.5378 - root_mean_squared_error: 28.2932 - val_loss: 942.0864 - val_root_mean_squared_error: 30.6766\n",
            "Epoch 41/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 797.9920 - root_mean_squared_error: 28.2305 - val_loss: 942.6812 - val_root_mean_squared_error: 30.6863\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "30.640009198061353\n",
            "Epoch 1/500\n",
            "288/288 [==============================] - 4s 7ms/step - loss: 1296.3973 - root_mean_squared_error: 35.9922 - val_loss: 1323.7325 - val_root_mean_squared_error: 36.3698\n",
            "Epoch 2/500\n",
            " 10/288 [>.............................] - ETA: 1s - loss: 902.3986 - root_mean_squared_error: 30.0237"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "288/288 [==============================] - 2s 6ms/step - loss: 969.4471 - root_mean_squared_error: 31.1199 - val_loss: 1009.3111 - val_root_mean_squared_error: 31.7536\n",
            "Epoch 3/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 898.3433 - root_mean_squared_error: 29.9556 - val_loss: 930.5032 - val_root_mean_squared_error: 30.4879\n",
            "Epoch 4/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 857.1227 - root_mean_squared_error: 29.2595 - val_loss: 915.9953 - val_root_mean_squared_error: 30.2485\n",
            "Epoch 5/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 835.8807 - root_mean_squared_error: 28.8940 - val_loss: 901.2163 - val_root_mean_squared_error: 30.0033\n",
            "Epoch 6/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 809.2927 - root_mean_squared_error: 28.4302 - val_loss: 901.5728 - val_root_mean_squared_error: 30.0092\n",
            "Epoch 7/500\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 806.2711 - root_mean_squared_error: 28.3769 - val_loss: 899.2301 - val_root_mean_squared_error: 29.9702\n",
            "Epoch 8/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 800.3696 - root_mean_squared_error: 28.2728 - val_loss: 904.8069 - val_root_mean_squared_error: 30.0631\n",
            "Epoch 9/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 794.2158 - root_mean_squared_error: 28.1637 - val_loss: 903.5930 - val_root_mean_squared_error: 30.0429\n",
            "Epoch 10/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 796.2510 - root_mean_squared_error: 28.1999 - val_loss: 904.9875 - val_root_mean_squared_error: 30.0661\n",
            "Epoch 11/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 795.3091 - root_mean_squared_error: 28.1831 - val_loss: 905.3334 - val_root_mean_squared_error: 30.0718\n",
            "Epoch 12/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 797.2709 - root_mean_squared_error: 28.2179 - val_loss: 905.7557 - val_root_mean_squared_error: 30.0788\n",
            "Epoch 13/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 794.3848 - root_mean_squared_error: 28.1667 - val_loss: 905.3044 - val_root_mean_squared_error: 30.0713\n",
            "Epoch 14/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 799.2784 - root_mean_squared_error: 28.2535 - val_loss: 904.9985 - val_root_mean_squared_error: 30.0662\n",
            "Epoch 15/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 788.7793 - root_mean_squared_error: 28.0671 - val_loss: 903.3844 - val_root_mean_squared_error: 30.0394\n",
            "Epoch 16/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 781.9850 - root_mean_squared_error: 27.9458 - val_loss: 902.5535 - val_root_mean_squared_error: 30.0256\n",
            "Epoch 17/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 796.1077 - root_mean_squared_error: 28.1973 - val_loss: 905.9366 - val_root_mean_squared_error: 30.0818\n",
            "Epoch 18/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 789.1006 - root_mean_squared_error: 28.0728 - val_loss: 904.4941 - val_root_mean_squared_error: 30.0578\n",
            "Epoch 19/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 791.2463 - root_mean_squared_error: 28.1110 - val_loss: 904.2988 - val_root_mean_squared_error: 30.0546\n",
            "Epoch 20/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 782.2909 - root_mean_squared_error: 27.9512 - val_loss: 904.0669 - val_root_mean_squared_error: 30.0507\n",
            "Epoch 21/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 793.3648 - root_mean_squared_error: 28.1486 - val_loss: 905.9744 - val_root_mean_squared_error: 30.0825\n",
            "Epoch 22/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 788.9483 - root_mean_squared_error: 28.0701 - val_loss: 906.6028 - val_root_mean_squared_error: 30.0929\n",
            "Epoch 23/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 784.3142 - root_mean_squared_error: 27.9874 - val_loss: 903.9865 - val_root_mean_squared_error: 30.0494\n",
            "Epoch 24/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 793.3292 - root_mean_squared_error: 28.1480 - val_loss: 904.6213 - val_root_mean_squared_error: 30.0600\n",
            "Epoch 25/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 783.9144 - root_mean_squared_error: 27.9803 - val_loss: 906.0825 - val_root_mean_squared_error: 30.0843\n",
            "Epoch 26/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 789.8252 - root_mean_squared_error: 28.0857 - val_loss: 904.6741 - val_root_mean_squared_error: 30.0608\n",
            "Epoch 27/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 789.1771 - root_mean_squared_error: 28.0741 - val_loss: 903.7208 - val_root_mean_squared_error: 30.0450\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "29.970178719800764\n",
            "Epoch 1/500\n",
            "288/288 [==============================] - 4s 7ms/step - loss: 1303.7458 - root_mean_squared_error: 36.0939 - val_loss: 1000.5612 - val_root_mean_squared_error: 31.6161\n",
            "Epoch 2/500\n",
            " 10/288 [>.............................] - ETA: 1s - loss: 951.6403 - root_mean_squared_error: 30.8320 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "288/288 [==============================] - 2s 7ms/step - loss: 966.7396 - root_mean_squared_error: 31.0762 - val_loss: 919.8818 - val_root_mean_squared_error: 30.3135\n",
            "Epoch 3/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 903.7537 - root_mean_squared_error: 30.0457 - val_loss: 922.8406 - val_root_mean_squared_error: 30.3619\n",
            "Epoch 4/500\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 847.1241 - root_mean_squared_error: 29.0880 - val_loss: 913.0953 - val_root_mean_squared_error: 30.2005\n",
            "Epoch 5/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 820.2964 - root_mean_squared_error: 28.6229 - val_loss: 919.4624 - val_root_mean_squared_error: 30.3058\n",
            "Epoch 6/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 827.4732 - root_mean_squared_error: 28.7481 - val_loss: 919.6181 - val_root_mean_squared_error: 30.3083\n",
            "Epoch 7/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 816.8185 - root_mean_squared_error: 28.5621 - val_loss: 916.8042 - val_root_mean_squared_error: 30.2619\n",
            "Epoch 8/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 812.1569 - root_mean_squared_error: 28.4804 - val_loss: 914.0159 - val_root_mean_squared_error: 30.2158\n",
            "Epoch 9/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 823.4589 - root_mean_squared_error: 28.6781 - val_loss: 915.3818 - val_root_mean_squared_error: 30.2384\n",
            "Epoch 10/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 812.7850 - root_mean_squared_error: 28.4914 - val_loss: 916.3035 - val_root_mean_squared_error: 30.2536\n",
            "Epoch 11/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 806.8619 - root_mean_squared_error: 28.3873 - val_loss: 910.5015 - val_root_mean_squared_error: 30.1576\n",
            "Epoch 12/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 806.9210 - root_mean_squared_error: 28.3883 - val_loss: 913.0897 - val_root_mean_squared_error: 30.2004\n",
            "Epoch 13/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 799.4997 - root_mean_squared_error: 28.2573 - val_loss: 915.9611 - val_root_mean_squared_error: 30.2479\n",
            "Epoch 14/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 809.1274 - root_mean_squared_error: 28.4272 - val_loss: 917.0051 - val_root_mean_squared_error: 30.2652\n",
            "Epoch 15/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 785.5672 - root_mean_squared_error: 28.0097 - val_loss: 914.6359 - val_root_mean_squared_error: 30.2260\n",
            "Epoch 16/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 803.7350 - root_mean_squared_error: 28.3322 - val_loss: 913.8204 - val_root_mean_squared_error: 30.2125\n",
            "Epoch 17/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 806.6614 - root_mean_squared_error: 28.3838 - val_loss: 915.8119 - val_root_mean_squared_error: 30.2455\n",
            "Epoch 18/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 808.1798 - root_mean_squared_error: 28.4105 - val_loss: 914.8447 - val_root_mean_squared_error: 30.2295\n",
            "Epoch 19/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 808.5809 - root_mean_squared_error: 28.4176 - val_loss: 915.2665 - val_root_mean_squared_error: 30.2365\n",
            "Epoch 20/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 792.2036 - root_mean_squared_error: 28.1279 - val_loss: 911.8889 - val_root_mean_squared_error: 30.1805\n",
            "Epoch 21/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 802.3987 - root_mean_squared_error: 28.3086 - val_loss: 913.4708 - val_root_mean_squared_error: 30.2067\n",
            "Epoch 22/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 798.6482 - root_mean_squared_error: 28.2423 - val_loss: 909.3944 - val_root_mean_squared_error: 30.1392\n",
            "Epoch 23/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 816.3177 - root_mean_squared_error: 28.5534 - val_loss: 916.9217 - val_root_mean_squared_error: 30.2638\n",
            "Epoch 24/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 785.7517 - root_mean_squared_error: 28.0130 - val_loss: 916.1442 - val_root_mean_squared_error: 30.2510\n",
            "Epoch 25/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 804.2265 - root_mean_squared_error: 28.3408 - val_loss: 916.3345 - val_root_mean_squared_error: 30.2541\n",
            "Epoch 26/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 799.2938 - root_mean_squared_error: 28.2537 - val_loss: 913.9437 - val_root_mean_squared_error: 30.2146\n",
            "Epoch 27/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 791.4467 - root_mean_squared_error: 28.1145 - val_loss: 914.9667 - val_root_mean_squared_error: 30.2315\n",
            "Epoch 28/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 796.6738 - root_mean_squared_error: 28.2073 - val_loss: 913.9222 - val_root_mean_squared_error: 30.2142\n",
            "Epoch 29/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 805.4586 - root_mean_squared_error: 28.3626 - val_loss: 915.2622 - val_root_mean_squared_error: 30.2364\n",
            "Epoch 30/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 801.3588 - root_mean_squared_error: 28.2902 - val_loss: 913.2166 - val_root_mean_squared_error: 30.2025\n",
            "Epoch 31/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 796.7436 - root_mean_squared_error: 28.2085 - val_loss: 915.0410 - val_root_mean_squared_error: 30.2327\n",
            "Epoch 32/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 804.1112 - root_mean_squared_error: 28.3388 - val_loss: 915.5896 - val_root_mean_squared_error: 30.2418\n",
            "Epoch 33/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 809.9422 - root_mean_squared_error: 28.4415 - val_loss: 915.8207 - val_root_mean_squared_error: 30.2456\n",
            "Epoch 34/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 806.1019 - root_mean_squared_error: 28.3739 - val_loss: 913.9066 - val_root_mean_squared_error: 30.2140\n",
            "Epoch 35/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 804.1745 - root_mean_squared_error: 28.3399 - val_loss: 912.6462 - val_root_mean_squared_error: 30.1931\n",
            "Epoch 36/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 812.2064 - root_mean_squared_error: 28.4813 - val_loss: 916.4974 - val_root_mean_squared_error: 30.2568\n",
            "Epoch 37/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 817.2561 - root_mean_squared_error: 28.5698 - val_loss: 916.6871 - val_root_mean_squared_error: 30.2599\n",
            "Epoch 38/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 809.9765 - root_mean_squared_error: 28.4421 - val_loss: 916.8508 - val_root_mean_squared_error: 30.2626\n",
            "Epoch 39/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 798.3187 - root_mean_squared_error: 28.2364 - val_loss: 913.7805 - val_root_mean_squared_error: 30.2119\n",
            "Epoch 40/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 815.1581 - root_mean_squared_error: 28.5330 - val_loss: 917.5246 - val_root_mean_squared_error: 30.2738\n",
            "Epoch 41/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 797.7219 - root_mean_squared_error: 28.2258 - val_loss: 916.4357 - val_root_mean_squared_error: 30.2558\n",
            "Epoch 42/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 810.1200 - root_mean_squared_error: 28.4446 - val_loss: 916.1552 - val_root_mean_squared_error: 30.2511\n",
            "8/8 [==============================] - 0s 3ms/step\n",
            "30.13919864310273\n",
            "Epoch 1/500\n",
            "288/288 [==============================] - 5s 7ms/step - loss: 1308.4362 - root_mean_squared_error: 36.1589 - val_loss: 1109.7206 - val_root_mean_squared_error: 33.2964\n",
            "Epoch 2/500\n",
            " 10/288 [>.............................] - ETA: 1s - loss: 912.3002 - root_mean_squared_error: 30.1871"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "288/288 [==============================] - 2s 7ms/step - loss: 955.3718 - root_mean_squared_error: 30.8926 - val_loss: 1061.3195 - val_root_mean_squared_error: 32.5622\n",
            "Epoch 3/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 889.2737 - root_mean_squared_error: 29.8035 - val_loss: 999.1924 - val_root_mean_squared_error: 31.5941\n",
            "Epoch 4/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 839.7041 - root_mean_squared_error: 28.9600 - val_loss: 980.6248 - val_root_mean_squared_error: 31.2984\n",
            "Epoch 5/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 801.2787 - root_mean_squared_error: 28.2886 - val_loss: 1018.1454 - val_root_mean_squared_error: 31.8922\n",
            "Epoch 6/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 796.2173 - root_mean_squared_error: 28.1990 - val_loss: 1011.8218 - val_root_mean_squared_error: 31.7929\n",
            "Epoch 7/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 782.4831 - root_mean_squared_error: 27.9544 - val_loss: 1019.4356 - val_root_mean_squared_error: 31.9124\n",
            "Epoch 8/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 777.0839 - root_mean_squared_error: 27.8576 - val_loss: 1023.7642 - val_root_mean_squared_error: 31.9801\n",
            "Epoch 9/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 776.2537 - root_mean_squared_error: 27.8427 - val_loss: 1016.0395 - val_root_mean_squared_error: 31.8591\n",
            "Epoch 10/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 778.7634 - root_mean_squared_error: 27.8877 - val_loss: 1026.2601 - val_root_mean_squared_error: 32.0191\n",
            "Epoch 11/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 777.7664 - root_mean_squared_error: 27.8698 - val_loss: 1022.1071 - val_root_mean_squared_error: 31.9542\n",
            "Epoch 12/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 774.5910 - root_mean_squared_error: 27.8128 - val_loss: 1020.4446 - val_root_mean_squared_error: 31.9281\n",
            "Epoch 13/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 771.4210 - root_mean_squared_error: 27.7558 - val_loss: 1023.4585 - val_root_mean_squared_error: 31.9753\n",
            "Epoch 14/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 773.7882 - root_mean_squared_error: 27.7984 - val_loss: 1025.0077 - val_root_mean_squared_error: 31.9995\n",
            "Epoch 15/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 779.6810 - root_mean_squared_error: 27.9042 - val_loss: 1022.6544 - val_root_mean_squared_error: 31.9627\n",
            "Epoch 16/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 772.2353 - root_mean_squared_error: 27.7704 - val_loss: 1023.9677 - val_root_mean_squared_error: 31.9833\n",
            "Epoch 17/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 756.4188 - root_mean_squared_error: 27.4842 - val_loss: 1017.6748 - val_root_mean_squared_error: 31.8847\n",
            "Epoch 18/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 785.5760 - root_mean_squared_error: 28.0096 - val_loss: 1021.6793 - val_root_mean_squared_error: 31.9475\n",
            "Epoch 19/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 785.9463 - root_mean_squared_error: 28.0162 - val_loss: 1023.3330 - val_root_mean_squared_error: 31.9733\n",
            "Epoch 20/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 784.7188 - root_mean_squared_error: 27.9943 - val_loss: 1019.9049 - val_root_mean_squared_error: 31.9197\n",
            "Epoch 21/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 782.9403 - root_mean_squared_error: 27.9625 - val_loss: 1022.6191 - val_root_mean_squared_error: 31.9622\n",
            "Epoch 22/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 762.8409 - root_mean_squared_error: 27.6008 - val_loss: 1022.7955 - val_root_mean_squared_error: 31.9649\n",
            "Epoch 23/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 780.8792 - root_mean_squared_error: 27.9256 - val_loss: 1025.2698 - val_root_mean_squared_error: 32.0036\n",
            "Epoch 24/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 785.6993 - root_mean_squared_error: 28.0118 - val_loss: 1024.5768 - val_root_mean_squared_error: 31.9928\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "31.298392243635735\n",
            "Epoch 1/500\n",
            "288/288 [==============================] - 4s 7ms/step - loss: 1314.8860 - root_mean_squared_error: 36.2482 - val_loss: 992.2254 - val_root_mean_squared_error: 31.4854\n",
            "Epoch 2/500\n",
            " 10/288 [>.............................] - ETA: 1s - loss: 953.9188 - root_mean_squared_error: 30.8707 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "288/288 [==============================] - 2s 6ms/step - loss: 961.2362 - root_mean_squared_error: 30.9879 - val_loss: 1029.1686 - val_root_mean_squared_error: 32.0661\n",
            "Epoch 3/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 903.2444 - root_mean_squared_error: 30.0376 - val_loss: 956.4465 - val_root_mean_squared_error: 30.9104\n",
            "Epoch 4/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 849.2034 - root_mean_squared_error: 29.1240 - val_loss: 876.8920 - val_root_mean_squared_error: 29.5956\n",
            "Epoch 5/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 814.9470 - root_mean_squared_error: 28.5298 - val_loss: 846.8148 - val_root_mean_squared_error: 29.0830\n",
            "Epoch 6/500\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 811.8124 - root_mean_squared_error: 28.4748 - val_loss: 827.9323 - val_root_mean_squared_error: 28.7565\n",
            "Epoch 7/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 820.2170 - root_mean_squared_error: 28.6220 - val_loss: 835.9838 - val_root_mean_squared_error: 28.8961\n",
            "Epoch 8/500\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 795.9887 - root_mean_squared_error: 28.1955 - val_loss: 827.6993 - val_root_mean_squared_error: 28.7524\n",
            "Epoch 9/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 790.7336 - root_mean_squared_error: 28.1022 - val_loss: 839.2292 - val_root_mean_squared_error: 28.9522\n",
            "Epoch 10/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 800.6605 - root_mean_squared_error: 28.2783 - val_loss: 833.1592 - val_root_mean_squared_error: 28.8472\n",
            "Epoch 11/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 806.5162 - root_mean_squared_error: 28.3816 - val_loss: 828.5008 - val_root_mean_squared_error: 28.7663\n",
            "Epoch 12/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 808.7945 - root_mean_squared_error: 28.4217 - val_loss: 833.1829 - val_root_mean_squared_error: 28.8476\n",
            "Epoch 13/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 794.3207 - root_mean_squared_error: 28.1660 - val_loss: 833.1162 - val_root_mean_squared_error: 28.8464\n",
            "Epoch 14/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 801.5385 - root_mean_squared_error: 28.2938 - val_loss: 837.6157 - val_root_mean_squared_error: 28.9243\n",
            "Epoch 15/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 792.3016 - root_mean_squared_error: 28.1301 - val_loss: 832.7201 - val_root_mean_squared_error: 28.8396\n",
            "Epoch 16/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 791.2681 - root_mean_squared_error: 28.1117 - val_loss: 828.8652 - val_root_mean_squared_error: 28.7727\n",
            "Epoch 17/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 793.2847 - root_mean_squared_error: 28.1476 - val_loss: 834.0518 - val_root_mean_squared_error: 28.8626\n",
            "Epoch 18/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 786.2722 - root_mean_squared_error: 28.0227 - val_loss: 827.5681 - val_root_mean_squared_error: 28.7501\n",
            "Epoch 19/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 790.4316 - root_mean_squared_error: 28.0968 - val_loss: 832.6940 - val_root_mean_squared_error: 28.8391\n",
            "Epoch 20/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 796.3907 - root_mean_squared_error: 28.2027 - val_loss: 836.2191 - val_root_mean_squared_error: 28.9002\n",
            "Epoch 21/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 784.9013 - root_mean_squared_error: 27.9982 - val_loss: 829.4221 - val_root_mean_squared_error: 28.7823\n",
            "Epoch 22/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 784.2718 - root_mean_squared_error: 27.9870 - val_loss: 832.7377 - val_root_mean_squared_error: 28.8399\n",
            "Epoch 23/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 801.0534 - root_mean_squared_error: 28.2852 - val_loss: 833.2130 - val_root_mean_squared_error: 28.8481\n",
            "Epoch 24/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 788.5309 - root_mean_squared_error: 28.0630 - val_loss: 834.3853 - val_root_mean_squared_error: 28.8684\n",
            "Epoch 25/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 797.1515 - root_mean_squared_error: 28.2162 - val_loss: 831.3657 - val_root_mean_squared_error: 28.8161\n",
            "Epoch 26/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 791.6654 - root_mean_squared_error: 28.1188 - val_loss: 831.7583 - val_root_mean_squared_error: 28.8229\n",
            "Epoch 27/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 798.3168 - root_mean_squared_error: 28.2368 - val_loss: 836.0112 - val_root_mean_squared_error: 28.8966\n",
            "Epoch 28/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 806.8857 - root_mean_squared_error: 28.3881 - val_loss: 829.5985 - val_root_mean_squared_error: 28.7854\n",
            "Epoch 29/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 791.8793 - root_mean_squared_error: 28.1226 - val_loss: 837.1180 - val_root_mean_squared_error: 28.9157\n",
            "Epoch 30/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 783.8569 - root_mean_squared_error: 27.9796 - val_loss: 831.6490 - val_root_mean_squared_error: 28.8210\n",
            "Epoch 31/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 796.0820 - root_mean_squared_error: 28.1972 - val_loss: 836.8658 - val_root_mean_squared_error: 28.9114\n",
            "Epoch 32/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 790.1242 - root_mean_squared_error: 28.0914 - val_loss: 832.8646 - val_root_mean_squared_error: 28.8421\n",
            "Epoch 33/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 800.4676 - root_mean_squared_error: 28.2749 - val_loss: 831.8171 - val_root_mean_squared_error: 28.8239\n",
            "Epoch 34/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 794.7908 - root_mean_squared_error: 28.1743 - val_loss: 834.5577 - val_root_mean_squared_error: 28.8714\n",
            "Epoch 35/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 793.0927 - root_mean_squared_error: 28.1441 - val_loss: 831.0439 - val_root_mean_squared_error: 28.8105\n",
            "Epoch 36/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 794.9244 - root_mean_squared_error: 28.1767 - val_loss: 831.3801 - val_root_mean_squared_error: 28.8163\n",
            "Epoch 37/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 796.5295 - root_mean_squared_error: 28.2051 - val_loss: 831.8938 - val_root_mean_squared_error: 28.8252\n",
            "Epoch 38/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 796.1506 - root_mean_squared_error: 28.1984 - val_loss: 831.4661 - val_root_mean_squared_error: 28.8178\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "28.750109234210367\n",
            "Epoch 1/500\n",
            "288/288 [==============================] - 4s 7ms/step - loss: 1287.2500 - root_mean_squared_error: 35.8649 - val_loss: 1071.0554 - val_root_mean_squared_error: 32.7123\n",
            "Epoch 2/500\n",
            " 10/288 [>.............................] - ETA: 1s - loss: 1000.2350 - root_mean_squared_error: 31.6114"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "288/288 [==============================] - 2s 6ms/step - loss: 960.3060 - root_mean_squared_error: 30.9729 - val_loss: 957.0281 - val_root_mean_squared_error: 30.9195\n",
            "Epoch 3/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 886.4269 - root_mean_squared_error: 29.7562 - val_loss: 973.0187 - val_root_mean_squared_error: 31.1775\n",
            "Epoch 4/500\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 841.0353 - root_mean_squared_error: 28.9834 - val_loss: 933.4893 - val_root_mean_squared_error: 30.5369\n",
            "Epoch 5/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 825.8965 - root_mean_squared_error: 28.7210 - val_loss: 937.1525 - val_root_mean_squared_error: 30.5967\n",
            "Epoch 6/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 805.6503 - root_mean_squared_error: 28.3664 - val_loss: 937.5900 - val_root_mean_squared_error: 30.6037\n",
            "Epoch 7/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 808.2153 - root_mean_squared_error: 28.4115 - val_loss: 944.1464 - val_root_mean_squared_error: 30.7106\n",
            "Epoch 8/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 809.0151 - root_mean_squared_error: 28.4255 - val_loss: 942.2083 - val_root_mean_squared_error: 30.6790\n",
            "Epoch 9/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 802.1238 - root_mean_squared_error: 28.3041 - val_loss: 944.5334 - val_root_mean_squared_error: 30.7169\n",
            "Epoch 10/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 790.1484 - root_mean_squared_error: 28.0917 - val_loss: 945.0464 - val_root_mean_squared_error: 30.7253\n",
            "Epoch 11/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 782.7334 - root_mean_squared_error: 27.9594 - val_loss: 946.0757 - val_root_mean_squared_error: 30.7420\n",
            "Epoch 12/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 796.5642 - root_mean_squared_error: 28.2057 - val_loss: 943.8064 - val_root_mean_squared_error: 30.7051\n",
            "Epoch 13/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 791.5328 - root_mean_squared_error: 28.1163 - val_loss: 945.2532 - val_root_mean_squared_error: 30.7286\n",
            "Epoch 14/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 797.4977 - root_mean_squared_error: 28.2222 - val_loss: 947.5196 - val_root_mean_squared_error: 30.7655\n",
            "Epoch 15/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 800.8089 - root_mean_squared_error: 28.2808 - val_loss: 944.5213 - val_root_mean_squared_error: 30.7167\n",
            "Epoch 16/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 798.3865 - root_mean_squared_error: 28.2379 - val_loss: 944.7253 - val_root_mean_squared_error: 30.7200\n",
            "Epoch 17/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 795.1827 - root_mean_squared_error: 28.1812 - val_loss: 944.3461 - val_root_mean_squared_error: 30.7139\n",
            "Epoch 18/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 797.2332 - root_mean_squared_error: 28.2175 - val_loss: 942.7970 - val_root_mean_squared_error: 30.6886\n",
            "Epoch 19/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 805.1505 - root_mean_squared_error: 28.3575 - val_loss: 948.7859 - val_root_mean_squared_error: 30.7861\n",
            "Epoch 20/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 798.3117 - root_mean_squared_error: 28.2366 - val_loss: 945.8829 - val_root_mean_squared_error: 30.7389\n",
            "Epoch 21/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 795.0853 - root_mean_squared_error: 28.1794 - val_loss: 944.7348 - val_root_mean_squared_error: 30.7202\n",
            "Epoch 22/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 790.9470 - root_mean_squared_error: 28.1059 - val_loss: 944.6787 - val_root_mean_squared_error: 30.7193\n",
            "Epoch 23/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 792.0771 - root_mean_squared_error: 28.1260 - val_loss: 945.9779 - val_root_mean_squared_error: 30.7404\n",
            "Epoch 24/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 810.9933 - root_mean_squared_error: 28.4603 - val_loss: 945.1439 - val_root_mean_squared_error: 30.7268\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "30.53687198212224\n",
            "Epoch 1/500\n",
            "288/288 [==============================] - 4s 7ms/step - loss: 1311.4471 - root_mean_squared_error: 36.2008 - val_loss: 965.7961 - val_root_mean_squared_error: 31.0618\n",
            "Epoch 2/500\n",
            " 10/288 [>.............................] - ETA: 1s - loss: 893.4153 - root_mean_squared_error: 29.8740 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "288/288 [==============================] - 2s 6ms/step - loss: 969.1851 - root_mean_squared_error: 31.1160 - val_loss: 891.5469 - val_root_mean_squared_error: 29.8429\n",
            "Epoch 3/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 876.8045 - root_mean_squared_error: 29.5944 - val_loss: 911.0483 - val_root_mean_squared_error: 30.1673\n",
            "Epoch 4/500\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 846.5980 - root_mean_squared_error: 29.0795 - val_loss: 881.5431 - val_root_mean_squared_error: 29.6742\n",
            "Epoch 5/500\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 822.2462 - root_mean_squared_error: 28.6577 - val_loss: 847.0067 - val_root_mean_squared_error: 29.0864\n",
            "Epoch 6/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 795.2241 - root_mean_squared_error: 28.1822 - val_loss: 860.2216 - val_root_mean_squared_error: 29.3127\n",
            "Epoch 7/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 791.7989 - root_mean_squared_error: 28.1214 - val_loss: 850.7232 - val_root_mean_squared_error: 29.1502\n",
            "Epoch 8/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 786.8156 - root_mean_squared_error: 28.0326 - val_loss: 847.6422 - val_root_mean_squared_error: 29.0973\n",
            "Epoch 9/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 782.9645 - root_mean_squared_error: 27.9638 - val_loss: 848.5405 - val_root_mean_squared_error: 29.1127\n",
            "Epoch 10/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 801.2332 - root_mean_squared_error: 28.2886 - val_loss: 849.2908 - val_root_mean_squared_error: 29.1256\n",
            "Epoch 11/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 790.6898 - root_mean_squared_error: 28.1016 - val_loss: 849.7792 - val_root_mean_squared_error: 29.1340\n",
            "Epoch 12/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 798.7930 - root_mean_squared_error: 28.2454 - val_loss: 847.8284 - val_root_mean_squared_error: 29.1005\n",
            "Epoch 13/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 787.5421 - root_mean_squared_error: 28.0455 - val_loss: 851.4501 - val_root_mean_squared_error: 29.1626\n",
            "Epoch 14/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 768.7117 - root_mean_squared_error: 27.7078 - val_loss: 850.0944 - val_root_mean_squared_error: 29.1394\n",
            "Epoch 15/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 785.6298 - root_mean_squared_error: 28.0114 - val_loss: 849.0969 - val_root_mean_squared_error: 29.1223\n",
            "Epoch 16/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 793.2176 - root_mean_squared_error: 28.1465 - val_loss: 849.9052 - val_root_mean_squared_error: 29.1361\n",
            "Epoch 17/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 788.4783 - root_mean_squared_error: 28.0622 - val_loss: 850.0933 - val_root_mean_squared_error: 29.1394\n",
            "Epoch 18/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 782.2049 - root_mean_squared_error: 27.9502 - val_loss: 849.6526 - val_root_mean_squared_error: 29.1318\n",
            "Epoch 19/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 787.2477 - root_mean_squared_error: 28.0403 - val_loss: 848.6502 - val_root_mean_squared_error: 29.1146\n",
            "Epoch 20/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 792.3654 - root_mean_squared_error: 28.1314 - val_loss: 849.9108 - val_root_mean_squared_error: 29.1362\n",
            "Epoch 21/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 788.5750 - root_mean_squared_error: 28.0639 - val_loss: 850.5715 - val_root_mean_squared_error: 29.1476\n",
            "Epoch 22/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 788.8377 - root_mean_squared_error: 28.0686 - val_loss: 851.4736 - val_root_mean_squared_error: 29.1631\n",
            "Epoch 23/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 782.1996 - root_mean_squared_error: 27.9501 - val_loss: 846.4594 - val_root_mean_squared_error: 29.0770\n",
            "Epoch 24/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 789.1147 - root_mean_squared_error: 28.0736 - val_loss: 850.9204 - val_root_mean_squared_error: 29.1536\n",
            "Epoch 25/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 791.4460 - root_mean_squared_error: 28.1150 - val_loss: 854.6426 - val_root_mean_squared_error: 29.2173\n",
            "Epoch 26/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 784.7242 - root_mean_squared_error: 27.9953 - val_loss: 851.5670 - val_root_mean_squared_error: 29.1647\n",
            "Epoch 27/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 781.2288 - root_mean_squared_error: 27.9327 - val_loss: 848.3140 - val_root_mean_squared_error: 29.1088\n",
            "Epoch 28/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 786.9426 - root_mean_squared_error: 28.0348 - val_loss: 849.5718 - val_root_mean_squared_error: 29.1304\n",
            "Epoch 29/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 791.9404 - root_mean_squared_error: 28.1238 - val_loss: 849.1601 - val_root_mean_squared_error: 29.1234\n",
            "Epoch 30/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 784.4588 - root_mean_squared_error: 27.9905 - val_loss: 850.5235 - val_root_mean_squared_error: 29.1468\n",
            "Epoch 31/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 785.8092 - root_mean_squared_error: 28.0146 - val_loss: 851.7176 - val_root_mean_squared_error: 29.1672\n",
            "Epoch 32/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 783.2678 - root_mean_squared_error: 27.9692 - val_loss: 847.8690 - val_root_mean_squared_error: 29.1012\n",
            "Epoch 33/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 773.8668 - root_mean_squared_error: 27.8007 - val_loss: 850.1176 - val_root_mean_squared_error: 29.1398\n",
            "Epoch 34/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 775.3118 - root_mean_squared_error: 27.8266 - val_loss: 850.0362 - val_root_mean_squared_error: 29.1384\n",
            "Epoch 35/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 787.9114 - root_mean_squared_error: 28.0521 - val_loss: 847.7349 - val_root_mean_squared_error: 29.0989\n",
            "Epoch 36/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 794.3825 - root_mean_squared_error: 28.1672 - val_loss: 852.1971 - val_root_mean_squared_error: 29.1755\n",
            "Epoch 37/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 792.3745 - root_mean_squared_error: 28.1316 - val_loss: 847.7239 - val_root_mean_squared_error: 29.0987\n",
            "Epoch 38/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 786.3720 - root_mean_squared_error: 28.0247 - val_loss: 851.3299 - val_root_mean_squared_error: 29.1606\n",
            "Epoch 39/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 786.5742 - root_mean_squared_error: 28.0283 - val_loss: 851.0652 - val_root_mean_squared_error: 29.1560\n",
            "Epoch 40/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 790.0242 - root_mean_squared_error: 28.0898 - val_loss: 849.8942 - val_root_mean_squared_error: 29.1360\n",
            "Epoch 41/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 768.1942 - root_mean_squared_error: 27.6985 - val_loss: 850.8085 - val_root_mean_squared_error: 29.1517\n",
            "Epoch 42/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 782.4016 - root_mean_squared_error: 27.9537 - val_loss: 851.1309 - val_root_mean_squared_error: 29.1572\n",
            "Epoch 43/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 786.0640 - root_mean_squared_error: 28.0192 - val_loss: 847.7646 - val_root_mean_squared_error: 29.0994\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "29.076957658306057\n",
            "Epoch 1/500\n",
            "288/288 [==============================] - 4s 8ms/step - loss: 1285.1943 - root_mean_squared_error: 35.8360 - val_loss: 989.5135 - val_root_mean_squared_error: 31.4393\n",
            "Epoch 2/500\n",
            "  9/288 [..............................] - ETA: 1s - loss: 1098.7964 - root_mean_squared_error: 33.1319"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "288/288 [==============================] - 2s 6ms/step - loss: 965.4373 - root_mean_squared_error: 31.0550 - val_loss: 1002.8621 - val_root_mean_squared_error: 31.6515\n",
            "Epoch 3/500\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 896.4118 - root_mean_squared_error: 29.9229 - val_loss: 956.5516 - val_root_mean_squared_error: 30.9116\n",
            "Epoch 4/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 866.3241 - root_mean_squared_error: 29.4159 - val_loss: 942.5939 - val_root_mean_squared_error: 30.6847\n",
            "Epoch 5/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 824.7061 - root_mean_squared_error: 28.6995 - val_loss: 915.5729 - val_root_mean_squared_error: 30.2413\n",
            "Epoch 6/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 818.3802 - root_mean_squared_error: 28.5892 - val_loss: 908.4505 - val_root_mean_squared_error: 30.1232\n",
            "Epoch 7/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 802.6996 - root_mean_squared_error: 28.3136 - val_loss: 912.5829 - val_root_mean_squared_error: 30.1917\n",
            "Epoch 8/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 809.6680 - root_mean_squared_error: 28.4363 - val_loss: 908.2629 - val_root_mean_squared_error: 30.1201\n",
            "Epoch 9/500\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 795.6577 - root_mean_squared_error: 28.1889 - val_loss: 907.7894 - val_root_mean_squared_error: 30.1122\n",
            "Epoch 10/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 791.7633 - root_mean_squared_error: 28.1197 - val_loss: 907.8290 - val_root_mean_squared_error: 30.1129\n",
            "Epoch 11/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 796.4622 - root_mean_squared_error: 28.2032 - val_loss: 908.7327 - val_root_mean_squared_error: 30.1279\n",
            "Epoch 12/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 811.6193 - root_mean_squared_error: 28.4706 - val_loss: 911.5167 - val_root_mean_squared_error: 30.1740\n",
            "Epoch 13/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 797.4968 - root_mean_squared_error: 28.2215 - val_loss: 908.6719 - val_root_mean_squared_error: 30.1269\n",
            "Epoch 14/500\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 800.8550 - root_mean_squared_error: 28.2809 - val_loss: 907.1819 - val_root_mean_squared_error: 30.1021\n",
            "Epoch 15/500\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 795.6368 - root_mean_squared_error: 28.1885 - val_loss: 906.5151 - val_root_mean_squared_error: 30.0910\n",
            "Epoch 16/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 797.9489 - root_mean_squared_error: 28.2295 - val_loss: 907.8381 - val_root_mean_squared_error: 30.1130\n",
            "Epoch 17/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 796.4490 - root_mean_squared_error: 28.2029 - val_loss: 906.1305 - val_root_mean_squared_error: 30.0847\n",
            "Epoch 18/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 803.9645 - root_mean_squared_error: 28.3359 - val_loss: 907.5953 - val_root_mean_squared_error: 30.1090\n",
            "Epoch 19/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 792.5777 - root_mean_squared_error: 28.1342 - val_loss: 905.9768 - val_root_mean_squared_error: 30.0821\n",
            "Epoch 20/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 797.2075 - root_mean_squared_error: 28.2164 - val_loss: 907.5894 - val_root_mean_squared_error: 30.1089\n",
            "Epoch 21/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 777.3838 - root_mean_squared_error: 27.8629 - val_loss: 909.0238 - val_root_mean_squared_error: 30.1327\n",
            "Epoch 22/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 799.2612 - root_mean_squared_error: 28.2527 - val_loss: 906.7922 - val_root_mean_squared_error: 30.0957\n",
            "Epoch 23/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 780.3663 - root_mean_squared_error: 27.9163 - val_loss: 908.0621 - val_root_mean_squared_error: 30.1167\n",
            "Epoch 24/500\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 790.0227 - root_mean_squared_error: 28.0888 - val_loss: 905.8267 - val_root_mean_squared_error: 30.0796\n",
            "Epoch 25/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 793.8600 - root_mean_squared_error: 28.1570 - val_loss: 907.4458 - val_root_mean_squared_error: 30.1065\n",
            "Epoch 26/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 807.2474 - root_mean_squared_error: 28.3937 - val_loss: 906.7599 - val_root_mean_squared_error: 30.0951\n",
            "Epoch 27/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 795.8104 - root_mean_squared_error: 28.1916 - val_loss: 905.8680 - val_root_mean_squared_error: 30.0803\n",
            "Epoch 28/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 803.8137 - root_mean_squared_error: 28.3332 - val_loss: 905.0583 - val_root_mean_squared_error: 30.0668\n",
            "Epoch 29/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 803.7477 - root_mean_squared_error: 28.3320 - val_loss: 906.3257 - val_root_mean_squared_error: 30.0879\n",
            "Epoch 30/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 816.2652 - root_mean_squared_error: 28.5521 - val_loss: 906.6631 - val_root_mean_squared_error: 30.0935\n",
            "Epoch 31/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 787.4125 - root_mean_squared_error: 28.0423 - val_loss: 907.7961 - val_root_mean_squared_error: 30.1123\n",
            "Epoch 32/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 805.0861 - root_mean_squared_error: 28.3556 - val_loss: 906.3718 - val_root_mean_squared_error: 30.0887\n",
            "Epoch 33/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 797.4973 - root_mean_squared_error: 28.2215 - val_loss: 906.5540 - val_root_mean_squared_error: 30.0917\n",
            "Epoch 34/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 812.6718 - root_mean_squared_error: 28.4891 - val_loss: 909.2513 - val_root_mean_squared_error: 30.1365\n",
            "Epoch 35/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 798.7576 - root_mean_squared_error: 28.2438 - val_loss: 905.9587 - val_root_mean_squared_error: 30.0818\n",
            "Epoch 36/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 794.6558 - root_mean_squared_error: 28.1711 - val_loss: 905.6961 - val_root_mean_squared_error: 30.0774\n",
            "Epoch 37/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 796.2045 - root_mean_squared_error: 28.1986 - val_loss: 905.0922 - val_root_mean_squared_error: 30.0674\n",
            "Epoch 38/500\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 796.1274 - root_mean_squared_error: 28.1972 - val_loss: 904.6720 - val_root_mean_squared_error: 30.0604\n",
            "Epoch 39/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 793.5196 - root_mean_squared_error: 28.1509 - val_loss: 909.2955 - val_root_mean_squared_error: 30.1372\n",
            "Epoch 40/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 788.4324 - root_mean_squared_error: 28.0605 - val_loss: 909.1207 - val_root_mean_squared_error: 30.1343\n",
            "Epoch 41/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 804.9874 - root_mean_squared_error: 28.3539 - val_loss: 907.6683 - val_root_mean_squared_error: 30.1102\n",
            "Epoch 42/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 799.3469 - root_mean_squared_error: 28.2543 - val_loss: 906.3032 - val_root_mean_squared_error: 30.0875\n",
            "Epoch 43/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 791.3083 - root_mean_squared_error: 28.1117 - val_loss: 906.4027 - val_root_mean_squared_error: 30.0892\n",
            "Epoch 44/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 795.1942 - root_mean_squared_error: 28.1807 - val_loss: 905.9892 - val_root_mean_squared_error: 30.0823\n",
            "Epoch 45/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 792.4038 - root_mean_squared_error: 28.1311 - val_loss: 906.3482 - val_root_mean_squared_error: 30.0883\n",
            "Epoch 46/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 782.3221 - root_mean_squared_error: 27.9514 - val_loss: 906.0460 - val_root_mean_squared_error: 30.0833\n",
            "Epoch 47/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 791.0240 - root_mean_squared_error: 28.1066 - val_loss: 907.3838 - val_root_mean_squared_error: 30.1055\n",
            "Epoch 48/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 802.7186 - root_mean_squared_error: 28.3139 - val_loss: 908.1056 - val_root_mean_squared_error: 30.1175\n",
            "Epoch 49/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 793.3382 - root_mean_squared_error: 28.1477 - val_loss: 905.2823 - val_root_mean_squared_error: 30.0706\n",
            "Epoch 50/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 783.8301 - root_mean_squared_error: 27.9783 - val_loss: 907.3994 - val_root_mean_squared_error: 30.1057\n",
            "Epoch 51/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 795.8408 - root_mean_squared_error: 28.1921 - val_loss: 907.5622 - val_root_mean_squared_error: 30.1084\n",
            "Epoch 52/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 798.8094 - root_mean_squared_error: 28.2448 - val_loss: 907.5349 - val_root_mean_squared_error: 30.1080\n",
            "Epoch 53/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 793.1809 - root_mean_squared_error: 28.1449 - val_loss: 907.2192 - val_root_mean_squared_error: 30.1027\n",
            "Epoch 54/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 786.9923 - root_mean_squared_error: 28.0348 - val_loss: 906.1370 - val_root_mean_squared_error: 30.0848\n",
            "Epoch 55/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 797.6242 - root_mean_squared_error: 28.2238 - val_loss: 909.6888 - val_root_mean_squared_error: 30.1437\n",
            "Epoch 56/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 789.7115 - root_mean_squared_error: 28.0832 - val_loss: 906.6021 - val_root_mean_squared_error: 30.0925\n",
            "Epoch 57/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 801.4089 - root_mean_squared_error: 28.2907 - val_loss: 906.9611 - val_root_mean_squared_error: 30.0985\n",
            "Epoch 58/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 797.3218 - root_mean_squared_error: 28.2184 - val_loss: 905.1330 - val_root_mean_squared_error: 30.0681\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "30.060411995100246\n",
            "Epoch 1/500\n",
            "288/288 [==============================] - 4s 7ms/step - loss: 1301.0879 - root_mean_squared_error: 36.0573 - val_loss: 1085.5717 - val_root_mean_squared_error: 32.9324\n",
            "Epoch 2/500\n",
            " 10/288 [>.............................] - ETA: 1s - loss: 1098.3137 - root_mean_squared_error: 33.1253"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "288/288 [==============================] - 2s 7ms/step - loss: 956.7711 - root_mean_squared_error: 30.9156 - val_loss: 902.6723 - val_root_mean_squared_error: 30.0278\n",
            "Epoch 3/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 881.4215 - root_mean_squared_error: 29.6719 - val_loss: 930.0016 - val_root_mean_squared_error: 30.4794\n",
            "Epoch 4/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 854.9504 - root_mean_squared_error: 29.2224 - val_loss: 910.9744 - val_root_mean_squared_error: 30.1658\n",
            "Epoch 5/500\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 817.1995 - root_mean_squared_error: 28.5691 - val_loss: 896.1577 - val_root_mean_squared_error: 29.9191\n",
            "Epoch 6/500\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 801.8460 - root_mean_squared_error: 28.2990 - val_loss: 887.8214 - val_root_mean_squared_error: 29.7794\n",
            "Epoch 7/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 790.9158 - root_mean_squared_error: 28.1053 - val_loss: 892.7686 - val_root_mean_squared_error: 29.8624\n",
            "Epoch 8/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 805.9922 - root_mean_squared_error: 28.3722 - val_loss: 892.6277 - val_root_mean_squared_error: 29.8600\n",
            "Epoch 9/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 797.0273 - root_mean_squared_error: 28.2138 - val_loss: 891.3548 - val_root_mean_squared_error: 29.8387\n",
            "Epoch 10/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 783.9612 - root_mean_squared_error: 27.9813 - val_loss: 893.7903 - val_root_mean_squared_error: 29.8795\n",
            "Epoch 11/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 780.5844 - root_mean_squared_error: 27.9209 - val_loss: 895.4641 - val_root_mean_squared_error: 29.9075\n",
            "Epoch 12/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 788.7888 - root_mean_squared_error: 28.0674 - val_loss: 890.6630 - val_root_mean_squared_error: 29.8271\n",
            "Epoch 13/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 801.6669 - root_mean_squared_error: 28.2959 - val_loss: 892.3046 - val_root_mean_squared_error: 29.8546\n",
            "Epoch 14/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 798.9079 - root_mean_squared_error: 28.2471 - val_loss: 892.6250 - val_root_mean_squared_error: 29.8599\n",
            "Epoch 15/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 801.0863 - root_mean_squared_error: 28.2856 - val_loss: 892.8636 - val_root_mean_squared_error: 29.8639\n",
            "Epoch 16/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 807.5137 - root_mean_squared_error: 28.3991 - val_loss: 894.1611 - val_root_mean_squared_error: 29.8857\n",
            "Epoch 17/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 785.6016 - root_mean_squared_error: 28.0106 - val_loss: 893.2646 - val_root_mean_squared_error: 29.8707\n",
            "Epoch 18/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 799.0847 - root_mean_squared_error: 28.2502 - val_loss: 891.9699 - val_root_mean_squared_error: 29.8490\n",
            "Epoch 19/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 782.2453 - root_mean_squared_error: 27.9506 - val_loss: 891.4269 - val_root_mean_squared_error: 29.8399\n",
            "Epoch 20/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 777.1804 - root_mean_squared_error: 27.8599 - val_loss: 894.8134 - val_root_mean_squared_error: 29.8966\n",
            "Epoch 21/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 771.7901 - root_mean_squared_error: 27.7630 - val_loss: 892.2483 - val_root_mean_squared_error: 29.8536\n",
            "Epoch 22/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 785.4291 - root_mean_squared_error: 28.0075 - val_loss: 892.2410 - val_root_mean_squared_error: 29.8535\n",
            "Epoch 23/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 798.1998 - root_mean_squared_error: 28.2346 - val_loss: 891.5336 - val_root_mean_squared_error: 29.8417\n",
            "Epoch 24/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 792.3658 - root_mean_squared_error: 28.1311 - val_loss: 892.5968 - val_root_mean_squared_error: 29.8595\n",
            "Epoch 25/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 788.9129 - root_mean_squared_error: 28.0696 - val_loss: 891.3955 - val_root_mean_squared_error: 29.8394\n",
            "Epoch 26/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 768.5545 - root_mean_squared_error: 27.7046 - val_loss: 892.0099 - val_root_mean_squared_error: 29.8496\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "29.779439066325843\n",
            "Epoch 1/500\n",
            "288/288 [==============================] - 4s 7ms/step - loss: 1288.1069 - root_mean_squared_error: 35.8766 - val_loss: 1041.3986 - val_root_mean_squared_error: 32.2554\n",
            "Epoch 2/500\n",
            " 10/288 [>.............................] - ETA: 1s - loss: 1030.2445 - root_mean_squared_error: 32.0815"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "288/288 [==============================] - 2s 7ms/step - loss: 963.1136 - root_mean_squared_error: 31.0176 - val_loss: 1004.6630 - val_root_mean_squared_error: 31.6803\n",
            "Epoch 3/500\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 882.3705 - root_mean_squared_error: 29.6875 - val_loss: 993.2209 - val_root_mean_squared_error: 31.4987\n",
            "Epoch 4/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 845.2192 - root_mean_squared_error: 29.0549 - val_loss: 959.8495 - val_root_mean_squared_error: 30.9649\n",
            "Epoch 5/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 811.9214 - root_mean_squared_error: 28.4762 - val_loss: 953.1473 - val_root_mean_squared_error: 30.8563\n",
            "Epoch 6/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 810.3391 - root_mean_squared_error: 28.4482 - val_loss: 952.9155 - val_root_mean_squared_error: 30.8526\n",
            "Epoch 7/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 800.7740 - root_mean_squared_error: 28.2796 - val_loss: 962.6016 - val_root_mean_squared_error: 31.0091\n",
            "Epoch 8/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 791.6173 - root_mean_squared_error: 28.1173 - val_loss: 965.5681 - val_root_mean_squared_error: 31.0569\n",
            "Epoch 9/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 796.3355 - root_mean_squared_error: 28.2010 - val_loss: 967.9806 - val_root_mean_squared_error: 31.0957\n",
            "Epoch 10/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 793.6223 - root_mean_squared_error: 28.1529 - val_loss: 967.3431 - val_root_mean_squared_error: 31.0855\n",
            "Epoch 11/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 792.0380 - root_mean_squared_error: 28.1247 - val_loss: 969.8300 - val_root_mean_squared_error: 31.1254\n",
            "Epoch 12/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 802.9526 - root_mean_squared_error: 28.3181 - val_loss: 969.7994 - val_root_mean_squared_error: 31.1250\n",
            "Epoch 13/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 785.0757 - root_mean_squared_error: 28.0007 - val_loss: 968.1521 - val_root_mean_squared_error: 31.0985\n",
            "Epoch 14/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 796.0327 - root_mean_squared_error: 28.1957 - val_loss: 968.2728 - val_root_mean_squared_error: 31.1004\n",
            "Epoch 15/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 791.5760 - root_mean_squared_error: 28.1165 - val_loss: 969.3981 - val_root_mean_squared_error: 31.1185\n",
            "Epoch 16/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 781.2271 - root_mean_squared_error: 27.9319 - val_loss: 967.5850 - val_root_mean_squared_error: 31.0894\n",
            "Epoch 17/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 791.6180 - root_mean_squared_error: 28.1173 - val_loss: 969.9933 - val_root_mean_squared_error: 31.1281\n",
            "Epoch 18/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 784.3986 - root_mean_squared_error: 27.9886 - val_loss: 971.7852 - val_root_mean_squared_error: 31.1568\n",
            "Epoch 19/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 786.8799 - root_mean_squared_error: 28.0329 - val_loss: 967.1235 - val_root_mean_squared_error: 31.0819\n",
            "Epoch 20/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 791.2682 - root_mean_squared_error: 28.1111 - val_loss: 970.0759 - val_root_mean_squared_error: 31.1294\n",
            "Epoch 21/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 784.0977 - root_mean_squared_error: 27.9832 - val_loss: 972.3396 - val_root_mean_squared_error: 31.1657\n",
            "Epoch 22/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 779.3874 - root_mean_squared_error: 27.8989 - val_loss: 968.1790 - val_root_mean_squared_error: 31.0989\n",
            "Epoch 23/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 784.2188 - root_mean_squared_error: 27.9854 - val_loss: 967.3295 - val_root_mean_squared_error: 31.0853\n",
            "Epoch 24/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 790.9244 - root_mean_squared_error: 28.1049 - val_loss: 966.4860 - val_root_mean_squared_error: 31.0717\n",
            "Epoch 25/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 795.1276 - root_mean_squared_error: 28.1796 - val_loss: 969.8422 - val_root_mean_squared_error: 31.1256\n",
            "Epoch 26/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 800.6574 - root_mean_squared_error: 28.2776 - val_loss: 975.4316 - val_root_mean_squared_error: 31.2153\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "30.85257290552741\n",
            "Epoch 1/500\n",
            "288/288 [==============================] - 4s 7ms/step - loss: 1296.6875 - root_mean_squared_error: 35.9960 - val_loss: 937.9646 - val_root_mean_squared_error: 30.6094\n",
            "Epoch 2/500\n",
            " 10/288 [>.............................] - ETA: 1s - loss: 987.9124 - root_mean_squared_error: 31.4147 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "288/288 [==============================] - 2s 6ms/step - loss: 960.6802 - root_mean_squared_error: 30.9787 - val_loss: 1010.4856 - val_root_mean_squared_error: 31.7728\n",
            "Epoch 3/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 896.6551 - root_mean_squared_error: 29.9275 - val_loss: 890.1312 - val_root_mean_squared_error: 29.8180\n",
            "Epoch 4/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 847.8170 - root_mean_squared_error: 29.0999 - val_loss: 898.4210 - val_root_mean_squared_error: 29.9566\n",
            "Epoch 5/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 829.1777 - root_mean_squared_error: 28.7778 - val_loss: 880.3607 - val_root_mean_squared_error: 29.6536\n",
            "Epoch 6/500\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 818.4329 - root_mean_squared_error: 28.5904 - val_loss: 868.4538 - val_root_mean_squared_error: 29.4522\n",
            "Epoch 7/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 795.9555 - root_mean_squared_error: 28.1946 - val_loss: 879.7989 - val_root_mean_squared_error: 29.6442\n",
            "Epoch 8/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 804.1358 - root_mean_squared_error: 28.3393 - val_loss: 870.8193 - val_root_mean_squared_error: 29.4923\n",
            "Epoch 9/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 807.3351 - root_mean_squared_error: 28.3957 - val_loss: 873.1731 - val_root_mean_squared_error: 29.5322\n",
            "Epoch 10/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 801.3805 - root_mean_squared_error: 28.2906 - val_loss: 871.6873 - val_root_mean_squared_error: 29.5070\n",
            "Epoch 11/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 791.0270 - root_mean_squared_error: 28.1070 - val_loss: 879.8221 - val_root_mean_squared_error: 29.6446\n",
            "Epoch 12/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 802.8254 - root_mean_squared_error: 28.3161 - val_loss: 876.9021 - val_root_mean_squared_error: 29.5953\n",
            "Epoch 13/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 798.9598 - root_mean_squared_error: 28.2478 - val_loss: 875.7440 - val_root_mean_squared_error: 29.5757\n",
            "Epoch 14/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 794.0703 - root_mean_squared_error: 28.1611 - val_loss: 877.7457 - val_root_mean_squared_error: 29.6095\n",
            "Epoch 15/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 810.2953 - root_mean_squared_error: 28.4477 - val_loss: 877.4118 - val_root_mean_squared_error: 29.6039\n",
            "Epoch 16/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 810.5095 - root_mean_squared_error: 28.4515 - val_loss: 874.4689 - val_root_mean_squared_error: 29.5541\n",
            "Epoch 17/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 807.7148 - root_mean_squared_error: 28.4023 - val_loss: 872.2264 - val_root_mean_squared_error: 29.5162\n",
            "Epoch 18/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 800.9880 - root_mean_squared_error: 28.2837 - val_loss: 877.7174 - val_root_mean_squared_error: 29.6090\n",
            "Epoch 19/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 805.7390 - root_mean_squared_error: 28.3675 - val_loss: 877.9852 - val_root_mean_squared_error: 29.6136\n",
            "Epoch 20/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 791.8220 - root_mean_squared_error: 28.1212 - val_loss: 874.4910 - val_root_mean_squared_error: 29.5545\n",
            "Epoch 21/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 804.1558 - root_mean_squared_error: 28.3396 - val_loss: 873.7010 - val_root_mean_squared_error: 29.5411\n",
            "Epoch 22/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 796.7896 - root_mean_squared_error: 28.2094 - val_loss: 873.8377 - val_root_mean_squared_error: 29.5435\n",
            "Epoch 23/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 807.1628 - root_mean_squared_error: 28.3926 - val_loss: 875.1779 - val_root_mean_squared_error: 29.5661\n",
            "Epoch 24/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 789.9321 - root_mean_squared_error: 28.0875 - val_loss: 876.8749 - val_root_mean_squared_error: 29.5948\n",
            "Epoch 25/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 798.5985 - root_mean_squared_error: 28.2414 - val_loss: 877.6196 - val_root_mean_squared_error: 29.6074\n",
            "Epoch 26/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 801.5926 - root_mean_squared_error: 28.2944 - val_loss: 874.0300 - val_root_mean_squared_error: 29.5467\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "29.452213995696855\n",
            "Epoch 1/500\n",
            "288/288 [==============================] - 4s 7ms/step - loss: 1293.7379 - root_mean_squared_error: 35.9549 - val_loss: 1127.6990 - val_root_mean_squared_error: 33.5659\n",
            "Epoch 2/500\n",
            " 10/288 [>.............................] - ETA: 1s - loss: 906.2965 - root_mean_squared_error: 30.0873 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "288/288 [==============================] - 2s 6ms/step - loss: 964.3829 - root_mean_squared_error: 31.0383 - val_loss: 1056.6051 - val_root_mean_squared_error: 32.4906\n",
            "Epoch 3/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 884.3466 - root_mean_squared_error: 29.7211 - val_loss: 952.8310 - val_root_mean_squared_error: 30.8521\n",
            "Epoch 4/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 852.1960 - root_mean_squared_error: 29.1753 - val_loss: 913.8705 - val_root_mean_squared_error: 30.2135\n",
            "Epoch 5/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 822.9369 - root_mean_squared_error: 28.6692 - val_loss: 926.8194 - val_root_mean_squared_error: 30.4273\n",
            "Epoch 6/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 793.8479 - root_mean_squared_error: 28.1574 - val_loss: 931.6790 - val_root_mean_squared_error: 30.5069\n",
            "Epoch 7/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 787.1792 - root_mean_squared_error: 28.0387 - val_loss: 928.2122 - val_root_mean_squared_error: 30.4500\n",
            "Epoch 8/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 790.6860 - root_mean_squared_error: 28.1012 - val_loss: 928.7911 - val_root_mean_squared_error: 30.4595\n",
            "Epoch 9/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 791.1000 - root_mean_squared_error: 28.1085 - val_loss: 928.5396 - val_root_mean_squared_error: 30.4554\n",
            "Epoch 10/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 790.6411 - root_mean_squared_error: 28.1004 - val_loss: 926.0659 - val_root_mean_squared_error: 30.4147\n",
            "Epoch 11/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 799.7225 - root_mean_squared_error: 28.2615 - val_loss: 924.2161 - val_root_mean_squared_error: 30.3843\n",
            "Epoch 12/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 792.6354 - root_mean_squared_error: 28.1358 - val_loss: 926.6429 - val_root_mean_squared_error: 30.4242\n",
            "Epoch 13/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 788.7285 - root_mean_squared_error: 28.0663 - val_loss: 930.8602 - val_root_mean_squared_error: 30.4934\n",
            "Epoch 14/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 790.1729 - root_mean_squared_error: 28.0920 - val_loss: 927.0250 - val_root_mean_squared_error: 30.4305\n",
            "Epoch 15/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 793.4984 - root_mean_squared_error: 28.1512 - val_loss: 926.9308 - val_root_mean_squared_error: 30.4289\n",
            "Epoch 16/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 780.0882 - root_mean_squared_error: 27.9120 - val_loss: 930.4687 - val_root_mean_squared_error: 30.4870\n",
            "Epoch 17/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 777.3314 - root_mean_squared_error: 27.8625 - val_loss: 927.4330 - val_root_mean_squared_error: 30.4372\n",
            "Epoch 18/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 770.1385 - root_mean_squared_error: 27.7331 - val_loss: 921.8467 - val_root_mean_squared_error: 30.3453\n",
            "Epoch 19/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 777.1808 - root_mean_squared_error: 27.8598 - val_loss: 927.1058 - val_root_mean_squared_error: 30.4318\n",
            "Epoch 20/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 784.7625 - root_mean_squared_error: 27.9956 - val_loss: 930.0830 - val_root_mean_squared_error: 30.4807\n",
            "Epoch 21/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 771.9058 - root_mean_squared_error: 27.7650 - val_loss: 930.1107 - val_root_mean_squared_error: 30.4811\n",
            "Epoch 22/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 779.4882 - root_mean_squared_error: 27.9012 - val_loss: 928.0717 - val_root_mean_squared_error: 30.4477\n",
            "Epoch 23/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 788.0904 - root_mean_squared_error: 28.0549 - val_loss: 928.6213 - val_root_mean_squared_error: 30.4567\n",
            "Epoch 24/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 796.9554 - root_mean_squared_error: 28.2125 - val_loss: 932.2197 - val_root_mean_squared_error: 30.5157\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "30.213517521428653\n",
            "Epoch 1/500\n",
            "288/288 [==============================] - 4s 7ms/step - loss: 1310.2781 - root_mean_squared_error: 36.1849 - val_loss: 985.9622 - val_root_mean_squared_error: 31.3853\n",
            "Epoch 2/500\n",
            " 10/288 [>.............................] - ETA: 1s - loss: 916.4401 - root_mean_squared_error: 30.2573"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "288/288 [==============================] - 2s 6ms/step - loss: 972.0267 - root_mean_squared_error: 31.1620 - val_loss: 911.6661 - val_root_mean_squared_error: 30.1779\n",
            "Epoch 3/500\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 891.3514 - root_mean_squared_error: 29.8394 - val_loss: 861.9135 - val_root_mean_squared_error: 29.3420\n",
            "Epoch 4/500\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 861.6165 - root_mean_squared_error: 29.3369 - val_loss: 836.9279 - val_root_mean_squared_error: 28.9131\n",
            "Epoch 5/500\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 828.5438 - root_mean_squared_error: 28.7678 - val_loss: 834.3096 - val_root_mean_squared_error: 28.8676\n",
            "Epoch 6/500\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 804.4935 - root_mean_squared_error: 28.3464 - val_loss: 823.2169 - val_root_mean_squared_error: 28.6748\n",
            "Epoch 7/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 803.4180 - root_mean_squared_error: 28.3275 - val_loss: 825.1581 - val_root_mean_squared_error: 28.7087\n",
            "Epoch 8/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 796.8590 - root_mean_squared_error: 28.2115 - val_loss: 823.6587 - val_root_mean_squared_error: 28.6825\n",
            "Epoch 9/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 808.0966 - root_mean_squared_error: 28.4099 - val_loss: 823.5986 - val_root_mean_squared_error: 28.6815\n",
            "Epoch 10/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 798.2292 - root_mean_squared_error: 28.2358 - val_loss: 824.3825 - val_root_mean_squared_error: 28.6951\n",
            "Epoch 11/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 792.6039 - root_mean_squared_error: 28.1360 - val_loss: 824.7095 - val_root_mean_squared_error: 28.7008\n",
            "Epoch 12/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 799.1983 - root_mean_squared_error: 28.2529 - val_loss: 823.8307 - val_root_mean_squared_error: 28.6855\n",
            "Epoch 13/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 804.0092 - root_mean_squared_error: 28.3379 - val_loss: 825.0077 - val_root_mean_squared_error: 28.7060\n",
            "Epoch 14/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 802.7674 - root_mean_squared_error: 28.3160 - val_loss: 825.2045 - val_root_mean_squared_error: 28.7095\n",
            "Epoch 15/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 807.5911 - root_mean_squared_error: 28.4011 - val_loss: 824.8615 - val_root_mean_squared_error: 28.7035\n",
            "Epoch 16/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 803.7171 - root_mean_squared_error: 28.3328 - val_loss: 825.2291 - val_root_mean_squared_error: 28.7099\n",
            "Epoch 17/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 796.2350 - root_mean_squared_error: 28.2004 - val_loss: 823.7218 - val_root_mean_squared_error: 28.6836\n",
            "Epoch 18/500\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 794.9916 - root_mean_squared_error: 28.1784 - val_loss: 823.0772 - val_root_mean_squared_error: 28.6724\n",
            "Epoch 19/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 795.0966 - root_mean_squared_error: 28.1802 - val_loss: 823.8813 - val_root_mean_squared_error: 28.6864\n",
            "Epoch 20/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 807.3108 - root_mean_squared_error: 28.3961 - val_loss: 825.1107 - val_root_mean_squared_error: 28.7078\n",
            "Epoch 21/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 797.3677 - root_mean_squared_error: 28.2205 - val_loss: 824.6085 - val_root_mean_squared_error: 28.6991\n",
            "Epoch 22/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 803.9839 - root_mean_squared_error: 28.3375 - val_loss: 824.7073 - val_root_mean_squared_error: 28.7008\n",
            "Epoch 23/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 783.4308 - root_mean_squared_error: 27.9725 - val_loss: 824.8691 - val_root_mean_squared_error: 28.7036\n",
            "Epoch 24/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 799.0488 - root_mean_squared_error: 28.2503 - val_loss: 822.5571 - val_root_mean_squared_error: 28.6633\n",
            "Epoch 25/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 799.5549 - root_mean_squared_error: 28.2592 - val_loss: 824.0189 - val_root_mean_squared_error: 28.6888\n",
            "Epoch 26/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 794.9465 - root_mean_squared_error: 28.1776 - val_loss: 825.2591 - val_root_mean_squared_error: 28.7104\n",
            "Epoch 27/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 801.7852 - root_mean_squared_error: 28.2987 - val_loss: 823.6509 - val_root_mean_squared_error: 28.6824\n",
            "Epoch 28/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 813.4518 - root_mean_squared_error: 28.5041 - val_loss: 823.6003 - val_root_mean_squared_error: 28.6815\n",
            "Epoch 29/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 787.9279 - root_mean_squared_error: 28.0527 - val_loss: 824.5839 - val_root_mean_squared_error: 28.6987\n",
            "Epoch 30/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 796.3906 - root_mean_squared_error: 28.2032 - val_loss: 823.9274 - val_root_mean_squared_error: 28.6872\n",
            "Epoch 31/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 801.9011 - root_mean_squared_error: 28.3007 - val_loss: 824.2745 - val_root_mean_squared_error: 28.6933\n",
            "Epoch 32/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 802.7286 - root_mean_squared_error: 28.3153 - val_loss: 823.8917 - val_root_mean_squared_error: 28.6866\n",
            "Epoch 33/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 796.8460 - root_mean_squared_error: 28.2112 - val_loss: 826.5848 - val_root_mean_squared_error: 28.7335\n",
            "Epoch 34/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 804.3876 - root_mean_squared_error: 28.3446 - val_loss: 824.7407 - val_root_mean_squared_error: 28.7014\n",
            "Epoch 35/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 788.8419 - root_mean_squared_error: 28.0690 - val_loss: 824.2998 - val_root_mean_squared_error: 28.6937\n",
            "Epoch 36/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 787.8323 - root_mean_squared_error: 28.0510 - val_loss: 823.8735 - val_root_mean_squared_error: 28.6863\n",
            "Epoch 37/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 799.2245 - root_mean_squared_error: 28.2534 - val_loss: 824.3615 - val_root_mean_squared_error: 28.6948\n",
            "Epoch 38/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 796.2709 - root_mean_squared_error: 28.2011 - val_loss: 821.5952 - val_root_mean_squared_error: 28.6465\n",
            "Epoch 39/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 788.5521 - root_mean_squared_error: 28.0639 - val_loss: 824.9211 - val_root_mean_squared_error: 28.7045\n",
            "Epoch 40/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 794.3692 - root_mean_squared_error: 28.1673 - val_loss: 824.8505 - val_root_mean_squared_error: 28.7033\n",
            "Epoch 41/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 804.5503 - root_mean_squared_error: 28.3475 - val_loss: 824.0258 - val_root_mean_squared_error: 28.6889\n",
            "Epoch 42/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 793.4033 - root_mean_squared_error: 28.1502 - val_loss: 825.2350 - val_root_mean_squared_error: 28.7100\n",
            "Epoch 43/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 801.2104 - root_mean_squared_error: 28.2885 - val_loss: 825.9005 - val_root_mean_squared_error: 28.7216\n",
            "Epoch 44/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 802.8451 - root_mean_squared_error: 28.3174 - val_loss: 823.5779 - val_root_mean_squared_error: 28.6811\n",
            "Epoch 45/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 787.3810 - root_mean_squared_error: 28.0430 - val_loss: 823.3892 - val_root_mean_squared_error: 28.6778\n",
            "Epoch 46/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 804.5566 - root_mean_squared_error: 28.3476 - val_loss: 824.3286 - val_root_mean_squared_error: 28.6942\n",
            "Epoch 47/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 787.1544 - root_mean_squared_error: 28.0390 - val_loss: 822.9967 - val_root_mean_squared_error: 28.6710\n",
            "Epoch 48/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 792.2582 - root_mean_squared_error: 28.1298 - val_loss: 824.5004 - val_root_mean_squared_error: 28.6972\n",
            "Epoch 49/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 790.3013 - root_mean_squared_error: 28.0950 - val_loss: 824.1410 - val_root_mean_squared_error: 28.6909\n",
            "Epoch 50/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 796.9764 - root_mean_squared_error: 28.2136 - val_loss: 824.4579 - val_root_mean_squared_error: 28.6965\n",
            "Epoch 51/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 796.4843 - root_mean_squared_error: 28.2048 - val_loss: 824.7057 - val_root_mean_squared_error: 28.7008\n",
            "Epoch 52/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 785.6793 - root_mean_squared_error: 28.0126 - val_loss: 824.0161 - val_root_mean_squared_error: 28.6888\n",
            "Epoch 53/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 788.2481 - root_mean_squared_error: 28.0585 - val_loss: 823.2933 - val_root_mean_squared_error: 28.6762\n",
            "Epoch 54/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 784.2304 - root_mean_squared_error: 27.9868 - val_loss: 824.3279 - val_root_mean_squared_error: 28.6942\n",
            "Epoch 55/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 799.1463 - root_mean_squared_error: 28.2520 - val_loss: 825.0948 - val_root_mean_squared_error: 28.7076\n",
            "Epoch 56/500\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 798.8895 - root_mean_squared_error: 28.2474 - val_loss: 824.2048 - val_root_mean_squared_error: 28.6920\n",
            "Epoch 57/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 811.4211 - root_mean_squared_error: 28.4684 - val_loss: 824.0940 - val_root_mean_squared_error: 28.6901\n",
            "Epoch 58/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 804.4464 - root_mean_squared_error: 28.3456 - val_loss: 824.7560 - val_root_mean_squared_error: 28.7017\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "28.6465332939799\n",
            "Epoch 1/500\n",
            "288/288 [==============================] - 4s 7ms/step - loss: 1287.7961 - root_mean_squared_error: 35.8721 - val_loss: 1121.4133 - val_root_mean_squared_error: 33.4737\n",
            "Epoch 2/500\n",
            " 10/288 [>.............................] - ETA: 1s - loss: 971.0143 - root_mean_squared_error: 31.1458"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "288/288 [==============================] - 2s 6ms/step - loss: 976.9449 - root_mean_squared_error: 31.2398 - val_loss: 1227.0645 - val_root_mean_squared_error: 35.0151\n",
            "Epoch 3/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 872.4480 - root_mean_squared_error: 29.5198 - val_loss: 1034.3286 - val_root_mean_squared_error: 32.1452\n",
            "Epoch 4/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 848.2982 - root_mean_squared_error: 29.1080 - val_loss: 991.8053 - val_root_mean_squared_error: 31.4764\n",
            "Epoch 5/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 813.8817 - root_mean_squared_error: 28.5104 - val_loss: 1017.9163 - val_root_mean_squared_error: 31.8886\n",
            "Epoch 6/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 795.5142 - root_mean_squared_error: 28.1865 - val_loss: 1012.3986 - val_root_mean_squared_error: 31.8019\n",
            "Epoch 7/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 806.6981 - root_mean_squared_error: 28.3842 - val_loss: 1009.2913 - val_root_mean_squared_error: 31.7530\n",
            "Epoch 8/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 795.1567 - root_mean_squared_error: 28.1801 - val_loss: 1014.7557 - val_root_mean_squared_error: 31.8389\n",
            "Epoch 9/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 782.2285 - root_mean_squared_error: 27.9498 - val_loss: 1009.8029 - val_root_mean_squared_error: 31.7611\n",
            "Epoch 10/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 781.2347 - root_mean_squared_error: 27.9320 - val_loss: 1012.6235 - val_root_mean_squared_error: 31.8054\n",
            "Epoch 11/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 781.5632 - root_mean_squared_error: 27.9379 - val_loss: 1012.1855 - val_root_mean_squared_error: 31.7985\n",
            "Epoch 12/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 787.4767 - root_mean_squared_error: 28.0435 - val_loss: 1014.1451 - val_root_mean_squared_error: 31.8293\n",
            "Epoch 13/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 775.4943 - root_mean_squared_error: 27.8291 - val_loss: 1007.6760 - val_root_mean_squared_error: 31.7276\n",
            "Epoch 14/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 785.8597 - root_mean_squared_error: 28.0147 - val_loss: 1014.0739 - val_root_mean_squared_error: 31.8282\n",
            "Epoch 15/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 767.7245 - root_mean_squared_error: 27.6891 - val_loss: 1015.3098 - val_root_mean_squared_error: 31.8476\n",
            "Epoch 16/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 781.2843 - root_mean_squared_error: 27.9329 - val_loss: 1011.8544 - val_root_mean_squared_error: 31.7933\n",
            "Epoch 17/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 773.3250 - root_mean_squared_error: 27.7901 - val_loss: 1014.9526 - val_root_mean_squared_error: 31.8420\n",
            "Epoch 18/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 788.2077 - root_mean_squared_error: 28.0565 - val_loss: 1021.0973 - val_root_mean_squared_error: 31.9384\n",
            "Epoch 19/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 771.5891 - root_mean_squared_error: 27.7588 - val_loss: 1013.2614 - val_root_mean_squared_error: 31.8155\n",
            "Epoch 20/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 773.3260 - root_mean_squared_error: 27.7901 - val_loss: 1013.7304 - val_root_mean_squared_error: 31.8228\n",
            "Epoch 21/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 778.8173 - root_mean_squared_error: 27.8887 - val_loss: 1010.1706 - val_root_mean_squared_error: 31.7668\n",
            "Epoch 22/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 789.6211 - root_mean_squared_error: 28.0817 - val_loss: 1013.0278 - val_root_mean_squared_error: 31.8118\n",
            "Epoch 23/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 784.6926 - root_mean_squared_error: 27.9938 - val_loss: 1012.5769 - val_root_mean_squared_error: 31.8047\n",
            "Epoch 24/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 779.0126 - root_mean_squared_error: 27.8922 - val_loss: 1013.8514 - val_root_mean_squared_error: 31.8247\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "31.47635946969802\n",
            "Epoch 1/500\n",
            "288/288 [==============================] - 4s 7ms/step - loss: 1304.4182 - root_mean_squared_error: 36.1034 - val_loss: 1006.6410 - val_root_mean_squared_error: 31.7117\n",
            "Epoch 2/500\n",
            " 10/288 [>.............................] - ETA: 1s - loss: 1115.2976 - root_mean_squared_error: 33.3811"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "288/288 [==============================] - 2s 6ms/step - loss: 970.0374 - root_mean_squared_error: 31.1294 - val_loss: 1049.7500 - val_root_mean_squared_error: 32.3849\n",
            "Epoch 3/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 900.6768 - root_mean_squared_error: 29.9948 - val_loss: 855.8312 - val_root_mean_squared_error: 29.2376\n",
            "Epoch 4/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 854.9095 - root_mean_squared_error: 29.2219 - val_loss: 887.8339 - val_root_mean_squared_error: 29.7798\n",
            "Epoch 5/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 839.6647 - root_mean_squared_error: 28.9598 - val_loss: 857.6632 - val_root_mean_squared_error: 29.2689\n",
            "Epoch 6/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 814.6807 - root_mean_squared_error: 28.5252 - val_loss: 857.9809 - val_root_mean_squared_error: 29.2743\n",
            "Epoch 7/500\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 802.5092 - root_mean_squared_error: 28.3110 - val_loss: 851.8073 - val_root_mean_squared_error: 29.1687\n",
            "Epoch 8/500\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 791.8781 - root_mean_squared_error: 28.1226 - val_loss: 848.3281 - val_root_mean_squared_error: 29.1089\n",
            "Epoch 9/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 799.1323 - root_mean_squared_error: 28.2513 - val_loss: 850.8814 - val_root_mean_squared_error: 29.1528\n",
            "Epoch 10/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 794.5007 - root_mean_squared_error: 28.1692 - val_loss: 852.7786 - val_root_mean_squared_error: 29.1853\n",
            "Epoch 11/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 792.5622 - root_mean_squared_error: 28.1347 - val_loss: 851.5648 - val_root_mean_squared_error: 29.1645\n",
            "Epoch 12/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 792.7115 - root_mean_squared_error: 28.1374 - val_loss: 853.5309 - val_root_mean_squared_error: 29.1982\n",
            "Epoch 13/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 800.4911 - root_mean_squared_error: 28.2753 - val_loss: 854.7047 - val_root_mean_squared_error: 29.2183\n",
            "Epoch 14/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 803.3719 - root_mean_squared_error: 28.3262 - val_loss: 850.8190 - val_root_mean_squared_error: 29.1517\n",
            "Epoch 15/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 800.1244 - root_mean_squared_error: 28.2688 - val_loss: 847.3461 - val_root_mean_squared_error: 29.0921\n",
            "Epoch 16/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 808.7560 - root_mean_squared_error: 28.4211 - val_loss: 852.5163 - val_root_mean_squared_error: 29.1808\n",
            "Epoch 17/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 799.1729 - root_mean_squared_error: 28.2520 - val_loss: 852.3704 - val_root_mean_squared_error: 29.1783\n",
            "Epoch 18/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 789.8455 - root_mean_squared_error: 28.0864 - val_loss: 853.6093 - val_root_mean_squared_error: 29.1995\n",
            "Epoch 19/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 797.3506 - root_mean_squared_error: 28.2197 - val_loss: 852.7769 - val_root_mean_squared_error: 29.1852\n",
            "Epoch 20/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 804.6602 - root_mean_squared_error: 28.3489 - val_loss: 848.2269 - val_root_mean_squared_error: 29.1072\n",
            "Epoch 21/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 806.7404 - root_mean_squared_error: 28.3856 - val_loss: 851.3630 - val_root_mean_squared_error: 29.1610\n",
            "Epoch 22/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 797.5317 - root_mean_squared_error: 28.2229 - val_loss: 852.9105 - val_root_mean_squared_error: 29.1875\n",
            "Epoch 23/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 793.0980 - root_mean_squared_error: 28.1443 - val_loss: 856.9749 - val_root_mean_squared_error: 29.2571\n",
            "Epoch 24/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 796.8763 - root_mean_squared_error: 28.2113 - val_loss: 853.8940 - val_root_mean_squared_error: 29.2044\n",
            "Epoch 25/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 808.2938 - root_mean_squared_error: 28.4129 - val_loss: 850.0937 - val_root_mean_squared_error: 29.1392\n",
            "Epoch 26/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 785.5090 - root_mean_squared_error: 28.0091 - val_loss: 847.4468 - val_root_mean_squared_error: 29.0938\n",
            "Epoch 27/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 786.2094 - root_mean_squared_error: 28.0216 - val_loss: 849.3401 - val_root_mean_squared_error: 29.1263\n",
            "Epoch 28/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 799.4087 - root_mean_squared_error: 28.2562 - val_loss: 849.2881 - val_root_mean_squared_error: 29.1254\n",
            "Epoch 29/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 799.8830 - root_mean_squared_error: 28.2645 - val_loss: 850.6562 - val_root_mean_squared_error: 29.1489\n",
            "Epoch 30/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 789.4089 - root_mean_squared_error: 28.0787 - val_loss: 849.7080 - val_root_mean_squared_error: 29.1326\n",
            "Epoch 31/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 784.7508 - root_mean_squared_error: 27.9956 - val_loss: 849.9951 - val_root_mean_squared_error: 29.1376\n",
            "Epoch 32/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 794.1322 - root_mean_squared_error: 28.1626 - val_loss: 852.1206 - val_root_mean_squared_error: 29.1740\n",
            "Epoch 33/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 789.9211 - root_mean_squared_error: 28.0878 - val_loss: 852.9196 - val_root_mean_squared_error: 29.1877\n",
            "Epoch 34/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 794.2436 - root_mean_squared_error: 28.1646 - val_loss: 853.9819 - val_root_mean_squared_error: 29.2059\n",
            "Epoch 35/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 798.9352 - root_mean_squared_error: 28.2478 - val_loss: 851.6358 - val_root_mean_squared_error: 29.1657\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "29.092058966972516\n",
            "Epoch 1/500\n",
            "288/288 [==============================] - 4s 7ms/step - loss: 1306.5945 - root_mean_squared_error: 36.1333 - val_loss: 955.4688 - val_root_mean_squared_error: 30.8947\n",
            "Epoch 2/500\n",
            " 10/288 [>.............................] - ETA: 1s - loss: 902.2206 - root_mean_squared_error: 30.0200"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "288/288 [==============================] - 2s 6ms/step - loss: 961.7115 - root_mean_squared_error: 30.9950 - val_loss: 928.8490 - val_root_mean_squared_error: 30.4607\n",
            "Epoch 3/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 878.0258 - root_mean_squared_error: 29.6143 - val_loss: 924.3303 - val_root_mean_squared_error: 30.3858\n",
            "Epoch 4/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 849.0795 - root_mean_squared_error: 29.1213 - val_loss: 942.8671 - val_root_mean_squared_error: 30.6896\n",
            "Epoch 5/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 834.6227 - root_mean_squared_error: 28.8721 - val_loss: 922.4080 - val_root_mean_squared_error: 30.3543\n",
            "Epoch 6/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 805.4034 - root_mean_squared_error: 28.3615 - val_loss: 926.3940 - val_root_mean_squared_error: 30.4198\n",
            "Epoch 7/500\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 789.4323 - root_mean_squared_error: 28.0785 - val_loss: 920.9262 - val_root_mean_squared_error: 30.3297\n",
            "Epoch 8/500\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 795.4206 - root_mean_squared_error: 28.1849 - val_loss: 919.7474 - val_root_mean_squared_error: 30.3103\n",
            "Epoch 9/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 804.7055 - root_mean_squared_error: 28.3491 - val_loss: 923.9695 - val_root_mean_squared_error: 30.3799\n",
            "Epoch 10/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 799.0360 - root_mean_squared_error: 28.2489 - val_loss: 922.2800 - val_root_mean_squared_error: 30.3520\n",
            "Epoch 11/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 795.3630 - root_mean_squared_error: 28.1839 - val_loss: 923.1425 - val_root_mean_squared_error: 30.3662\n",
            "Epoch 12/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 794.3447 - root_mean_squared_error: 28.1658 - val_loss: 920.9315 - val_root_mean_squared_error: 30.3298\n",
            "Epoch 13/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 792.1239 - root_mean_squared_error: 28.1263 - val_loss: 922.3732 - val_root_mean_squared_error: 30.3536\n",
            "Epoch 14/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 791.1367 - root_mean_squared_error: 28.1088 - val_loss: 923.4818 - val_root_mean_squared_error: 30.3718\n",
            "Epoch 15/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 782.3466 - root_mean_squared_error: 27.9520 - val_loss: 924.2018 - val_root_mean_squared_error: 30.3837\n",
            "Epoch 16/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 777.2625 - root_mean_squared_error: 27.8609 - val_loss: 921.7292 - val_root_mean_squared_error: 30.3430\n",
            "Epoch 17/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 793.5153 - root_mean_squared_error: 28.1510 - val_loss: 921.9307 - val_root_mean_squared_error: 30.3463\n",
            "Epoch 18/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 792.9336 - root_mean_squared_error: 28.1407 - val_loss: 923.2005 - val_root_mean_squared_error: 30.3672\n",
            "Epoch 19/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 797.9323 - root_mean_squared_error: 28.2294 - val_loss: 924.4830 - val_root_mean_squared_error: 30.3883\n",
            "Epoch 20/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 791.4950 - root_mean_squared_error: 28.1151 - val_loss: 924.4146 - val_root_mean_squared_error: 30.3872\n",
            "Epoch 21/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 786.1932 - root_mean_squared_error: 28.0207 - val_loss: 923.6753 - val_root_mean_squared_error: 30.3750\n",
            "Epoch 22/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 785.9171 - root_mean_squared_error: 28.0158 - val_loss: 922.2749 - val_root_mean_squared_error: 30.3520\n",
            "Epoch 23/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 790.5254 - root_mean_squared_error: 28.0979 - val_loss: 924.7333 - val_root_mean_squared_error: 30.3924\n",
            "Epoch 24/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 790.9397 - root_mean_squared_error: 28.1053 - val_loss: 927.7119 - val_root_mean_squared_error: 30.4414\n",
            "Epoch 25/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 805.1356 - root_mean_squared_error: 28.3567 - val_loss: 919.1818 - val_root_mean_squared_error: 30.3010\n",
            "Epoch 26/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 788.8190 - root_mean_squared_error: 28.0675 - val_loss: 923.2745 - val_root_mean_squared_error: 30.3684\n",
            "Epoch 27/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 789.8486 - root_mean_squared_error: 28.0859 - val_loss: 923.1079 - val_root_mean_squared_error: 30.3657\n",
            "Epoch 28/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 802.1696 - root_mean_squared_error: 28.3043 - val_loss: 920.7316 - val_root_mean_squared_error: 30.3265\n",
            "Epoch 29/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 789.6873 - root_mean_squared_error: 28.0830 - val_loss: 924.3085 - val_root_mean_squared_error: 30.3854\n",
            "Epoch 30/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 783.4927 - root_mean_squared_error: 27.9725 - val_loss: 922.8499 - val_root_mean_squared_error: 30.3614\n",
            "Epoch 31/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 769.1716 - root_mean_squared_error: 27.7153 - val_loss: 922.2161 - val_root_mean_squared_error: 30.3510\n",
            "Epoch 32/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 799.8707 - root_mean_squared_error: 28.2637 - val_loss: 921.3094 - val_root_mean_squared_error: 30.3360\n",
            "Epoch 33/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 797.7966 - root_mean_squared_error: 28.2270 - val_loss: 922.5076 - val_root_mean_squared_error: 30.3558\n",
            "Epoch 34/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 785.2001 - root_mean_squared_error: 28.0030 - val_loss: 924.8716 - val_root_mean_squared_error: 30.3947\n",
            "Epoch 35/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 771.5727 - root_mean_squared_error: 27.7586 - val_loss: 924.8953 - val_root_mean_squared_error: 30.3951\n",
            "Epoch 36/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 784.4253 - root_mean_squared_error: 27.9891 - val_loss: 923.4925 - val_root_mean_squared_error: 30.3720\n",
            "Epoch 37/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 790.9589 - root_mean_squared_error: 28.1056 - val_loss: 923.2195 - val_root_mean_squared_error: 30.3675\n",
            "Epoch 38/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 804.1647 - root_mean_squared_error: 28.3396 - val_loss: 921.6987 - val_root_mean_squared_error: 30.3425\n",
            "Epoch 39/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 815.6461 - root_mean_squared_error: 28.5414 - val_loss: 920.5118 - val_root_mean_squared_error: 30.3229\n",
            "Epoch 40/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 797.2082 - root_mean_squared_error: 28.2166 - val_loss: 923.3376 - val_root_mean_squared_error: 30.3695\n",
            "Epoch 41/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 795.2643 - root_mean_squared_error: 28.1821 - val_loss: 923.7277 - val_root_mean_squared_error: 30.3759\n",
            "Epoch 42/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 794.3177 - root_mean_squared_error: 28.1653 - val_loss: 922.6473 - val_root_mean_squared_error: 30.3581\n",
            "Epoch 43/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 774.0938 - root_mean_squared_error: 27.8040 - val_loss: 923.3012 - val_root_mean_squared_error: 30.3689\n",
            "Epoch 44/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 792.8276 - root_mean_squared_error: 28.1388 - val_loss: 920.5487 - val_root_mean_squared_error: 30.3235\n",
            "Epoch 45/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 803.6240 - root_mean_squared_error: 28.3300 - val_loss: 921.1868 - val_root_mean_squared_error: 30.3340\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "30.300962480444408\n",
            "Epoch 1/500\n",
            "288/288 [==============================] - 4s 8ms/step - loss: 1303.4092 - root_mean_squared_error: 36.0897 - val_loss: 1124.0217 - val_root_mean_squared_error: 33.5122\n",
            "Epoch 2/500\n",
            "  9/288 [..............................] - ETA: 1s - loss: 927.4714 - root_mean_squared_error: 30.4384 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "288/288 [==============================] - 2s 7ms/step - loss: 962.1399 - root_mean_squared_error: 31.0026 - val_loss: 929.1572 - val_root_mean_squared_error: 30.4657\n",
            "Epoch 3/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 902.8282 - root_mean_squared_error: 30.0307 - val_loss: 1011.1262 - val_root_mean_squared_error: 31.7829\n",
            "Epoch 4/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 851.2714 - root_mean_squared_error: 29.1596 - val_loss: 913.1437 - val_root_mean_squared_error: 30.2019\n",
            "Epoch 5/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 807.4139 - root_mean_squared_error: 28.3975 - val_loss: 910.5735 - val_root_mean_squared_error: 30.1593\n",
            "Epoch 6/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 810.3943 - root_mean_squared_error: 28.4500 - val_loss: 901.5732 - val_root_mean_squared_error: 30.0096\n",
            "Epoch 7/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 802.2261 - root_mean_squared_error: 28.3060 - val_loss: 908.4830 - val_root_mean_squared_error: 30.1245\n",
            "Epoch 8/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 798.0773 - root_mean_squared_error: 28.2326 - val_loss: 908.7532 - val_root_mean_squared_error: 30.1290\n",
            "Epoch 9/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 790.1054 - root_mean_squared_error: 28.0911 - val_loss: 910.1730 - val_root_mean_squared_error: 30.1525\n",
            "Epoch 10/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 777.7539 - root_mean_squared_error: 27.8703 - val_loss: 912.8773 - val_root_mean_squared_error: 30.1973\n",
            "Epoch 11/500\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 787.1337 - root_mean_squared_error: 28.0381 - val_loss: 915.4391 - val_root_mean_squared_error: 30.2397\n",
            "Epoch 12/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 795.8185 - root_mean_squared_error: 28.1925 - val_loss: 904.1745 - val_root_mean_squared_error: 30.0529\n",
            "Epoch 13/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 790.0698 - root_mean_squared_error: 28.0904 - val_loss: 912.4278 - val_root_mean_squared_error: 30.1899\n",
            "Epoch 14/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 783.6170 - root_mean_squared_error: 27.9753 - val_loss: 915.0603 - val_root_mean_squared_error: 30.2334\n",
            "Epoch 15/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 785.1974 - root_mean_squared_error: 28.0035 - val_loss: 915.0727 - val_root_mean_squared_error: 30.2337\n",
            "Epoch 16/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 799.0292 - root_mean_squared_error: 28.2494 - val_loss: 919.3435 - val_root_mean_squared_error: 30.3042\n",
            "Epoch 17/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 786.3981 - root_mean_squared_error: 28.0250 - val_loss: 907.4690 - val_root_mean_squared_error: 30.1076\n",
            "Epoch 18/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 793.8010 - root_mean_squared_error: 28.1567 - val_loss: 915.9889 - val_root_mean_squared_error: 30.2488\n",
            "Epoch 19/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 785.1088 - root_mean_squared_error: 28.0020 - val_loss: 917.5615 - val_root_mean_squared_error: 30.2748\n",
            "Epoch 20/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 777.9932 - root_mean_squared_error: 27.8746 - val_loss: 914.2714 - val_root_mean_squared_error: 30.2204\n",
            "Epoch 21/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 772.1272 - root_mean_squared_error: 27.7692 - val_loss: 911.7822 - val_root_mean_squared_error: 30.1792\n",
            "Epoch 22/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 782.2322 - root_mean_squared_error: 27.9505 - val_loss: 910.3434 - val_root_mean_squared_error: 30.1553\n",
            "Epoch 23/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 790.4427 - root_mean_squared_error: 28.0970 - val_loss: 907.6935 - val_root_mean_squared_error: 30.1114\n",
            "Epoch 24/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 785.5995 - root_mean_squared_error: 28.0107 - val_loss: 912.5339 - val_root_mean_squared_error: 30.1916\n",
            "Epoch 25/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 785.9027 - root_mean_squared_error: 28.0161 - val_loss: 909.9777 - val_root_mean_squared_error: 30.1493\n",
            "Epoch 26/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 792.1126 - root_mean_squared_error: 28.1267 - val_loss: 912.8408 - val_root_mean_squared_error: 30.1967\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "30.009619097025997\n",
            "Epoch 1/500\n",
            "288/288 [==============================] - 4s 7ms/step - loss: 1316.5504 - root_mean_squared_error: 36.2710 - val_loss: 1040.6455 - val_root_mean_squared_error: 32.2429\n",
            "Epoch 2/500\n",
            " 10/288 [>.............................] - ETA: 1s - loss: 889.3212 - root_mean_squared_error: 29.8039"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "288/288 [==============================] - 2s 6ms/step - loss: 967.2577 - root_mean_squared_error: 31.0845 - val_loss: 999.2137 - val_root_mean_squared_error: 31.5949\n",
            "Epoch 3/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 901.8840 - root_mean_squared_error: 30.0146 - val_loss: 912.6188 - val_root_mean_squared_error: 30.1927\n",
            "Epoch 4/500\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 858.3898 - root_mean_squared_error: 29.2810 - val_loss: 888.4388 - val_root_mean_squared_error: 29.7896\n",
            "Epoch 5/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 835.7283 - root_mean_squared_error: 28.8914 - val_loss: 908.7468 - val_root_mean_squared_error: 30.1286\n",
            "Epoch 6/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 833.2374 - root_mean_squared_error: 28.8482 - val_loss: 901.3223 - val_root_mean_squared_error: 30.0051\n",
            "Epoch 7/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 792.6755 - root_mean_squared_error: 28.1364 - val_loss: 894.6212 - val_root_mean_squared_error: 29.8932\n",
            "Epoch 8/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 811.2785 - root_mean_squared_error: 28.4651 - val_loss: 890.9376 - val_root_mean_squared_error: 29.8315\n",
            "Epoch 9/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 806.9761 - root_mean_squared_error: 28.3894 - val_loss: 892.5250 - val_root_mean_squared_error: 29.8581\n",
            "Epoch 10/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 787.8801 - root_mean_squared_error: 28.0510 - val_loss: 890.5286 - val_root_mean_squared_error: 29.8246\n",
            "Epoch 11/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 807.1849 - root_mean_squared_error: 28.3930 - val_loss: 892.5989 - val_root_mean_squared_error: 29.8593\n",
            "Epoch 12/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 800.1826 - root_mean_squared_error: 28.2695 - val_loss: 890.0989 - val_root_mean_squared_error: 29.8174\n",
            "Epoch 13/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 802.8246 - root_mean_squared_error: 28.3162 - val_loss: 891.5459 - val_root_mean_squared_error: 29.8417\n",
            "Epoch 14/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 805.0441 - root_mean_squared_error: 28.3553 - val_loss: 894.0714 - val_root_mean_squared_error: 29.8840\n",
            "Epoch 15/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 807.8223 - root_mean_squared_error: 28.4043 - val_loss: 890.6349 - val_root_mean_squared_error: 29.8264\n",
            "Epoch 16/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 795.2896 - root_mean_squared_error: 28.1828 - val_loss: 892.3661 - val_root_mean_squared_error: 29.8554\n",
            "Epoch 17/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 795.2457 - root_mean_squared_error: 28.1820 - val_loss: 892.8361 - val_root_mean_squared_error: 29.8633\n",
            "Epoch 18/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 799.1094 - root_mean_squared_error: 28.2505 - val_loss: 888.7248 - val_root_mean_squared_error: 29.7944\n",
            "Epoch 19/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 798.3587 - root_mean_squared_error: 28.2372 - val_loss: 892.7815 - val_root_mean_squared_error: 29.8624\n",
            "Epoch 20/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 798.5637 - root_mean_squared_error: 28.2408 - val_loss: 894.8754 - val_root_mean_squared_error: 29.8974\n",
            "Epoch 21/500\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 798.6754 - root_mean_squared_error: 28.2428 - val_loss: 889.4817 - val_root_mean_squared_error: 29.8071\n",
            "Epoch 22/500\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 811.8948 - root_mean_squared_error: 28.4759 - val_loss: 889.0224 - val_root_mean_squared_error: 29.7994\n",
            "Epoch 23/500\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 802.8616 - root_mean_squared_error: 28.3168 - val_loss: 893.3955 - val_root_mean_squared_error: 29.8727\n",
            "Epoch 24/500\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 793.9743 - root_mean_squared_error: 28.1594 - val_loss: 890.7925 - val_root_mean_squared_error: 29.8291\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "29.789643272672123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, BatchNormalization, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.metrics import RootMeanSquaredError\n",
        "import keras\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import math\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "\n",
        "# Define features and targets\n",
        "non_features = ['id', 'SMILES', 'MLM', 'HLM', 'Fingerprint']\n",
        "features = [column for column in train.columns if column not in non_features]\n",
        "mlm_target = \"MLM\"\n",
        "hlm_target = \"HLM\"\n",
        "\n",
        "# Initialize KFold\n",
        "seed = 42\n",
        "n_splits = 20\n",
        "kf = KFold(n_splits=n_splits, random_state=seed, shuffle=True)\n",
        "\n",
        "# Initialize arrays to store models and scores\n",
        "reg_mlms = []\n",
        "reg_hlms = []\n",
        "\n",
        "# Initialize arrays to store RMSE scores\n",
        "mlm_rmse_scores = []\n",
        "hlm_rmse_scores = []\n",
        "\n",
        "# Loop through KFold splits\n",
        "for i, (train_index, valid_index) in enumerate(kf.split(train_MLM)):\n",
        "    df_train = train_MLM.iloc[train_index]\n",
        "    df_valid = train_MLM.iloc[valid_index]\n",
        "\n",
        "    x_train_num = df_train[features].values\n",
        "\n",
        "    y_mlm_train = df_train[mlm_target].values\n",
        "\n",
        "    x_valid_num = df_valid[features].values\n",
        "\n",
        "    y_mlm_valid = df_valid[mlm_target].values\n",
        "\n",
        "    # Ïù¥ÎØ∏ÏßÄ ÏûÖÎ†• Í≤ΩÎ°ú\n",
        "    x1_input = keras.Input(shape=(x_train_num.shape[1],))\n",
        "    x1 = layers.Dense(1024, activation='relu')(x1_input)\n",
        "    x1 = layers.BatchNormalization()(x1)\n",
        "    x1 = layers.Dropout(0.2)(x1)\n",
        "    merged = layers.Dense(1024, activation='relu')(x1)\n",
        "    merged = layers.BatchNormalization()(merged)\n",
        "    merged = layers.Dropout(0.2)(merged)\n",
        "    merged = layers.Dense(512, activation='relu')(merged)\n",
        "    merged = layers.BatchNormalization()(merged)\n",
        "    merged = layers.Dropout(0.2)(merged)\n",
        "    merged = layers.Dense(256, activation='relu')(merged)\n",
        "    merged = layers.BatchNormalization()(merged)\n",
        "    merged = layers.Dropout(0.2)(merged)\n",
        "    merged = layers.Dense(128, activation='relu')(merged)\n",
        "    merged = layers.BatchNormalization()(merged)\n",
        "\n",
        "    # ÌöåÍ∑Ä Î™®Îç∏ Ï∂úÎ†• Î†àÏù¥Ïñ¥ Ï∂îÍ∞Ä\n",
        "    outputs = layers.Dense(1)(merged)\n",
        "\n",
        "    # Î™®Îç∏ ÏÉùÏÑ±\n",
        "    model = keras.Model(inputs=x1_input, outputs=outputs)\n",
        "\n",
        "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.001,\n",
        "    decay_steps=8,\n",
        "    decay_rate=0.98)\n",
        "    optimizer_decay = keras.optimizers.SGD(learning_rate=lr_schedule)\n",
        "\n",
        "    model.compile(optimizer=optimizer_decay, loss='mean_squared_error', metrics=[RootMeanSquaredError()])\n",
        "\n",
        "    # Create and compile another model for HLM\n",
        "    # Ïù¥ÎØ∏ÏßÄ ÏûÖÎ†• Í≤ΩÎ°ú\n",
        "    x1_input = keras.Input(shape=(x_train_num.shape[1],))\n",
        "    x1 = layers.Dense(256, activation='relu')(x1_input)\n",
        "    x1 = layers.BatchNormalization()(x1)\n",
        "    x1 = layers.Dropout(0.2)(x1)\n",
        "    merged = layers.Dense(1024, activation='relu')(x1)\n",
        "    merged = layers.BatchNormalization()(merged)\n",
        "    merged = layers.Dropout(0.2)(merged)\n",
        "    merged = layers.Dense(512, activation='relu')(merged)\n",
        "    merged = layers.BatchNormalization()(merged)\n",
        "    merged = layers.Dropout(0.2)(merged)\n",
        "    merged = layers.Dense(256, activation='relu')(merged)\n",
        "    merged = layers.BatchNormalization()(merged)\n",
        "    merged = layers.Dropout(0.2)(merged)\n",
        "    merged = layers.Dense(128, activation='relu')(merged)\n",
        "    merged = layers.BatchNormalization()(merged)\n",
        "\n",
        "    # ÌöåÍ∑Ä Î™®Îç∏ Ï∂úÎ†• Î†àÏù¥Ïñ¥ Ï∂îÍ∞Ä\n",
        "    outputs = layers.Dense(1)(merged)\n",
        "\n",
        "    # Î™®Îç∏ ÏÉùÏÑ±\n",
        "    model_hlm = keras.Model(inputs=x1_input, outputs=outputs)\n",
        "\n",
        "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.001,\n",
        "    decay_steps=8,\n",
        "    decay_rate=0.98)\n",
        "    optimizer_decay = keras.optimizers.SGD(learning_rate=lr_schedule)\n",
        "\n",
        "    model_hlm.compile(optimizer=optimizer_decay, loss='mean_squared_error', metrics=[RootMeanSquaredError()])\n",
        "\n",
        "\n",
        "    # Train the model\n",
        "    checkpoint_mlm = ModelCheckpoint(f'model_mlm_fold{i}.h5', monitor='val_loss', verbose=0, save_best_only=True)\n",
        "    early_stopping_mlm = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "\n",
        "    model.fit(x_train_num, y_mlm_train, epochs=500, batch_size=16, verbose=1, validation_data=(x_valid_num, y_mlm_valid),\n",
        "              callbacks=[checkpoint_mlm, early_stopping_mlm])\n",
        "\n",
        "    reg_mlms.append(model)\n",
        "\n",
        "    # checkpoint_hlm = ModelCheckpoint(f'model_hlm_fold{i}.h5', monitor='val_loss', verbose=0, save_best_only=True)\n",
        "    # early_stopping_hlm = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "\n",
        "    # model_hlm.fit(x_train_num, y_hlm_train, epochs=500, batch_size=16, verbose=1, validation_data=(x_valid_num, y_hlm_valid),\n",
        "    #               callbacks=[checkpoint_hlm, early_stopping_hlm])\n",
        "\n",
        "    # reg_hlms.append(model_hlm)\n",
        "\n",
        "    # Calculate RMSE for MLM predictions\n",
        "    y_mlm_pred = model.predict(x_valid_num)\n",
        "    mlm_rmse = math.sqrt(mean_squared_error(y_mlm_valid, y_mlm_pred))\n",
        "    print(mlm_rmse)\n",
        "    mlm_rmse_scores.append(mlm_rmse)\n",
        "\n",
        "    # # Calculate RMSE for HLM predictions\n",
        "    # y_hlm_pred = model_hlm.predict(x_valid_num)\n",
        "    # hlm_rmse = math.sqrt(mean_squared_error(y_hlm_valid, y_hlm_pred))\n",
        "    # print(hlm_rmse)\n",
        "    # hlm_rmse_scores.append(hlm_rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mn5Ks3dkOBnf",
        "outputId": "0202bbf1-54d3-46f7-fea1-841c39b261c5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "241/241 [==============================] - 4s 8ms/step - loss: 1222.0164 - root_mean_squared_error: 34.9573 - val_loss: 3813.9473 - val_root_mean_squared_error: 61.7572\n",
            "Epoch 2/500\n",
            " 10/241 [>.............................] - ETA: 1s - loss: 1000.3320 - root_mean_squared_error: 31.6280"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "241/241 [==============================] - 2s 7ms/step - loss: 933.0826 - root_mean_squared_error: 30.5464 - val_loss: 994.5351 - val_root_mean_squared_error: 31.5363\n",
            "Epoch 3/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 877.6008 - root_mean_squared_error: 29.6243 - val_loss: 1053.8179 - val_root_mean_squared_error: 32.4626\n",
            "Epoch 4/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 836.5040 - root_mean_squared_error: 28.9224 - val_loss: 1001.8346 - val_root_mean_squared_error: 31.6518\n",
            "Epoch 5/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 793.2324 - root_mean_squared_error: 28.1644 - val_loss: 984.6315 - val_root_mean_squared_error: 31.3788\n",
            "Epoch 6/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 775.9859 - root_mean_squared_error: 27.8565 - val_loss: 967.1755 - val_root_mean_squared_error: 31.0994\n",
            "Epoch 7/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 771.7156 - root_mean_squared_error: 27.7798 - val_loss: 959.3795 - val_root_mean_squared_error: 30.9739\n",
            "Epoch 8/500\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 772.7352 - root_mean_squared_error: 27.7981 - val_loss: 956.0801 - val_root_mean_squared_error: 30.9205\n",
            "Epoch 9/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 751.9559 - root_mean_squared_error: 27.4218 - val_loss: 957.2112 - val_root_mean_squared_error: 30.9388\n",
            "Epoch 10/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 766.4374 - root_mean_squared_error: 27.6846 - val_loss: 961.1833 - val_root_mean_squared_error: 31.0030\n",
            "Epoch 11/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 750.6313 - root_mean_squared_error: 27.3977 - val_loss: 961.8271 - val_root_mean_squared_error: 31.0133\n",
            "Epoch 12/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 745.0757 - root_mean_squared_error: 27.2961 - val_loss: 963.8418 - val_root_mean_squared_error: 31.0458\n",
            "Epoch 13/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 750.1469 - root_mean_squared_error: 27.3888 - val_loss: 963.0418 - val_root_mean_squared_error: 31.0329\n",
            "Epoch 14/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 740.3382 - root_mean_squared_error: 27.2092 - val_loss: 962.7253 - val_root_mean_squared_error: 31.0278\n",
            "Epoch 15/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 749.5583 - root_mean_squared_error: 27.3781 - val_loss: 964.5217 - val_root_mean_squared_error: 31.0567\n",
            "Epoch 16/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 764.5009 - root_mean_squared_error: 27.6496 - val_loss: 963.8066 - val_root_mean_squared_error: 31.0452\n",
            "Epoch 17/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 751.2415 - root_mean_squared_error: 27.4088 - val_loss: 966.0364 - val_root_mean_squared_error: 31.0811\n",
            "Epoch 18/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 764.4871 - root_mean_squared_error: 27.6494 - val_loss: 964.8572 - val_root_mean_squared_error: 31.0622\n",
            "Epoch 19/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 753.1890 - root_mean_squared_error: 27.4443 - val_loss: 962.6038 - val_root_mean_squared_error: 31.0259\n",
            "Epoch 20/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 753.7504 - root_mean_squared_error: 27.4545 - val_loss: 959.1556 - val_root_mean_squared_error: 30.9702\n",
            "Epoch 21/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 737.1744 - root_mean_squared_error: 27.1510 - val_loss: 961.4977 - val_root_mean_squared_error: 31.0080\n",
            "Epoch 22/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 755.7135 - root_mean_squared_error: 27.4902 - val_loss: 961.6279 - val_root_mean_squared_error: 31.0101\n",
            "Epoch 23/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 753.3530 - root_mean_squared_error: 27.4473 - val_loss: 962.4243 - val_root_mean_squared_error: 31.0230\n",
            "Epoch 24/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 733.6760 - root_mean_squared_error: 27.0865 - val_loss: 960.9411 - val_root_mean_squared_error: 30.9991\n",
            "Epoch 25/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 754.0378 - root_mean_squared_error: 27.4597 - val_loss: 961.3561 - val_root_mean_squared_error: 31.0057\n",
            "Epoch 26/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 755.2237 - root_mean_squared_error: 27.4813 - val_loss: 963.5749 - val_root_mean_squared_error: 31.0415\n",
            "Epoch 27/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 768.6073 - root_mean_squared_error: 27.7238 - val_loss: 958.7096 - val_root_mean_squared_error: 30.9630\n",
            "Epoch 28/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 747.5984 - root_mean_squared_error: 27.3422 - val_loss: 962.6913 - val_root_mean_squared_error: 31.0273\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "30.920546451687226\n",
            "Epoch 1/500\n",
            "241/241 [==============================] - 4s 8ms/step - loss: 1245.2827 - root_mean_squared_error: 35.2886 - val_loss: 1471.2983 - val_root_mean_squared_error: 38.3575\n",
            "Epoch 2/500\n",
            " 10/241 [>.............................] - ETA: 1s - loss: 896.9293 - root_mean_squared_error: 29.9488"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "241/241 [==============================] - 2s 7ms/step - loss: 942.3912 - root_mean_squared_error: 30.6984 - val_loss: 998.3001 - val_root_mean_squared_error: 31.5959\n",
            "Epoch 3/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 866.7396 - root_mean_squared_error: 29.4404 - val_loss: 958.6582 - val_root_mean_squared_error: 30.9622\n",
            "Epoch 4/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 841.3298 - root_mean_squared_error: 29.0057 - val_loss: 872.6892 - val_root_mean_squared_error: 29.5413\n",
            "Epoch 5/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 801.1785 - root_mean_squared_error: 28.3051 - val_loss: 848.4699 - val_root_mean_squared_error: 29.1285\n",
            "Epoch 6/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 785.6418 - root_mean_squared_error: 28.0293 - val_loss: 846.9062 - val_root_mean_squared_error: 29.1017\n",
            "Epoch 7/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 774.7936 - root_mean_squared_error: 27.8351 - val_loss: 845.7957 - val_root_mean_squared_error: 29.0826\n",
            "Epoch 8/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 759.1946 - root_mean_squared_error: 27.5535 - val_loss: 845.5750 - val_root_mean_squared_error: 29.0788\n",
            "Epoch 9/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 753.0488 - root_mean_squared_error: 27.4417 - val_loss: 843.1248 - val_root_mean_squared_error: 29.0366\n",
            "Epoch 10/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 750.5533 - root_mean_squared_error: 27.3962 - val_loss: 840.3886 - val_root_mean_squared_error: 28.9895\n",
            "Epoch 11/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 749.3311 - root_mean_squared_error: 27.3739 - val_loss: 843.0068 - val_root_mean_squared_error: 29.0346\n",
            "Epoch 12/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 764.1473 - root_mean_squared_error: 27.6432 - val_loss: 845.8599 - val_root_mean_squared_error: 29.0837\n",
            "Epoch 13/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 754.0663 - root_mean_squared_error: 27.4603 - val_loss: 843.0367 - val_root_mean_squared_error: 29.0351\n",
            "Epoch 14/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 771.8297 - root_mean_squared_error: 27.7818 - val_loss: 843.4066 - val_root_mean_squared_error: 29.0415\n",
            "Epoch 15/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 746.0109 - root_mean_squared_error: 27.3132 - val_loss: 843.0705 - val_root_mean_squared_error: 29.0357\n",
            "Epoch 16/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 760.8549 - root_mean_squared_error: 27.5836 - val_loss: 844.9763 - val_root_mean_squared_error: 29.0685\n",
            "Epoch 17/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 758.6109 - root_mean_squared_error: 27.5429 - val_loss: 842.3175 - val_root_mean_squared_error: 29.0227\n",
            "Epoch 18/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 764.4655 - root_mean_squared_error: 27.6490 - val_loss: 844.2546 - val_root_mean_squared_error: 29.0561\n",
            "Epoch 19/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 751.4753 - root_mean_squared_error: 27.4130 - val_loss: 843.4051 - val_root_mean_squared_error: 29.0414\n",
            "Epoch 20/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 767.3170 - root_mean_squared_error: 27.7005 - val_loss: 842.9619 - val_root_mean_squared_error: 29.0338\n",
            "Epoch 21/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 752.2388 - root_mean_squared_error: 27.4270 - val_loss: 844.7375 - val_root_mean_squared_error: 29.0644\n",
            "Epoch 22/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 749.6825 - root_mean_squared_error: 27.3803 - val_loss: 843.9111 - val_root_mean_squared_error: 29.0501\n",
            "Epoch 23/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 745.7186 - root_mean_squared_error: 27.3078 - val_loss: 846.0539 - val_root_mean_squared_error: 29.0870\n",
            "Epoch 24/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 756.6805 - root_mean_squared_error: 27.5078 - val_loss: 844.8005 - val_root_mean_squared_error: 29.0655\n",
            "Epoch 25/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 759.3958 - root_mean_squared_error: 27.5571 - val_loss: 844.2670 - val_root_mean_squared_error: 29.0563\n",
            "Epoch 26/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 758.0947 - root_mean_squared_error: 27.5335 - val_loss: 845.1061 - val_root_mean_squared_error: 29.0707\n",
            "Epoch 27/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 752.3600 - root_mean_squared_error: 27.4292 - val_loss: 845.9567 - val_root_mean_squared_error: 29.0853\n",
            "Epoch 28/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 763.8945 - root_mean_squared_error: 27.6386 - val_loss: 843.0654 - val_root_mean_squared_error: 29.0356\n",
            "Epoch 29/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 748.2321 - root_mean_squared_error: 27.3538 - val_loss: 842.1144 - val_root_mean_squared_error: 29.0192\n",
            "Epoch 30/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 739.5943 - root_mean_squared_error: 27.1955 - val_loss: 844.2307 - val_root_mean_squared_error: 29.0556\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "28.989455706357745\n",
            "Epoch 1/500\n",
            "241/241 [==============================] - 4s 8ms/step - loss: 1239.1696 - root_mean_squared_error: 35.2018 - val_loss: 1165.1523 - val_root_mean_squared_error: 34.1343\n",
            "Epoch 2/500\n",
            "  9/241 [>.............................] - ETA: 1s - loss: 1027.5490 - root_mean_squared_error: 32.0554"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "241/241 [==============================] - 2s 7ms/step - loss: 929.1797 - root_mean_squared_error: 30.4824 - val_loss: 1025.7661 - val_root_mean_squared_error: 32.0276\n",
            "Epoch 3/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 878.6020 - root_mean_squared_error: 29.6412 - val_loss: 1146.9155 - val_root_mean_squared_error: 33.8661\n",
            "Epoch 4/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 836.1281 - root_mean_squared_error: 28.9159 - val_loss: 1016.4890 - val_root_mean_squared_error: 31.8824\n",
            "Epoch 5/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 805.5778 - root_mean_squared_error: 28.3827 - val_loss: 934.9440 - val_root_mean_squared_error: 30.5769\n",
            "Epoch 6/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 780.4408 - root_mean_squared_error: 27.9364 - val_loss: 918.4033 - val_root_mean_squared_error: 30.3052\n",
            "Epoch 7/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 781.3235 - root_mean_squared_error: 27.9522 - val_loss: 934.7341 - val_root_mean_squared_error: 30.5734\n",
            "Epoch 8/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 773.8732 - root_mean_squared_error: 27.8186 - val_loss: 920.6545 - val_root_mean_squared_error: 30.3423\n",
            "Epoch 9/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 775.5955 - root_mean_squared_error: 27.8495 - val_loss: 928.3102 - val_root_mean_squared_error: 30.4682\n",
            "Epoch 10/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 752.7747 - root_mean_squared_error: 27.4367 - val_loss: 928.7912 - val_root_mean_squared_error: 30.4761\n",
            "Epoch 11/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 764.1758 - root_mean_squared_error: 27.6437 - val_loss: 924.3829 - val_root_mean_squared_error: 30.4037\n",
            "Epoch 12/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 737.0684 - root_mean_squared_error: 27.1490 - val_loss: 928.8520 - val_root_mean_squared_error: 30.4771\n",
            "Epoch 13/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 759.0866 - root_mean_squared_error: 27.5515 - val_loss: 929.8788 - val_root_mean_squared_error: 30.4939\n",
            "Epoch 14/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 756.3526 - root_mean_squared_error: 27.5019 - val_loss: 930.1093 - val_root_mean_squared_error: 30.4977\n",
            "Epoch 15/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 768.2183 - root_mean_squared_error: 27.7168 - val_loss: 925.9589 - val_root_mean_squared_error: 30.4296\n",
            "Epoch 16/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 757.7651 - root_mean_squared_error: 27.5275 - val_loss: 923.7993 - val_root_mean_squared_error: 30.3941\n",
            "Epoch 17/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 771.2218 - root_mean_squared_error: 27.7709 - val_loss: 922.1806 - val_root_mean_squared_error: 30.3674\n",
            "Epoch 18/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 770.5327 - root_mean_squared_error: 27.7585 - val_loss: 924.6320 - val_root_mean_squared_error: 30.4078\n",
            "Epoch 19/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 746.8015 - root_mean_squared_error: 27.3277 - val_loss: 928.7479 - val_root_mean_squared_error: 30.4754\n",
            "Epoch 20/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 760.6561 - root_mean_squared_error: 27.5800 - val_loss: 925.9501 - val_root_mean_squared_error: 30.4294\n",
            "Epoch 21/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 752.3004 - root_mean_squared_error: 27.4281 - val_loss: 925.4821 - val_root_mean_squared_error: 30.4217\n",
            "Epoch 22/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 754.2510 - root_mean_squared_error: 27.4636 - val_loss: 927.8151 - val_root_mean_squared_error: 30.4601\n",
            "Epoch 23/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 743.1874 - root_mean_squared_error: 27.2615 - val_loss: 926.2448 - val_root_mean_squared_error: 30.4343\n",
            "Epoch 24/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 751.1669 - root_mean_squared_error: 27.4074 - val_loss: 925.1097 - val_root_mean_squared_error: 30.4156\n",
            "Epoch 25/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 751.0476 - root_mean_squared_error: 27.4052 - val_loss: 927.7534 - val_root_mean_squared_error: 30.4590\n",
            "Epoch 26/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 778.1818 - root_mean_squared_error: 27.8959 - val_loss: 927.0127 - val_root_mean_squared_error: 30.4469\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "30.305171097362052\n",
            "Epoch 1/500\n",
            "241/241 [==============================] - 4s 8ms/step - loss: 1242.2325 - root_mean_squared_error: 35.2453 - val_loss: 22347290.0000 - val_root_mean_squared_error: 4727.2920\n",
            "Epoch 2/500\n",
            "  9/241 [>.............................] - ETA: 1s - loss: 997.6992 - root_mean_squared_error: 31.5864"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "241/241 [==============================] - 2s 7ms/step - loss: 997.7070 - root_mean_squared_error: 31.5865 - val_loss: 1336.4657 - val_root_mean_squared_error: 36.5577\n",
            "Epoch 3/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 918.0977 - root_mean_squared_error: 30.3001 - val_loss: 958.0440 - val_root_mean_squared_error: 30.9523\n",
            "Epoch 4/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 877.1732 - root_mean_squared_error: 29.6171 - val_loss: 954.9534 - val_root_mean_squared_error: 30.9023\n",
            "Epoch 5/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 845.4518 - root_mean_squared_error: 29.0767 - val_loss: 955.3337 - val_root_mean_squared_error: 30.9085\n",
            "Epoch 6/500\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 834.1083 - root_mean_squared_error: 28.8809 - val_loss: 945.6327 - val_root_mean_squared_error: 30.7511\n",
            "Epoch 7/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 814.8275 - root_mean_squared_error: 28.5452 - val_loss: 930.8863 - val_root_mean_squared_error: 30.5104\n",
            "Epoch 8/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 807.9240 - root_mean_squared_error: 28.4240 - val_loss: 932.1824 - val_root_mean_squared_error: 30.5317\n",
            "Epoch 9/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 819.4862 - root_mean_squared_error: 28.6267 - val_loss: 934.9516 - val_root_mean_squared_error: 30.5770\n",
            "Epoch 10/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 814.9872 - root_mean_squared_error: 28.5480 - val_loss: 933.3428 - val_root_mean_squared_error: 30.5507\n",
            "Epoch 11/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 801.4258 - root_mean_squared_error: 28.3095 - val_loss: 931.2589 - val_root_mean_squared_error: 30.5165\n",
            "Epoch 12/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 810.8841 - root_mean_squared_error: 28.4760 - val_loss: 932.1049 - val_root_mean_squared_error: 30.5304\n",
            "Epoch 13/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 803.6374 - root_mean_squared_error: 28.3485 - val_loss: 931.2605 - val_root_mean_squared_error: 30.5166\n",
            "Epoch 14/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 782.5179 - root_mean_squared_error: 27.9735 - val_loss: 932.2070 - val_root_mean_squared_error: 30.5321\n",
            "Epoch 15/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 806.7179 - root_mean_squared_error: 28.4028 - val_loss: 934.7394 - val_root_mean_squared_error: 30.5735\n",
            "Epoch 16/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 803.9906 - root_mean_squared_error: 28.3547 - val_loss: 935.9793 - val_root_mean_squared_error: 30.5938\n",
            "Epoch 17/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 810.9683 - root_mean_squared_error: 28.4775 - val_loss: 935.1607 - val_root_mean_squared_error: 30.5804\n",
            "Epoch 18/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 790.1547 - root_mean_squared_error: 28.1097 - val_loss: 930.9887 - val_root_mean_squared_error: 30.5121\n",
            "Epoch 19/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 797.0234 - root_mean_squared_error: 28.2316 - val_loss: 929.9115 - val_root_mean_squared_error: 30.4944\n",
            "Epoch 20/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 816.7629 - root_mean_squared_error: 28.5791 - val_loss: 929.9570 - val_root_mean_squared_error: 30.4952\n",
            "Epoch 21/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 797.0793 - root_mean_squared_error: 28.2326 - val_loss: 930.1307 - val_root_mean_squared_error: 30.4980\n",
            "Epoch 22/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 796.4910 - root_mean_squared_error: 28.2222 - val_loss: 933.0092 - val_root_mean_squared_error: 30.5452\n",
            "Epoch 23/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 793.8460 - root_mean_squared_error: 28.1753 - val_loss: 930.7397 - val_root_mean_squared_error: 30.5080\n",
            "Epoch 24/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 801.2604 - root_mean_squared_error: 28.3065 - val_loss: 931.5917 - val_root_mean_squared_error: 30.5220\n",
            "Epoch 25/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 789.9627 - root_mean_squared_error: 28.1063 - val_loss: 930.3937 - val_root_mean_squared_error: 30.5024\n",
            "Epoch 26/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 799.0394 - root_mean_squared_error: 28.2673 - val_loss: 930.9929 - val_root_mean_squared_error: 30.5122\n",
            "Epoch 27/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 798.2307 - root_mean_squared_error: 28.2530 - val_loss: 936.1873 - val_root_mean_squared_error: 30.5972\n",
            "Epoch 28/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 804.9365 - root_mean_squared_error: 28.3714 - val_loss: 933.0581 - val_root_mean_squared_error: 30.5460\n",
            "Epoch 29/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 806.1881 - root_mean_squared_error: 28.3935 - val_loss: 931.1893 - val_root_mean_squared_error: 30.5154\n",
            "Epoch 30/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 796.8143 - root_mean_squared_error: 28.2279 - val_loss: 933.6307 - val_root_mean_squared_error: 30.5554\n",
            "Epoch 31/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 796.7913 - root_mean_squared_error: 28.2275 - val_loss: 934.1555 - val_root_mean_squared_error: 30.5640\n",
            "Epoch 32/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 791.5921 - root_mean_squared_error: 28.1352 - val_loss: 933.9466 - val_root_mean_squared_error: 30.5605\n",
            "Epoch 33/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 796.9500 - root_mean_squared_error: 28.2303 - val_loss: 934.1489 - val_root_mean_squared_error: 30.5639\n",
            "Epoch 34/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 795.6278 - root_mean_squared_error: 28.2069 - val_loss: 930.1616 - val_root_mean_squared_error: 30.4986\n",
            "Epoch 35/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 792.8315 - root_mean_squared_error: 28.1573 - val_loss: 930.7414 - val_root_mean_squared_error: 30.5081\n",
            "Epoch 36/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 789.5344 - root_mean_squared_error: 28.0987 - val_loss: 929.9676 - val_root_mean_squared_error: 30.4954\n",
            "Epoch 37/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 806.9718 - root_mean_squared_error: 28.4072 - val_loss: 934.8183 - val_root_mean_squared_error: 30.5748\n",
            "Epoch 38/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 811.1344 - root_mean_squared_error: 28.4804 - val_loss: 934.8219 - val_root_mean_squared_error: 30.5749\n",
            "Epoch 39/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 796.8276 - root_mean_squared_error: 28.2281 - val_loss: 937.2328 - val_root_mean_squared_error: 30.6143\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "30.49445310975257\n",
            "Epoch 1/500\n",
            "241/241 [==============================] - 4s 8ms/step - loss: 1246.2112 - root_mean_squared_error: 35.3017 - val_loss: 1592.3566 - val_root_mean_squared_error: 39.9043\n",
            "Epoch 2/500\n",
            " 10/241 [>.............................] - ETA: 1s - loss: 939.3419 - root_mean_squared_error: 30.6487 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "241/241 [==============================] - 2s 6ms/step - loss: 958.2677 - root_mean_squared_error: 30.9559 - val_loss: 2326.9993 - val_root_mean_squared_error: 48.2390\n",
            "Epoch 3/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 905.3437 - root_mean_squared_error: 30.0889 - val_loss: 1149.9042 - val_root_mean_squared_error: 33.9102\n",
            "Epoch 4/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 841.7939 - root_mean_squared_error: 29.0137 - val_loss: 849.6742 - val_root_mean_squared_error: 29.1492\n",
            "Epoch 5/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 822.9319 - root_mean_squared_error: 28.6868 - val_loss: 758.3301 - val_root_mean_squared_error: 27.5378\n",
            "Epoch 6/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 802.7153 - root_mean_squared_error: 28.3322 - val_loss: 762.1769 - val_root_mean_squared_error: 27.6076\n",
            "Epoch 7/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 784.2398 - root_mean_squared_error: 28.0043 - val_loss: 759.1157 - val_root_mean_squared_error: 27.5521\n",
            "Epoch 8/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 801.9021 - root_mean_squared_error: 28.3179 - val_loss: 763.0454 - val_root_mean_squared_error: 27.6233\n",
            "Epoch 9/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 775.6669 - root_mean_squared_error: 27.8508 - val_loss: 761.3326 - val_root_mean_squared_error: 27.5923\n",
            "Epoch 10/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 767.1259 - root_mean_squared_error: 27.6970 - val_loss: 783.4285 - val_root_mean_squared_error: 27.9898\n",
            "Epoch 11/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 777.4849 - root_mean_squared_error: 27.8834 - val_loss: 772.7800 - val_root_mean_squared_error: 27.7989\n",
            "Epoch 12/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 784.2353 - root_mean_squared_error: 28.0042 - val_loss: 769.7830 - val_root_mean_squared_error: 27.7450\n",
            "Epoch 13/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 769.6004 - root_mean_squared_error: 27.7417 - val_loss: 773.1140 - val_root_mean_squared_error: 27.8049\n",
            "Epoch 14/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 767.3372 - root_mean_squared_error: 27.7009 - val_loss: 771.0368 - val_root_mean_squared_error: 27.7675\n",
            "Epoch 15/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 772.2695 - root_mean_squared_error: 27.7897 - val_loss: 772.0946 - val_root_mean_squared_error: 27.7866\n",
            "Epoch 16/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 775.4160 - root_mean_squared_error: 27.8463 - val_loss: 771.8234 - val_root_mean_squared_error: 27.7817\n",
            "Epoch 17/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 778.5482 - root_mean_squared_error: 27.9025 - val_loss: 769.3076 - val_root_mean_squared_error: 27.7364\n",
            "Epoch 18/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 766.2687 - root_mean_squared_error: 27.6816 - val_loss: 770.4211 - val_root_mean_squared_error: 27.7565\n",
            "Epoch 19/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 778.9324 - root_mean_squared_error: 27.9094 - val_loss: 771.1774 - val_root_mean_squared_error: 27.7701\n",
            "Epoch 20/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 774.3724 - root_mean_squared_error: 27.8275 - val_loss: 771.3251 - val_root_mean_squared_error: 27.7727\n",
            "Epoch 21/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 776.6561 - root_mean_squared_error: 27.8685 - val_loss: 772.0081 - val_root_mean_squared_error: 27.7850\n",
            "Epoch 22/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 771.4495 - root_mean_squared_error: 27.7750 - val_loss: 772.1577 - val_root_mean_squared_error: 27.7877\n",
            "Epoch 23/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 764.1224 - root_mean_squared_error: 27.6428 - val_loss: 770.0239 - val_root_mean_squared_error: 27.7493\n",
            "Epoch 24/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 765.5135 - root_mean_squared_error: 27.6679 - val_loss: 773.7999 - val_root_mean_squared_error: 27.8173\n",
            "Epoch 25/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 766.1218 - root_mean_squared_error: 27.6789 - val_loss: 771.5472 - val_root_mean_squared_error: 27.7767\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "27.53779167971835\n",
            "Epoch 1/500\n",
            "241/241 [==============================] - 4s 8ms/step - loss: 1221.6245 - root_mean_squared_error: 34.9517 - val_loss: 1314.3503 - val_root_mean_squared_error: 36.2540\n",
            "Epoch 2/500\n",
            "  9/241 [>.............................] - ETA: 1s - loss: 927.0687 - root_mean_squared_error: 30.4478 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "241/241 [==============================] - 2s 7ms/step - loss: 948.0201 - root_mean_squared_error: 30.7899 - val_loss: 1073.4764 - val_root_mean_squared_error: 32.7640\n",
            "Epoch 3/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 880.3629 - root_mean_squared_error: 29.6709 - val_loss: 1140.8884 - val_root_mean_squared_error: 33.7770\n",
            "Epoch 4/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 827.3884 - root_mean_squared_error: 28.7644 - val_loss: 1042.8801 - val_root_mean_squared_error: 32.2937\n",
            "Epoch 5/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 805.2982 - root_mean_squared_error: 28.3778 - val_loss: 1017.0474 - val_root_mean_squared_error: 31.8912\n",
            "Epoch 6/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 797.8494 - root_mean_squared_error: 28.2462 - val_loss: 1022.1279 - val_root_mean_squared_error: 31.9707\n",
            "Epoch 7/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 778.8472 - root_mean_squared_error: 27.9078 - val_loss: 1017.8554 - val_root_mean_squared_error: 31.9038\n",
            "Epoch 8/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 766.7243 - root_mean_squared_error: 27.6898 - val_loss: 1013.8080 - val_root_mean_squared_error: 31.8404\n",
            "Epoch 9/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 758.3057 - root_mean_squared_error: 27.5374 - val_loss: 1020.1246 - val_root_mean_squared_error: 31.9394\n",
            "Epoch 10/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 779.5580 - root_mean_squared_error: 27.9206 - val_loss: 1021.4247 - val_root_mean_squared_error: 31.9597\n",
            "Epoch 11/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 739.0825 - root_mean_squared_error: 27.1861 - val_loss: 1016.1144 - val_root_mean_squared_error: 31.8765\n",
            "Epoch 12/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 766.1340 - root_mean_squared_error: 27.6791 - val_loss: 1021.6037 - val_root_mean_squared_error: 31.9625\n",
            "Epoch 13/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 749.0496 - root_mean_squared_error: 27.3688 - val_loss: 1020.9818 - val_root_mean_squared_error: 31.9528\n",
            "Epoch 14/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 756.9952 - root_mean_squared_error: 27.5135 - val_loss: 1016.6366 - val_root_mean_squared_error: 31.8847\n",
            "Epoch 15/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 758.1562 - root_mean_squared_error: 27.5346 - val_loss: 1020.1910 - val_root_mean_squared_error: 31.9404\n",
            "Epoch 16/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 775.2467 - root_mean_squared_error: 27.8433 - val_loss: 1020.5363 - val_root_mean_squared_error: 31.9458\n",
            "Epoch 17/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 761.8496 - root_mean_squared_error: 27.6016 - val_loss: 1019.9335 - val_root_mean_squared_error: 31.9364\n",
            "Epoch 18/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 758.4908 - root_mean_squared_error: 27.5407 - val_loss: 1018.6520 - val_root_mean_squared_error: 31.9163\n",
            "Epoch 19/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 756.7076 - root_mean_squared_error: 27.5083 - val_loss: 1018.2930 - val_root_mean_squared_error: 31.9107\n",
            "Epoch 20/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 771.2565 - root_mean_squared_error: 27.7715 - val_loss: 1018.4620 - val_root_mean_squared_error: 31.9134\n",
            "Epoch 21/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 754.9581 - root_mean_squared_error: 27.4765 - val_loss: 1023.7311 - val_root_mean_squared_error: 31.9958\n",
            "Epoch 22/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 756.8382 - root_mean_squared_error: 27.5107 - val_loss: 1017.7177 - val_root_mean_squared_error: 31.9017\n",
            "Epoch 23/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 758.5739 - root_mean_squared_error: 27.5422 - val_loss: 1020.0428 - val_root_mean_squared_error: 31.9381\n",
            "Epoch 24/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 756.7684 - root_mean_squared_error: 27.5094 - val_loss: 1019.8099 - val_root_mean_squared_error: 31.9345\n",
            "Epoch 25/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 758.3458 - root_mean_squared_error: 27.5381 - val_loss: 1022.7356 - val_root_mean_squared_error: 31.9802\n",
            "Epoch 26/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 751.2315 - root_mean_squared_error: 27.4086 - val_loss: 1017.2834 - val_root_mean_squared_error: 31.8949\n",
            "Epoch 27/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 749.3694 - root_mean_squared_error: 27.3746 - val_loss: 1014.7830 - val_root_mean_squared_error: 31.8557\n",
            "Epoch 28/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 753.5292 - root_mean_squared_error: 27.4505 - val_loss: 1016.3238 - val_root_mean_squared_error: 31.8798\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "31.8403521096336\n",
            "Epoch 1/500\n",
            "241/241 [==============================] - 4s 8ms/step - loss: 1254.3315 - root_mean_squared_error: 35.4165 - val_loss: 1052.6904 - val_root_mean_squared_error: 32.4452\n",
            "Epoch 2/500\n",
            "  9/241 [>.............................] - ETA: 1s - loss: 891.1049 - root_mean_squared_error: 29.8514 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "241/241 [==============================] - 2s 7ms/step - loss: 944.6306 - root_mean_squared_error: 30.7348 - val_loss: 818.4809 - val_root_mean_squared_error: 28.6091\n",
            "Epoch 3/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 895.9221 - root_mean_squared_error: 29.9320 - val_loss: 748.8750 - val_root_mean_squared_error: 27.3656\n",
            "Epoch 4/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 845.5774 - root_mean_squared_error: 29.0788 - val_loss: 718.1498 - val_root_mean_squared_error: 26.7983\n",
            "Epoch 5/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 810.9866 - root_mean_squared_error: 28.4778 - val_loss: 696.9405 - val_root_mean_squared_error: 26.3996\n",
            "Epoch 6/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 779.6746 - root_mean_squared_error: 27.9227 - val_loss: 669.9597 - val_root_mean_squared_error: 25.8836\n",
            "Epoch 7/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 762.0635 - root_mean_squared_error: 27.6055 - val_loss: 684.3346 - val_root_mean_squared_error: 26.1598\n",
            "Epoch 8/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 761.3832 - root_mean_squared_error: 27.5932 - val_loss: 669.9922 - val_root_mean_squared_error: 25.8842\n",
            "Epoch 9/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 764.4523 - root_mean_squared_error: 27.6487 - val_loss: 664.9102 - val_root_mean_squared_error: 25.7859\n",
            "Epoch 10/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 763.6237 - root_mean_squared_error: 27.6337 - val_loss: 667.8868 - val_root_mean_squared_error: 25.8435\n",
            "Epoch 11/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 761.9680 - root_mean_squared_error: 27.6038 - val_loss: 666.3585 - val_root_mean_squared_error: 25.8139\n",
            "Epoch 12/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 756.1314 - root_mean_squared_error: 27.4978 - val_loss: 666.9942 - val_root_mean_squared_error: 25.8262\n",
            "Epoch 13/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 756.6585 - root_mean_squared_error: 27.5074 - val_loss: 667.5190 - val_root_mean_squared_error: 25.8364\n",
            "Epoch 14/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 763.5320 - root_mean_squared_error: 27.6321 - val_loss: 669.4533 - val_root_mean_squared_error: 25.8738\n",
            "Epoch 15/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 752.2903 - root_mean_squared_error: 27.4279 - val_loss: 668.7686 - val_root_mean_squared_error: 25.8606\n",
            "Epoch 16/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 730.3641 - root_mean_squared_error: 27.0252 - val_loss: 671.3065 - val_root_mean_squared_error: 25.9096\n",
            "Epoch 17/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 763.7148 - root_mean_squared_error: 27.6354 - val_loss: 669.4285 - val_root_mean_squared_error: 25.8733\n",
            "Epoch 18/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 766.6209 - root_mean_squared_error: 27.6879 - val_loss: 670.6193 - val_root_mean_squared_error: 25.8963\n",
            "Epoch 19/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 745.9405 - root_mean_squared_error: 27.3119 - val_loss: 666.0633 - val_root_mean_squared_error: 25.8082\n",
            "Epoch 20/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 761.5012 - root_mean_squared_error: 27.5953 - val_loss: 666.3094 - val_root_mean_squared_error: 25.8130\n",
            "Epoch 21/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 749.0764 - root_mean_squared_error: 27.3693 - val_loss: 666.5057 - val_root_mean_squared_error: 25.8168\n",
            "Epoch 22/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 772.6226 - root_mean_squared_error: 27.7961 - val_loss: 668.9575 - val_root_mean_squared_error: 25.8642\n",
            "Epoch 23/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 755.1739 - root_mean_squared_error: 27.4804 - val_loss: 667.1698 - val_root_mean_squared_error: 25.8296\n",
            "Epoch 24/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 746.7477 - root_mean_squared_error: 27.3267 - val_loss: 666.0638 - val_root_mean_squared_error: 25.8082\n",
            "Epoch 25/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 751.8682 - root_mean_squared_error: 27.4202 - val_loss: 666.8395 - val_root_mean_squared_error: 25.8232\n",
            "Epoch 26/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 751.6656 - root_mean_squared_error: 27.4165 - val_loss: 667.6169 - val_root_mean_squared_error: 25.8383\n",
            "Epoch 27/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 761.6874 - root_mean_squared_error: 27.5987 - val_loss: 670.9451 - val_root_mean_squared_error: 25.9026\n",
            "Epoch 28/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 763.6498 - root_mean_squared_error: 27.6342 - val_loss: 666.9264 - val_root_mean_squared_error: 25.8249\n",
            "Epoch 29/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 751.8885 - root_mean_squared_error: 27.4206 - val_loss: 668.4280 - val_root_mean_squared_error: 25.8540\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "25.785854152309625\n",
            "Epoch 1/500\n",
            "241/241 [==============================] - 4s 8ms/step - loss: 1231.9012 - root_mean_squared_error: 35.0984 - val_loss: 1307.8600 - val_root_mean_squared_error: 36.1643\n",
            "Epoch 2/500\n",
            "  9/241 [>.............................] - ETA: 1s - loss: 1193.1729 - root_mean_squared_error: 34.5423"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "241/241 [==============================] - 2s 7ms/step - loss: 940.7393 - root_mean_squared_error: 30.6715 - val_loss: 939.9817 - val_root_mean_squared_error: 30.6591\n",
            "Epoch 3/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 869.5251 - root_mean_squared_error: 29.4877 - val_loss: 909.6097 - val_root_mean_squared_error: 30.1597\n",
            "Epoch 4/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 837.3807 - root_mean_squared_error: 28.9375 - val_loss: 887.6647 - val_root_mean_squared_error: 29.7937\n",
            "Epoch 5/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 803.4961 - root_mean_squared_error: 28.3460 - val_loss: 884.7249 - val_root_mean_squared_error: 29.7443\n",
            "Epoch 6/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 771.5820 - root_mean_squared_error: 27.7774 - val_loss: 877.8287 - val_root_mean_squared_error: 29.6282\n",
            "Epoch 7/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 766.1939 - root_mean_squared_error: 27.6802 - val_loss: 865.6178 - val_root_mean_squared_error: 29.4214\n",
            "Epoch 8/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 748.2922 - root_mean_squared_error: 27.3549 - val_loss: 865.6055 - val_root_mean_squared_error: 29.4212\n",
            "Epoch 9/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 755.9263 - root_mean_squared_error: 27.4941 - val_loss: 863.7236 - val_root_mean_squared_error: 29.3892\n",
            "Epoch 10/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 757.7376 - root_mean_squared_error: 27.5270 - val_loss: 866.2665 - val_root_mean_squared_error: 29.4324\n",
            "Epoch 11/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 759.3981 - root_mean_squared_error: 27.5572 - val_loss: 868.2455 - val_root_mean_squared_error: 29.4660\n",
            "Epoch 12/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 745.2089 - root_mean_squared_error: 27.2985 - val_loss: 864.9495 - val_root_mean_squared_error: 29.4100\n",
            "Epoch 13/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 754.7516 - root_mean_squared_error: 27.4727 - val_loss: 867.3782 - val_root_mean_squared_error: 29.4513\n",
            "Epoch 14/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 744.0999 - root_mean_squared_error: 27.2782 - val_loss: 868.8197 - val_root_mean_squared_error: 29.4757\n",
            "Epoch 15/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 749.5129 - root_mean_squared_error: 27.3772 - val_loss: 867.9106 - val_root_mean_squared_error: 29.4603\n",
            "Epoch 16/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 761.5593 - root_mean_squared_error: 27.5964 - val_loss: 866.5407 - val_root_mean_squared_error: 29.4371\n",
            "Epoch 17/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 742.3723 - root_mean_squared_error: 27.2465 - val_loss: 866.4788 - val_root_mean_squared_error: 29.4360\n",
            "Epoch 18/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 742.9105 - root_mean_squared_error: 27.2564 - val_loss: 867.7477 - val_root_mean_squared_error: 29.4576\n",
            "Epoch 19/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 758.7919 - root_mean_squared_error: 27.5462 - val_loss: 866.9480 - val_root_mean_squared_error: 29.4440\n",
            "Epoch 20/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 756.1560 - root_mean_squared_error: 27.4983 - val_loss: 867.2786 - val_root_mean_squared_error: 29.4496\n",
            "Epoch 21/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 764.3250 - root_mean_squared_error: 27.6464 - val_loss: 865.4393 - val_root_mean_squared_error: 29.4184\n",
            "Epoch 22/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 762.9170 - root_mean_squared_error: 27.6210 - val_loss: 867.7850 - val_root_mean_squared_error: 29.4582\n",
            "Epoch 23/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 761.8608 - root_mean_squared_error: 27.6018 - val_loss: 867.1854 - val_root_mean_squared_error: 29.4480\n",
            "Epoch 24/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 745.8393 - root_mean_squared_error: 27.3101 - val_loss: 863.9347 - val_root_mean_squared_error: 29.3928\n",
            "Epoch 25/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 753.4759 - root_mean_squared_error: 27.4495 - val_loss: 866.1025 - val_root_mean_squared_error: 29.4296\n",
            "Epoch 26/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 746.4976 - root_mean_squared_error: 27.3221 - val_loss: 865.7202 - val_root_mean_squared_error: 29.4231\n",
            "Epoch 27/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 763.3832 - root_mean_squared_error: 27.6294 - val_loss: 867.5026 - val_root_mean_squared_error: 29.4534\n",
            "Epoch 28/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 754.1987 - root_mean_squared_error: 27.4627 - val_loss: 864.5959 - val_root_mean_squared_error: 29.4040\n",
            "Epoch 29/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 747.4243 - root_mean_squared_error: 27.3391 - val_loss: 869.2011 - val_root_mean_squared_error: 29.4822\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "29.389176039485893\n",
            "Epoch 1/500\n",
            "241/241 [==============================] - 4s 8ms/step - loss: 1246.4922 - root_mean_squared_error: 35.3057 - val_loss: 1352.0487 - val_root_mean_squared_error: 36.7702\n",
            "Epoch 2/500\n",
            "  9/241 [>.............................] - ETA: 1s - loss: 894.5835 - root_mean_squared_error: 29.9096"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "241/241 [==============================] - 2s 7ms/step - loss: 943.7394 - root_mean_squared_error: 30.7203 - val_loss: 971.1420 - val_root_mean_squared_error: 31.1632\n",
            "Epoch 3/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 868.5599 - root_mean_squared_error: 29.4713 - val_loss: 1316.6285 - val_root_mean_squared_error: 36.2854\n",
            "Epoch 4/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 849.6124 - root_mean_squared_error: 29.1481 - val_loss: 962.1282 - val_root_mean_squared_error: 31.0182\n",
            "Epoch 5/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 805.1697 - root_mean_squared_error: 28.3755 - val_loss: 999.1310 - val_root_mean_squared_error: 31.6090\n",
            "Epoch 6/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 800.3043 - root_mean_squared_error: 28.2896 - val_loss: 968.5489 - val_root_mean_squared_error: 31.1215\n",
            "Epoch 7/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 787.0083 - root_mean_squared_error: 28.0537 - val_loss: 976.7633 - val_root_mean_squared_error: 31.2532\n",
            "Epoch 8/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 748.7987 - root_mean_squared_error: 27.3642 - val_loss: 986.2692 - val_root_mean_squared_error: 31.4049\n",
            "Epoch 9/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 757.4327 - root_mean_squared_error: 27.5215 - val_loss: 987.8472 - val_root_mean_squared_error: 31.4300\n",
            "Epoch 10/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 753.1921 - root_mean_squared_error: 27.4443 - val_loss: 986.1601 - val_root_mean_squared_error: 31.4032\n",
            "Epoch 11/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 756.2865 - root_mean_squared_error: 27.5007 - val_loss: 988.7430 - val_root_mean_squared_error: 31.4443\n",
            "Epoch 12/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 761.6237 - root_mean_squared_error: 27.5975 - val_loss: 989.4260 - val_root_mean_squared_error: 31.4551\n",
            "Epoch 13/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 751.8615 - root_mean_squared_error: 27.4201 - val_loss: 990.7010 - val_root_mean_squared_error: 31.4754\n",
            "Epoch 14/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 751.5795 - root_mean_squared_error: 27.4149 - val_loss: 989.6873 - val_root_mean_squared_error: 31.4593\n",
            "Epoch 15/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 755.2164 - root_mean_squared_error: 27.4812 - val_loss: 994.6635 - val_root_mean_squared_error: 31.5383\n",
            "Epoch 16/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 751.5170 - root_mean_squared_error: 27.4138 - val_loss: 992.6666 - val_root_mean_squared_error: 31.5066\n",
            "Epoch 17/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 761.4753 - root_mean_squared_error: 27.5948 - val_loss: 993.5845 - val_root_mean_squared_error: 31.5212\n",
            "Epoch 18/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 755.3615 - root_mean_squared_error: 27.4838 - val_loss: 990.7101 - val_root_mean_squared_error: 31.4755\n",
            "Epoch 19/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 764.2972 - root_mean_squared_error: 27.6459 - val_loss: 990.5349 - val_root_mean_squared_error: 31.4728\n",
            "Epoch 20/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 761.5772 - root_mean_squared_error: 27.5967 - val_loss: 994.2774 - val_root_mean_squared_error: 31.5322\n",
            "Epoch 21/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 742.1790 - root_mean_squared_error: 27.2430 - val_loss: 986.1995 - val_root_mean_squared_error: 31.4038\n",
            "Epoch 22/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 761.2481 - root_mean_squared_error: 27.5907 - val_loss: 991.5582 - val_root_mean_squared_error: 31.4890\n",
            "Epoch 23/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 767.6559 - root_mean_squared_error: 27.7066 - val_loss: 990.4238 - val_root_mean_squared_error: 31.4710\n",
            "Epoch 24/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 756.4084 - root_mean_squared_error: 27.5029 - val_loss: 993.6600 - val_root_mean_squared_error: 31.5224\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "31.018193619998684\n",
            "Epoch 1/500\n",
            "241/241 [==============================] - 5s 10ms/step - loss: 1227.4281 - root_mean_squared_error: 35.0347 - val_loss: 1281.3593 - val_root_mean_squared_error: 35.7961\n",
            "Epoch 2/500\n",
            "  9/241 [>.............................] - ETA: 1s - loss: 848.2908 - root_mean_squared_error: 29.1254 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "241/241 [==============================] - 2s 6ms/step - loss: 955.1485 - root_mean_squared_error: 30.9055 - val_loss: 2492.9482 - val_root_mean_squared_error: 49.9294\n",
            "Epoch 3/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 890.7745 - root_mean_squared_error: 29.8458 - val_loss: 1006.9413 - val_root_mean_squared_error: 31.7323\n",
            "Epoch 4/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 833.3052 - root_mean_squared_error: 28.8670 - val_loss: 1010.2051 - val_root_mean_squared_error: 31.7837\n",
            "Epoch 5/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 810.9666 - root_mean_squared_error: 28.4775 - val_loss: 951.7338 - val_root_mean_squared_error: 30.8502\n",
            "Epoch 6/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 764.2907 - root_mean_squared_error: 27.6458 - val_loss: 932.9084 - val_root_mean_squared_error: 30.5435\n",
            "Epoch 7/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 755.7994 - root_mean_squared_error: 27.4918 - val_loss: 946.8978 - val_root_mean_squared_error: 30.7717\n",
            "Epoch 8/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 759.9374 - root_mean_squared_error: 27.5670 - val_loss: 949.2398 - val_root_mean_squared_error: 30.8097\n",
            "Epoch 9/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 757.6937 - root_mean_squared_error: 27.5262 - val_loss: 952.0773 - val_root_mean_squared_error: 30.8557\n",
            "Epoch 10/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 759.9864 - root_mean_squared_error: 27.5679 - val_loss: 961.2479 - val_root_mean_squared_error: 31.0040\n",
            "Epoch 11/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 753.4668 - root_mean_squared_error: 27.4493 - val_loss: 966.4581 - val_root_mean_squared_error: 31.0879\n",
            "Epoch 12/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 755.0797 - root_mean_squared_error: 27.4787 - val_loss: 957.6835 - val_root_mean_squared_error: 30.9465\n",
            "Epoch 13/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 746.6427 - root_mean_squared_error: 27.3248 - val_loss: 955.7455 - val_root_mean_squared_error: 30.9151\n",
            "Epoch 14/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 734.9864 - root_mean_squared_error: 27.1106 - val_loss: 951.8534 - val_root_mean_squared_error: 30.8521\n",
            "Epoch 15/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 748.7339 - root_mean_squared_error: 27.3630 - val_loss: 952.3184 - val_root_mean_squared_error: 30.8597\n",
            "Epoch 16/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 736.3813 - root_mean_squared_error: 27.1363 - val_loss: 954.0441 - val_root_mean_squared_error: 30.8876\n",
            "Epoch 17/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 755.0779 - root_mean_squared_error: 27.4787 - val_loss: 960.5189 - val_root_mean_squared_error: 30.9922\n",
            "Epoch 18/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 757.6425 - root_mean_squared_error: 27.5253 - val_loss: 962.4470 - val_root_mean_squared_error: 31.0233\n",
            "Epoch 19/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 760.1706 - root_mean_squared_error: 27.5712 - val_loss: 961.4940 - val_root_mean_squared_error: 31.0080\n",
            "Epoch 20/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 747.9991 - root_mean_squared_error: 27.3496 - val_loss: 960.3441 - val_root_mean_squared_error: 30.9894\n",
            "Epoch 21/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 758.0189 - root_mean_squared_error: 27.5321 - val_loss: 957.9805 - val_root_mean_squared_error: 30.9513\n",
            "Epoch 22/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 760.7764 - root_mean_squared_error: 27.5822 - val_loss: 957.4435 - val_root_mean_squared_error: 30.9426\n",
            "Epoch 23/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 746.9827 - root_mean_squared_error: 27.3310 - val_loss: 962.1910 - val_root_mean_squared_error: 31.0192\n",
            "Epoch 24/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 750.9409 - root_mean_squared_error: 27.4033 - val_loss: 956.1785 - val_root_mean_squared_error: 30.9221\n",
            "Epoch 25/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 752.4359 - root_mean_squared_error: 27.4306 - val_loss: 958.1606 - val_root_mean_squared_error: 30.9542\n",
            "Epoch 26/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 753.9517 - root_mean_squared_error: 27.4582 - val_loss: 952.6259 - val_root_mean_squared_error: 30.8646\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "30.543549952138832\n",
            "Epoch 1/500\n",
            "241/241 [==============================] - 4s 8ms/step - loss: 1226.4551 - root_mean_squared_error: 35.0208 - val_loss: 1165.6072 - val_root_mean_squared_error: 34.1410\n",
            "Epoch 2/500\n",
            "  9/241 [>.............................] - ETA: 1s - loss: 818.4464 - root_mean_squared_error: 28.6085"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "241/241 [==============================] - 2s 7ms/step - loss: 930.2214 - root_mean_squared_error: 30.4995 - val_loss: 977.5208 - val_root_mean_squared_error: 31.2653\n",
            "Epoch 3/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 853.0997 - root_mean_squared_error: 29.2079 - val_loss: 965.9774 - val_root_mean_squared_error: 31.0802\n",
            "Epoch 4/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 823.7294 - root_mean_squared_error: 28.7007 - val_loss: 1028.7188 - val_root_mean_squared_error: 32.0736\n",
            "Epoch 5/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 801.1185 - root_mean_squared_error: 28.3040 - val_loss: 951.2590 - val_root_mean_squared_error: 30.8425\n",
            "Epoch 6/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 805.7645 - root_mean_squared_error: 28.3860 - val_loss: 933.1534 - val_root_mean_squared_error: 30.5476\n",
            "Epoch 7/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 771.5453 - root_mean_squared_error: 27.7767 - val_loss: 942.7531 - val_root_mean_squared_error: 30.7043\n",
            "Epoch 8/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 779.0649 - root_mean_squared_error: 27.9117 - val_loss: 934.5695 - val_root_mean_squared_error: 30.5707\n",
            "Epoch 9/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 761.5291 - root_mean_squared_error: 27.5958 - val_loss: 939.8264 - val_root_mean_squared_error: 30.6566\n",
            "Epoch 10/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 770.4548 - root_mean_squared_error: 27.7571 - val_loss: 937.1406 - val_root_mean_squared_error: 30.6128\n",
            "Epoch 11/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 762.9707 - root_mean_squared_error: 27.6219 - val_loss: 934.8414 - val_root_mean_squared_error: 30.5752\n",
            "Epoch 12/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 768.8761 - root_mean_squared_error: 27.7286 - val_loss: 936.8422 - val_root_mean_squared_error: 30.6079\n",
            "Epoch 13/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 760.5546 - root_mean_squared_error: 27.5782 - val_loss: 939.2455 - val_root_mean_squared_error: 30.6471\n",
            "Epoch 14/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 752.2603 - root_mean_squared_error: 27.4274 - val_loss: 939.5463 - val_root_mean_squared_error: 30.6520\n",
            "Epoch 15/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 749.5013 - root_mean_squared_error: 27.3770 - val_loss: 937.6860 - val_root_mean_squared_error: 30.6217\n",
            "Epoch 16/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 763.7021 - root_mean_squared_error: 27.6352 - val_loss: 935.8722 - val_root_mean_squared_error: 30.5920\n",
            "Epoch 17/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 771.3087 - root_mean_squared_error: 27.7724 - val_loss: 935.9432 - val_root_mean_squared_error: 30.5932\n",
            "Epoch 18/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 757.4485 - root_mean_squared_error: 27.5218 - val_loss: 938.3645 - val_root_mean_squared_error: 30.6327\n",
            "Epoch 19/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 754.6680 - root_mean_squared_error: 27.4712 - val_loss: 934.9176 - val_root_mean_squared_error: 30.5764\n",
            "Epoch 20/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 752.0278 - root_mean_squared_error: 27.4231 - val_loss: 939.4088 - val_root_mean_squared_error: 30.6498\n",
            "Epoch 21/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 753.3881 - root_mean_squared_error: 27.4479 - val_loss: 939.3950 - val_root_mean_squared_error: 30.6496\n",
            "Epoch 22/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 760.1821 - root_mean_squared_error: 27.5714 - val_loss: 935.6216 - val_root_mean_squared_error: 30.5879\n",
            "Epoch 23/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 768.5173 - root_mean_squared_error: 27.7221 - val_loss: 940.6055 - val_root_mean_squared_error: 30.6693\n",
            "Epoch 24/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 762.0061 - root_mean_squared_error: 27.6045 - val_loss: 938.2945 - val_root_mean_squared_error: 30.6316\n",
            "Epoch 25/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 751.8826 - root_mean_squared_error: 27.4205 - val_loss: 936.4963 - val_root_mean_squared_error: 30.6022\n",
            "Epoch 26/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 777.1600 - root_mean_squared_error: 27.8776 - val_loss: 935.4873 - val_root_mean_squared_error: 30.5857\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "30.547561090862953\n",
            "Epoch 1/500\n",
            "241/241 [==============================] - 4s 8ms/step - loss: 1225.7924 - root_mean_squared_error: 35.0113 - val_loss: 1230.7261 - val_root_mean_squared_error: 35.0817\n",
            "Epoch 2/500\n",
            " 10/241 [>.............................] - ETA: 1s - loss: 939.7377 - root_mean_squared_error: 30.6551 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "241/241 [==============================] - 2s 7ms/step - loss: 924.9633 - root_mean_squared_error: 30.4132 - val_loss: 1108.8002 - val_root_mean_squared_error: 33.2986\n",
            "Epoch 3/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 869.5213 - root_mean_squared_error: 29.4876 - val_loss: 1011.4711 - val_root_mean_squared_error: 31.8036\n",
            "Epoch 4/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 826.8135 - root_mean_squared_error: 28.7544 - val_loss: 975.5798 - val_root_mean_squared_error: 31.2343\n",
            "Epoch 5/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 797.2003 - root_mean_squared_error: 28.2347 - val_loss: 985.2294 - val_root_mean_squared_error: 31.3884\n",
            "Epoch 6/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 771.3656 - root_mean_squared_error: 27.7735 - val_loss: 994.5396 - val_root_mean_squared_error: 31.5363\n",
            "Epoch 7/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 763.0049 - root_mean_squared_error: 27.6225 - val_loss: 1000.7698 - val_root_mean_squared_error: 31.6349\n",
            "Epoch 8/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 746.8951 - root_mean_squared_error: 27.3294 - val_loss: 999.9227 - val_root_mean_squared_error: 31.6216\n",
            "Epoch 9/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 759.0428 - root_mean_squared_error: 27.5507 - val_loss: 1004.3403 - val_root_mean_squared_error: 31.6913\n",
            "Epoch 10/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 724.8988 - root_mean_squared_error: 26.9239 - val_loss: 1002.1808 - val_root_mean_squared_error: 31.6572\n",
            "Epoch 11/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 759.3859 - root_mean_squared_error: 27.5570 - val_loss: 1006.6022 - val_root_mean_squared_error: 31.7270\n",
            "Epoch 12/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 732.3248 - root_mean_squared_error: 27.0615 - val_loss: 1000.9666 - val_root_mean_squared_error: 31.6381\n",
            "Epoch 13/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 734.4560 - root_mean_squared_error: 27.1008 - val_loss: 1005.6001 - val_root_mean_squared_error: 31.7112\n",
            "Epoch 14/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 745.9122 - root_mean_squared_error: 27.3114 - val_loss: 1005.1257 - val_root_mean_squared_error: 31.7037\n",
            "Epoch 15/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 744.4618 - root_mean_squared_error: 27.2848 - val_loss: 1005.5312 - val_root_mean_squared_error: 31.7101\n",
            "Epoch 16/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 738.0266 - root_mean_squared_error: 27.1666 - val_loss: 1007.8611 - val_root_mean_squared_error: 31.7468\n",
            "Epoch 17/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 732.9473 - root_mean_squared_error: 27.0730 - val_loss: 1004.0778 - val_root_mean_squared_error: 31.6872\n",
            "Epoch 18/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 752.8432 - root_mean_squared_error: 27.4380 - val_loss: 1003.3739 - val_root_mean_squared_error: 31.6761\n",
            "Epoch 19/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 730.2236 - root_mean_squared_error: 27.0226 - val_loss: 1001.6929 - val_root_mean_squared_error: 31.6495\n",
            "Epoch 20/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 737.5070 - root_mean_squared_error: 27.1571 - val_loss: 1003.4990 - val_root_mean_squared_error: 31.6781\n",
            "Epoch 21/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 740.1528 - root_mean_squared_error: 27.2057 - val_loss: 1003.3984 - val_root_mean_squared_error: 31.6765\n",
            "Epoch 22/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 749.4998 - root_mean_squared_error: 27.3770 - val_loss: 1006.9141 - val_root_mean_squared_error: 31.7319\n",
            "Epoch 23/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 734.4968 - root_mean_squared_error: 27.1016 - val_loss: 1006.4517 - val_root_mean_squared_error: 31.7246\n",
            "Epoch 24/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 735.7593 - root_mean_squared_error: 27.1249 - val_loss: 1004.1904 - val_root_mean_squared_error: 31.6890\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "31.234273840337583\n",
            "Epoch 1/500\n",
            "241/241 [==============================] - 4s 9ms/step - loss: 1242.9574 - root_mean_squared_error: 35.2556 - val_loss: 1063.9861 - val_root_mean_squared_error: 32.6188\n",
            "Epoch 2/500\n",
            " 10/241 [>.............................] - ETA: 1s - loss: 1120.1621 - root_mean_squared_error: 33.4688"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "241/241 [==============================] - 2s 6ms/step - loss: 934.6320 - root_mean_squared_error: 30.5718 - val_loss: 981.1650 - val_root_mean_squared_error: 31.3236\n",
            "Epoch 3/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 865.9468 - root_mean_squared_error: 29.4270 - val_loss: 1007.0223 - val_root_mean_squared_error: 31.7336\n",
            "Epoch 4/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 817.9219 - root_mean_squared_error: 28.5993 - val_loss: 957.8275 - val_root_mean_squared_error: 30.9488\n",
            "Epoch 5/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 774.4199 - root_mean_squared_error: 27.8284 - val_loss: 962.8100 - val_root_mean_squared_error: 31.0292\n",
            "Epoch 6/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 785.6662 - root_mean_squared_error: 28.0297 - val_loss: 954.4209 - val_root_mean_squared_error: 30.8937\n",
            "Epoch 7/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 775.0671 - root_mean_squared_error: 27.8400 - val_loss: 939.6512 - val_root_mean_squared_error: 30.6537\n",
            "Epoch 8/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 749.0158 - root_mean_squared_error: 27.3682 - val_loss: 937.9282 - val_root_mean_squared_error: 30.6256\n",
            "Epoch 9/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 751.6440 - root_mean_squared_error: 27.4161 - val_loss: 934.6329 - val_root_mean_squared_error: 30.5718\n",
            "Epoch 10/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 741.1078 - root_mean_squared_error: 27.2233 - val_loss: 938.6033 - val_root_mean_squared_error: 30.6366\n",
            "Epoch 11/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 739.4144 - root_mean_squared_error: 27.1922 - val_loss: 940.5994 - val_root_mean_squared_error: 30.6692\n",
            "Epoch 12/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 742.5848 - root_mean_squared_error: 27.2504 - val_loss: 941.7907 - val_root_mean_squared_error: 30.6886\n",
            "Epoch 13/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 752.7457 - root_mean_squared_error: 27.4362 - val_loss: 943.1259 - val_root_mean_squared_error: 30.7104\n",
            "Epoch 14/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 742.6358 - root_mean_squared_error: 27.2513 - val_loss: 939.0322 - val_root_mean_squared_error: 30.6436\n",
            "Epoch 15/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 737.0341 - root_mean_squared_error: 27.1484 - val_loss: 942.8386 - val_root_mean_squared_error: 30.7057\n",
            "Epoch 16/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 738.3608 - root_mean_squared_error: 27.1728 - val_loss: 942.8281 - val_root_mean_squared_error: 30.7055\n",
            "Epoch 17/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 751.7326 - root_mean_squared_error: 27.4177 - val_loss: 941.0588 - val_root_mean_squared_error: 30.6767\n",
            "Epoch 18/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 746.5840 - root_mean_squared_error: 27.3237 - val_loss: 938.7227 - val_root_mean_squared_error: 30.6386\n",
            "Epoch 19/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 740.8267 - root_mean_squared_error: 27.2181 - val_loss: 940.5433 - val_root_mean_squared_error: 30.6683\n",
            "Epoch 20/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 737.1083 - root_mean_squared_error: 27.1497 - val_loss: 943.7141 - val_root_mean_squared_error: 30.7199\n",
            "Epoch 21/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 737.5978 - root_mean_squared_error: 27.1588 - val_loss: 937.9511 - val_root_mean_squared_error: 30.6260\n",
            "Epoch 22/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 730.3325 - root_mean_squared_error: 27.0247 - val_loss: 939.3599 - val_root_mean_squared_error: 30.6490\n",
            "Epoch 23/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 742.2720 - root_mean_squared_error: 27.2447 - val_loss: 942.5294 - val_root_mean_squared_error: 30.7006\n",
            "Epoch 24/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 743.3807 - root_mean_squared_error: 27.2650 - val_loss: 942.2280 - val_root_mean_squared_error: 30.6957\n",
            "Epoch 25/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 732.8951 - root_mean_squared_error: 27.0720 - val_loss: 940.5562 - val_root_mean_squared_error: 30.6685\n",
            "Epoch 26/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 742.7303 - root_mean_squared_error: 27.2531 - val_loss: 940.2401 - val_root_mean_squared_error: 30.6633\n",
            "Epoch 27/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 737.9591 - root_mean_squared_error: 27.1654 - val_loss: 938.5189 - val_root_mean_squared_error: 30.6353\n",
            "Epoch 28/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 744.5449 - root_mean_squared_error: 27.2863 - val_loss: 940.8609 - val_root_mean_squared_error: 30.6735\n",
            "Epoch 29/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 760.2939 - root_mean_squared_error: 27.5734 - val_loss: 942.4624 - val_root_mean_squared_error: 30.6996\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "30.57176662211275\n",
            "Epoch 1/500\n",
            "241/241 [==============================] - 4s 8ms/step - loss: 1232.2040 - root_mean_squared_error: 35.1028 - val_loss: 1119.6731 - val_root_mean_squared_error: 33.4615\n",
            "Epoch 2/500\n",
            "  9/241 [>.............................] - ETA: 1s - loss: 776.4562 - root_mean_squared_error: 27.8650"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "241/241 [==============================] - 2s 7ms/step - loss: 950.8755 - root_mean_squared_error: 30.8363 - val_loss: 896.2538 - val_root_mean_squared_error: 29.9375\n",
            "Epoch 3/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 887.9944 - root_mean_squared_error: 29.7992 - val_loss: 873.9819 - val_root_mean_squared_error: 29.5632\n",
            "Epoch 4/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 846.0316 - root_mean_squared_error: 29.0866 - val_loss: 850.6446 - val_root_mean_squared_error: 29.1658\n",
            "Epoch 5/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 808.2520 - root_mean_squared_error: 28.4298 - val_loss: 830.2342 - val_root_mean_squared_error: 28.8138\n",
            "Epoch 6/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 769.9250 - root_mean_squared_error: 27.7475 - val_loss: 832.6691 - val_root_mean_squared_error: 28.8560\n",
            "Epoch 7/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 759.6024 - root_mean_squared_error: 27.5609 - val_loss: 829.2974 - val_root_mean_squared_error: 28.7975\n",
            "Epoch 8/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 749.9094 - root_mean_squared_error: 27.3845 - val_loss: 832.6039 - val_root_mean_squared_error: 28.8549\n",
            "Epoch 9/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 760.3858 - root_mean_squared_error: 27.5751 - val_loss: 830.7592 - val_root_mean_squared_error: 28.8229\n",
            "Epoch 10/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 762.2453 - root_mean_squared_error: 27.6088 - val_loss: 832.7940 - val_root_mean_squared_error: 28.8582\n",
            "Epoch 11/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 750.2670 - root_mean_squared_error: 27.3910 - val_loss: 828.9716 - val_root_mean_squared_error: 28.7919\n",
            "Epoch 12/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 747.4494 - root_mean_squared_error: 27.3395 - val_loss: 832.6697 - val_root_mean_squared_error: 28.8560\n",
            "Epoch 13/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 745.4153 - root_mean_squared_error: 27.3023 - val_loss: 826.5320 - val_root_mean_squared_error: 28.7495\n",
            "Epoch 14/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 767.0161 - root_mean_squared_error: 27.6951 - val_loss: 832.4992 - val_root_mean_squared_error: 28.8531\n",
            "Epoch 15/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 763.9739 - root_mean_squared_error: 27.6401 - val_loss: 830.0868 - val_root_mean_squared_error: 28.8112\n",
            "Epoch 16/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 756.0882 - root_mean_squared_error: 27.4971 - val_loss: 831.1227 - val_root_mean_squared_error: 28.8292\n",
            "Epoch 17/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 754.5146 - root_mean_squared_error: 27.4684 - val_loss: 829.8186 - val_root_mean_squared_error: 28.8066\n",
            "Epoch 18/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 763.7328 - root_mean_squared_error: 27.6357 - val_loss: 830.7821 - val_root_mean_squared_error: 28.8233\n",
            "Epoch 19/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 760.4439 - root_mean_squared_error: 27.5761 - val_loss: 831.0746 - val_root_mean_squared_error: 28.8284\n",
            "Epoch 20/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 755.6707 - root_mean_squared_error: 27.4895 - val_loss: 831.2628 - val_root_mean_squared_error: 28.8316\n",
            "Epoch 21/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 742.5781 - root_mean_squared_error: 27.2503 - val_loss: 828.7100 - val_root_mean_squared_error: 28.7873\n",
            "Epoch 22/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 749.8609 - root_mean_squared_error: 27.3836 - val_loss: 830.6743 - val_root_mean_squared_error: 28.8214\n",
            "Epoch 23/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 760.0082 - root_mean_squared_error: 27.5682 - val_loss: 833.9333 - val_root_mean_squared_error: 28.8779\n",
            "Epoch 24/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 744.0122 - root_mean_squared_error: 27.2766 - val_loss: 834.1068 - val_root_mean_squared_error: 28.8809\n",
            "Epoch 25/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 763.3568 - root_mean_squared_error: 27.6289 - val_loss: 829.3658 - val_root_mean_squared_error: 28.7987\n",
            "Epoch 26/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 760.1687 - root_mean_squared_error: 27.5712 - val_loss: 831.8715 - val_root_mean_squared_error: 28.8422\n",
            "Epoch 27/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 746.2822 - root_mean_squared_error: 27.3182 - val_loss: 830.4048 - val_root_mean_squared_error: 28.8167\n",
            "Epoch 28/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 747.2856 - root_mean_squared_error: 27.3365 - val_loss: 828.8417 - val_root_mean_squared_error: 28.7896\n",
            "Epoch 29/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 737.9980 - root_mean_squared_error: 27.1661 - val_loss: 831.7960 - val_root_mean_squared_error: 28.8409\n",
            "Epoch 30/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 752.0145 - root_mean_squared_error: 27.4229 - val_loss: 830.9456 - val_root_mean_squared_error: 28.8261\n",
            "Epoch 31/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 759.3945 - root_mean_squared_error: 27.5571 - val_loss: 829.7576 - val_root_mean_squared_error: 28.8055\n",
            "Epoch 32/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 773.3291 - root_mean_squared_error: 27.8088 - val_loss: 829.7910 - val_root_mean_squared_error: 28.8061\n",
            "Epoch 33/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 750.8351 - root_mean_squared_error: 27.4014 - val_loss: 832.2732 - val_root_mean_squared_error: 28.8491\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "28.74947198083204\n",
            "Epoch 1/500\n",
            "241/241 [==============================] - 4s 8ms/step - loss: 1225.7639 - root_mean_squared_error: 35.0109 - val_loss: 955.6263 - val_root_mean_squared_error: 30.9132\n",
            "Epoch 2/500\n",
            "  9/241 [>.............................] - ETA: 1s - loss: 841.9416 - root_mean_squared_error: 29.0162"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "241/241 [==============================] - 2s 6ms/step - loss: 935.4200 - root_mean_squared_error: 30.5846 - val_loss: 1185.2892 - val_root_mean_squared_error: 34.4280\n",
            "Epoch 3/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 881.5842 - root_mean_squared_error: 29.6915 - val_loss: 784.1912 - val_root_mean_squared_error: 28.0034\n",
            "Epoch 4/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 844.7078 - root_mean_squared_error: 29.0639 - val_loss: 772.2146 - val_root_mean_squared_error: 27.7887\n",
            "Epoch 5/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 827.8607 - root_mean_squared_error: 28.7726 - val_loss: 768.1951 - val_root_mean_squared_error: 27.7163\n",
            "Epoch 6/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 778.7684 - root_mean_squared_error: 27.9064 - val_loss: 749.8976 - val_root_mean_squared_error: 27.3843\n",
            "Epoch 7/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 768.4642 - root_mean_squared_error: 27.7212 - val_loss: 746.8503 - val_root_mean_squared_error: 27.3286\n",
            "Epoch 8/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 761.6472 - root_mean_squared_error: 27.5980 - val_loss: 740.4159 - val_root_mean_squared_error: 27.2106\n",
            "Epoch 9/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 761.9349 - root_mean_squared_error: 27.6032 - val_loss: 742.0819 - val_root_mean_squared_error: 27.2412\n",
            "Epoch 10/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 773.9182 - root_mean_squared_error: 27.8194 - val_loss: 736.7725 - val_root_mean_squared_error: 27.1436\n",
            "Epoch 11/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 772.3230 - root_mean_squared_error: 27.7907 - val_loss: 740.5344 - val_root_mean_squared_error: 27.2128\n",
            "Epoch 12/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 769.3917 - root_mean_squared_error: 27.7379 - val_loss: 737.5099 - val_root_mean_squared_error: 27.1571\n",
            "Epoch 13/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 740.1795 - root_mean_squared_error: 27.2062 - val_loss: 741.7534 - val_root_mean_squared_error: 27.2352\n",
            "Epoch 14/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 755.4901 - root_mean_squared_error: 27.4862 - val_loss: 738.3262 - val_root_mean_squared_error: 27.1722\n",
            "Epoch 15/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 762.9666 - root_mean_squared_error: 27.6219 - val_loss: 735.8734 - val_root_mean_squared_error: 27.1270\n",
            "Epoch 16/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 766.5071 - root_mean_squared_error: 27.6859 - val_loss: 740.8713 - val_root_mean_squared_error: 27.2190\n",
            "Epoch 17/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 766.2687 - root_mean_squared_error: 27.6816 - val_loss: 734.3239 - val_root_mean_squared_error: 27.0984\n",
            "Epoch 18/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 769.3474 - root_mean_squared_error: 27.7371 - val_loss: 736.3539 - val_root_mean_squared_error: 27.1358\n",
            "Epoch 19/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 761.4303 - root_mean_squared_error: 27.5940 - val_loss: 735.3457 - val_root_mean_squared_error: 27.1173\n",
            "Epoch 20/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 762.2927 - root_mean_squared_error: 27.6096 - val_loss: 735.6377 - val_root_mean_squared_error: 27.1226\n",
            "Epoch 21/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 769.4014 - root_mean_squared_error: 27.7381 - val_loss: 738.6505 - val_root_mean_squared_error: 27.1781\n",
            "Epoch 22/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 754.8115 - root_mean_squared_error: 27.4738 - val_loss: 735.6310 - val_root_mean_squared_error: 27.1225\n",
            "Epoch 23/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 765.5241 - root_mean_squared_error: 27.6681 - val_loss: 735.4840 - val_root_mean_squared_error: 27.1198\n",
            "Epoch 24/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 764.7561 - root_mean_squared_error: 27.6542 - val_loss: 738.9917 - val_root_mean_squared_error: 27.1844\n",
            "Epoch 25/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 756.0820 - root_mean_squared_error: 27.4969 - val_loss: 735.9187 - val_root_mean_squared_error: 27.1278\n",
            "Epoch 26/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 757.3228 - root_mean_squared_error: 27.5195 - val_loss: 736.1354 - val_root_mean_squared_error: 27.1318\n",
            "Epoch 27/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 766.6204 - root_mean_squared_error: 27.6879 - val_loss: 739.6029 - val_root_mean_squared_error: 27.1956\n",
            "Epoch 28/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 766.3322 - root_mean_squared_error: 27.6827 - val_loss: 738.3809 - val_root_mean_squared_error: 27.1732\n",
            "Epoch 29/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 783.2632 - root_mean_squared_error: 27.9868 - val_loss: 734.5800 - val_root_mean_squared_error: 27.1031\n",
            "Epoch 30/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 752.4782 - root_mean_squared_error: 27.4313 - val_loss: 736.8365 - val_root_mean_squared_error: 27.1447\n",
            "Epoch 31/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 759.8583 - root_mean_squared_error: 27.5655 - val_loss: 737.9813 - val_root_mean_squared_error: 27.1658\n",
            "Epoch 32/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 759.1443 - root_mean_squared_error: 27.5526 - val_loss: 738.8271 - val_root_mean_squared_error: 27.1814\n",
            "Epoch 33/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 755.7036 - root_mean_squared_error: 27.4901 - val_loss: 738.8230 - val_root_mean_squared_error: 27.1813\n",
            "Epoch 34/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 748.9417 - root_mean_squared_error: 27.3668 - val_loss: 739.3275 - val_root_mean_squared_error: 27.1906\n",
            "Epoch 35/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 741.7391 - root_mean_squared_error: 27.2349 - val_loss: 739.6815 - val_root_mean_squared_error: 27.1971\n",
            "Epoch 36/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 776.0873 - root_mean_squared_error: 27.8583 - val_loss: 735.1827 - val_root_mean_squared_error: 27.1143\n",
            "Epoch 37/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 739.0724 - root_mean_squared_error: 27.1859 - val_loss: 736.1345 - val_root_mean_squared_error: 27.1318\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "27.098410122633993\n",
            "Epoch 1/500\n",
            "239/241 [============================>.] - ETA: 0s - loss: 1246.1218 - root_mean_squared_error: 35.3004"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 5s 10ms/step - loss: 1244.5668 - root_mean_squared_error: 35.2784 - val_loss: 984.1927 - val_root_mean_squared_error: 31.3718\n",
            "Epoch 2/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 938.7347 - root_mean_squared_error: 30.6388 - val_loss: 988.3545 - val_root_mean_squared_error: 31.4381\n",
            "Epoch 3/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 878.2601 - root_mean_squared_error: 29.6355 - val_loss: 905.5310 - val_root_mean_squared_error: 30.0920\n",
            "Epoch 4/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 839.9728 - root_mean_squared_error: 28.9823 - val_loss: 901.3683 - val_root_mean_squared_error: 30.0228\n",
            "Epoch 5/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 804.5987 - root_mean_squared_error: 28.3654 - val_loss: 889.5726 - val_root_mean_squared_error: 29.8257\n",
            "Epoch 6/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 780.4619 - root_mean_squared_error: 27.9367 - val_loss: 912.6407 - val_root_mean_squared_error: 30.2099\n",
            "Epoch 7/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 768.0706 - root_mean_squared_error: 27.7141 - val_loss: 908.9835 - val_root_mean_squared_error: 30.1494\n",
            "Epoch 8/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 767.2005 - root_mean_squared_error: 27.6984 - val_loss: 907.3697 - val_root_mean_squared_error: 30.1226\n",
            "Epoch 9/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 761.5923 - root_mean_squared_error: 27.5970 - val_loss: 908.4868 - val_root_mean_squared_error: 30.1411\n",
            "Epoch 10/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 756.0821 - root_mean_squared_error: 27.4969 - val_loss: 906.8080 - val_root_mean_squared_error: 30.1133\n",
            "Epoch 11/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 773.7078 - root_mean_squared_error: 27.8156 - val_loss: 905.6708 - val_root_mean_squared_error: 30.0944\n",
            "Epoch 12/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 751.7630 - root_mean_squared_error: 27.4183 - val_loss: 904.9939 - val_root_mean_squared_error: 30.0831\n",
            "Epoch 13/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 755.0939 - root_mean_squared_error: 27.4790 - val_loss: 907.2223 - val_root_mean_squared_error: 30.1201\n",
            "Epoch 14/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 749.7398 - root_mean_squared_error: 27.3814 - val_loss: 907.7744 - val_root_mean_squared_error: 30.1293\n",
            "Epoch 15/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 749.6575 - root_mean_squared_error: 27.3799 - val_loss: 905.4824 - val_root_mean_squared_error: 30.0912\n",
            "Epoch 16/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 752.0965 - root_mean_squared_error: 27.4244 - val_loss: 908.5924 - val_root_mean_squared_error: 30.1429\n",
            "Epoch 17/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 755.0450 - root_mean_squared_error: 27.4781 - val_loss: 905.5934 - val_root_mean_squared_error: 30.0931\n",
            "Epoch 18/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 763.5939 - root_mean_squared_error: 27.6332 - val_loss: 908.6516 - val_root_mean_squared_error: 30.1438\n",
            "Epoch 19/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 762.6121 - root_mean_squared_error: 27.6154 - val_loss: 904.9224 - val_root_mean_squared_error: 30.0819\n",
            "Epoch 20/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 770.6135 - root_mean_squared_error: 27.7599 - val_loss: 902.1209 - val_root_mean_squared_error: 30.0353\n",
            "Epoch 21/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 760.1244 - root_mean_squared_error: 27.5704 - val_loss: 907.9930 - val_root_mean_squared_error: 30.1329\n",
            "Epoch 22/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 764.5065 - root_mean_squared_error: 27.6497 - val_loss: 902.5021 - val_root_mean_squared_error: 30.0417\n",
            "Epoch 23/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 762.5540 - root_mean_squared_error: 27.6144 - val_loss: 902.8674 - val_root_mean_squared_error: 30.0478\n",
            "Epoch 24/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 742.7596 - root_mean_squared_error: 27.2536 - val_loss: 904.5805 - val_root_mean_squared_error: 30.0762\n",
            "Epoch 25/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 752.5839 - root_mean_squared_error: 27.4333 - val_loss: 909.0900 - val_root_mean_squared_error: 30.1511\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "29.82570380167719\n",
            "Epoch 1/500\n",
            "241/241 [==============================] - 4s 7ms/step - loss: 1238.4647 - root_mean_squared_error: 35.1918 - val_loss: 4049.9233 - val_root_mean_squared_error: 63.6390\n",
            "Epoch 2/500\n",
            "  9/241 [>.............................] - ETA: 1s - loss: 1368.9828 - root_mean_squared_error: 36.9998"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "241/241 [==============================] - 2s 7ms/step - loss: 989.0692 - root_mean_squared_error: 31.4495 - val_loss: 1010.7341 - val_root_mean_squared_error: 31.7920\n",
            "Epoch 3/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 914.3407 - root_mean_squared_error: 30.2381 - val_loss: 878.5744 - val_root_mean_squared_error: 29.6408\n",
            "Epoch 4/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 854.0456 - root_mean_squared_error: 29.2241 - val_loss: 883.9242 - val_root_mean_squared_error: 29.7309\n",
            "Epoch 5/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 835.1078 - root_mean_squared_error: 28.8982 - val_loss: 868.4899 - val_root_mean_squared_error: 29.4702\n",
            "Epoch 6/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 807.5456 - root_mean_squared_error: 28.4173 - val_loss: 869.7168 - val_root_mean_squared_error: 29.4910\n",
            "Epoch 7/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 809.0849 - root_mean_squared_error: 28.4444 - val_loss: 871.3236 - val_root_mean_squared_error: 29.5182\n",
            "Epoch 8/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 799.0729 - root_mean_squared_error: 28.2679 - val_loss: 862.8339 - val_root_mean_squared_error: 29.3740\n",
            "Epoch 9/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 792.1470 - root_mean_squared_error: 28.1451 - val_loss: 865.5203 - val_root_mean_squared_error: 29.4197\n",
            "Epoch 10/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 788.4867 - root_mean_squared_error: 28.0800 - val_loss: 862.1743 - val_root_mean_squared_error: 29.3628\n",
            "Epoch 11/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 787.1151 - root_mean_squared_error: 28.0556 - val_loss: 861.9509 - val_root_mean_squared_error: 29.3590\n",
            "Epoch 12/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 776.0257 - root_mean_squared_error: 27.8572 - val_loss: 862.6530 - val_root_mean_squared_error: 29.3710\n",
            "Epoch 13/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 782.7538 - root_mean_squared_error: 27.9777 - val_loss: 860.1140 - val_root_mean_squared_error: 29.3277\n",
            "Epoch 14/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 778.3748 - root_mean_squared_error: 27.8994 - val_loss: 861.1580 - val_root_mean_squared_error: 29.3455\n",
            "Epoch 15/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 778.2053 - root_mean_squared_error: 27.8963 - val_loss: 863.4489 - val_root_mean_squared_error: 29.3845\n",
            "Epoch 16/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 778.8067 - root_mean_squared_error: 27.9071 - val_loss: 862.5122 - val_root_mean_squared_error: 29.3686\n",
            "Epoch 17/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 776.8575 - root_mean_squared_error: 27.8722 - val_loss: 861.7984 - val_root_mean_squared_error: 29.3564\n",
            "Epoch 18/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 776.7826 - root_mean_squared_error: 27.8708 - val_loss: 865.6044 - val_root_mean_squared_error: 29.4212\n",
            "Epoch 19/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 779.4140 - root_mean_squared_error: 27.9180 - val_loss: 862.0621 - val_root_mean_squared_error: 29.3609\n",
            "Epoch 20/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 784.0791 - root_mean_squared_error: 28.0014 - val_loss: 863.8655 - val_root_mean_squared_error: 29.3916\n",
            "Epoch 21/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 792.6055 - root_mean_squared_error: 28.1532 - val_loss: 862.2764 - val_root_mean_squared_error: 29.3645\n",
            "Epoch 22/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 782.1913 - root_mean_squared_error: 27.9677 - val_loss: 866.4274 - val_root_mean_squared_error: 29.4351\n",
            "Epoch 23/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 788.5809 - root_mean_squared_error: 28.0817 - val_loss: 863.6045 - val_root_mean_squared_error: 29.3871\n",
            "Epoch 24/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 773.0530 - root_mean_squared_error: 27.8038 - val_loss: 862.9881 - val_root_mean_squared_error: 29.3767\n",
            "Epoch 25/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 781.8685 - root_mean_squared_error: 27.9619 - val_loss: 861.6813 - val_root_mean_squared_error: 29.3544\n",
            "Epoch 26/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 775.2332 - root_mean_squared_error: 27.8430 - val_loss: 859.8324 - val_root_mean_squared_error: 29.3229\n",
            "Epoch 27/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 778.6281 - root_mean_squared_error: 27.9039 - val_loss: 862.2890 - val_root_mean_squared_error: 29.3648\n",
            "Epoch 28/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 793.5175 - root_mean_squared_error: 28.1694 - val_loss: 864.1392 - val_root_mean_squared_error: 29.3962\n",
            "Epoch 29/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 780.3478 - root_mean_squared_error: 27.9347 - val_loss: 861.6050 - val_root_mean_squared_error: 29.3531\n",
            "Epoch 30/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 785.5643 - root_mean_squared_error: 28.0279 - val_loss: 864.1705 - val_root_mean_squared_error: 29.3968\n",
            "Epoch 31/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 772.8907 - root_mean_squared_error: 27.8009 - val_loss: 859.7905 - val_root_mean_squared_error: 29.3222\n",
            "Epoch 32/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 776.5911 - root_mean_squared_error: 27.8674 - val_loss: 863.2511 - val_root_mean_squared_error: 29.3811\n",
            "Epoch 33/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 793.2000 - root_mean_squared_error: 28.1638 - val_loss: 860.8860 - val_root_mean_squared_error: 29.3409\n",
            "Epoch 34/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 784.8788 - root_mean_squared_error: 28.0157 - val_loss: 861.8939 - val_root_mean_squared_error: 29.3580\n",
            "Epoch 35/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 785.2645 - root_mean_squared_error: 28.0226 - val_loss: 865.6968 - val_root_mean_squared_error: 29.4227\n",
            "Epoch 36/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 779.1856 - root_mean_squared_error: 27.9139 - val_loss: 864.7187 - val_root_mean_squared_error: 29.4061\n",
            "Epoch 37/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 781.2029 - root_mean_squared_error: 27.9500 - val_loss: 863.7258 - val_root_mean_squared_error: 29.3892\n",
            "Epoch 38/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 786.4504 - root_mean_squared_error: 28.0437 - val_loss: 862.1429 - val_root_mean_squared_error: 29.3623\n",
            "Epoch 39/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 781.2863 - root_mean_squared_error: 27.9515 - val_loss: 863.5504 - val_root_mean_squared_error: 29.3862\n",
            "Epoch 40/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 775.1807 - root_mean_squared_error: 27.8421 - val_loss: 864.5442 - val_root_mean_squared_error: 29.4031\n",
            "Epoch 41/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 793.5357 - root_mean_squared_error: 28.1698 - val_loss: 863.3612 - val_root_mean_squared_error: 29.3830\n",
            "Epoch 42/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 792.3663 - root_mean_squared_error: 28.1490 - val_loss: 862.3423 - val_root_mean_squared_error: 29.3657\n",
            "Epoch 43/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 779.5609 - root_mean_squared_error: 27.9206 - val_loss: 861.5335 - val_root_mean_squared_error: 29.3519\n",
            "Epoch 44/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 801.7553 - root_mean_squared_error: 28.3153 - val_loss: 860.7332 - val_root_mean_squared_error: 29.3383\n",
            "Epoch 45/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 783.2324 - root_mean_squared_error: 27.9863 - val_loss: 863.6943 - val_root_mean_squared_error: 29.3887\n",
            "Epoch 46/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 778.0448 - root_mean_squared_error: 27.8935 - val_loss: 862.6655 - val_root_mean_squared_error: 29.3712\n",
            "Epoch 47/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 783.4976 - root_mean_squared_error: 27.9910 - val_loss: 862.7511 - val_root_mean_squared_error: 29.3726\n",
            "Epoch 48/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 785.4749 - root_mean_squared_error: 28.0263 - val_loss: 863.3090 - val_root_mean_squared_error: 29.3821\n",
            "Epoch 49/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 787.5117 - root_mean_squared_error: 28.0626 - val_loss: 862.8851 - val_root_mean_squared_error: 29.3749\n",
            "Epoch 50/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 767.9047 - root_mean_squared_error: 27.7111 - val_loss: 864.7169 - val_root_mean_squared_error: 29.4061\n",
            "Epoch 51/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 786.2086 - root_mean_squared_error: 28.0394 - val_loss: 862.6549 - val_root_mean_squared_error: 29.3710\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "29.322187039529044\n",
            "Epoch 1/500\n",
            "241/241 [==============================] - 4s 7ms/step - loss: 1233.6672 - root_mean_squared_error: 35.1236 - val_loss: 985.0549 - val_root_mean_squared_error: 31.3856\n",
            "Epoch 2/500\n",
            " 10/241 [>.............................] - ETA: 1s - loss: 997.1756 - root_mean_squared_error: 31.5781 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "241/241 [==============================] - 2s 6ms/step - loss: 932.6884 - root_mean_squared_error: 30.5399 - val_loss: 919.3033 - val_root_mean_squared_error: 30.3200\n",
            "Epoch 3/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 858.8267 - root_mean_squared_error: 29.3057 - val_loss: 981.5154 - val_root_mean_squared_error: 31.3291\n",
            "Epoch 4/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 824.6358 - root_mean_squared_error: 28.7165 - val_loss: 897.2676 - val_root_mean_squared_error: 29.9544\n",
            "Epoch 5/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 813.5470 - root_mean_squared_error: 28.5227 - val_loss: 862.2141 - val_root_mean_squared_error: 29.3635\n",
            "Epoch 6/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 773.5362 - root_mean_squared_error: 27.8125 - val_loss: 875.4138 - val_root_mean_squared_error: 29.5874\n",
            "Epoch 7/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 768.8917 - root_mean_squared_error: 27.7289 - val_loss: 881.2856 - val_root_mean_squared_error: 29.6865\n",
            "Epoch 8/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 755.3005 - root_mean_squared_error: 27.4827 - val_loss: 885.6158 - val_root_mean_squared_error: 29.7593\n",
            "Epoch 9/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 751.5715 - root_mean_squared_error: 27.4148 - val_loss: 883.5785 - val_root_mean_squared_error: 29.7250\n",
            "Epoch 10/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 757.7897 - root_mean_squared_error: 27.5280 - val_loss: 884.6615 - val_root_mean_squared_error: 29.7433\n",
            "Epoch 11/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 755.0783 - root_mean_squared_error: 27.4787 - val_loss: 884.4674 - val_root_mean_squared_error: 29.7400\n",
            "Epoch 12/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 751.6644 - root_mean_squared_error: 27.4165 - val_loss: 884.1564 - val_root_mean_squared_error: 29.7348\n",
            "Epoch 13/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 748.0432 - root_mean_squared_error: 27.3504 - val_loss: 884.8936 - val_root_mean_squared_error: 29.7472\n",
            "Epoch 14/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 750.9846 - root_mean_squared_error: 27.4041 - val_loss: 887.0203 - val_root_mean_squared_error: 29.7829\n",
            "Epoch 15/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 755.5373 - root_mean_squared_error: 27.4870 - val_loss: 886.1990 - val_root_mean_squared_error: 29.7691\n",
            "Epoch 16/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 739.3360 - root_mean_squared_error: 27.1907 - val_loss: 888.7170 - val_root_mean_squared_error: 29.8114\n",
            "Epoch 17/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 753.1562 - root_mean_squared_error: 27.4437 - val_loss: 886.8044 - val_root_mean_squared_error: 29.7793\n",
            "Epoch 18/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 732.1649 - root_mean_squared_error: 27.0585 - val_loss: 883.8255 - val_root_mean_squared_error: 29.7292\n",
            "Epoch 19/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 748.8494 - root_mean_squared_error: 27.3651 - val_loss: 886.5685 - val_root_mean_squared_error: 29.7753\n",
            "Epoch 20/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 738.9615 - root_mean_squared_error: 27.1838 - val_loss: 885.8707 - val_root_mean_squared_error: 29.7636\n",
            "Epoch 21/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 746.2803 - root_mean_squared_error: 27.3181 - val_loss: 885.8481 - val_root_mean_squared_error: 29.7632\n",
            "Epoch 22/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 749.2145 - root_mean_squared_error: 27.3718 - val_loss: 890.3813 - val_root_mean_squared_error: 29.8393\n",
            "Epoch 23/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 732.1435 - root_mean_squared_error: 27.0581 - val_loss: 888.1404 - val_root_mean_squared_error: 29.8017\n",
            "Epoch 24/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 747.6285 - root_mean_squared_error: 27.3428 - val_loss: 886.7941 - val_root_mean_squared_error: 29.7791\n",
            "Epoch 25/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 747.2771 - root_mean_squared_error: 27.3364 - val_loss: 886.5452 - val_root_mean_squared_error: 29.7749\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "29.363482597924378\n",
            "Epoch 1/500\n",
            "241/241 [==============================] - 4s 8ms/step - loss: 1235.1254 - root_mean_squared_error: 35.1443 - val_loss: 1024.1371 - val_root_mean_squared_error: 32.0021\n",
            "Epoch 2/500\n",
            " 10/241 [>.............................] - ETA: 1s - loss: 1078.7053 - root_mean_squared_error: 32.8436"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "241/241 [==============================] - 1s 6ms/step - loss: 936.8481 - root_mean_squared_error: 30.6080 - val_loss: 104165.6641 - val_root_mean_squared_error: 322.7471\n",
            "Epoch 3/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 943.4705 - root_mean_squared_error: 30.7160 - val_loss: 1071.3113 - val_root_mean_squared_error: 32.7309\n",
            "Epoch 4/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 851.7455 - root_mean_squared_error: 29.1847 - val_loss: 931.8867 - val_root_mean_squared_error: 30.5268\n",
            "Epoch 5/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 830.3231 - root_mean_squared_error: 28.8153 - val_loss: 957.3655 - val_root_mean_squared_error: 30.9413\n",
            "Epoch 6/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 806.7167 - root_mean_squared_error: 28.4028 - val_loss: 952.4528 - val_root_mean_squared_error: 30.8618\n",
            "Epoch 7/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 776.2912 - root_mean_squared_error: 27.8620 - val_loss: 967.0523 - val_root_mean_squared_error: 31.0975\n",
            "Epoch 8/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 769.1561 - root_mean_squared_error: 27.7337 - val_loss: 973.8781 - val_root_mean_squared_error: 31.2070\n",
            "Epoch 9/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 766.2328 - root_mean_squared_error: 27.6809 - val_loss: 991.8203 - val_root_mean_squared_error: 31.4932\n",
            "Epoch 10/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 763.6409 - root_mean_squared_error: 27.6341 - val_loss: 970.6115 - val_root_mean_squared_error: 31.1546\n",
            "Epoch 11/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 739.4749 - root_mean_squared_error: 27.1933 - val_loss: 976.9928 - val_root_mean_squared_error: 31.2569\n",
            "Epoch 12/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 763.6567 - root_mean_squared_error: 27.6343 - val_loss: 976.5031 - val_root_mean_squared_error: 31.2491\n",
            "Epoch 13/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 742.8636 - root_mean_squared_error: 27.2555 - val_loss: 977.7679 - val_root_mean_squared_error: 31.2693\n",
            "Epoch 14/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 755.1801 - root_mean_squared_error: 27.4805 - val_loss: 974.0873 - val_root_mean_squared_error: 31.2104\n",
            "Epoch 15/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 763.8159 - root_mean_squared_error: 27.6372 - val_loss: 982.1704 - val_root_mean_squared_error: 31.3396\n",
            "Epoch 16/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 753.6671 - root_mean_squared_error: 27.4530 - val_loss: 987.0336 - val_root_mean_squared_error: 31.4171\n",
            "Epoch 17/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 768.7717 - root_mean_squared_error: 27.7267 - val_loss: 978.7089 - val_root_mean_squared_error: 31.2843\n",
            "Epoch 18/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 758.3807 - root_mean_squared_error: 27.5387 - val_loss: 989.4561 - val_root_mean_squared_error: 31.4556\n",
            "Epoch 19/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 741.4460 - root_mean_squared_error: 27.2295 - val_loss: 982.7162 - val_root_mean_squared_error: 31.3483\n",
            "Epoch 20/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 758.9366 - root_mean_squared_error: 27.5488 - val_loss: 979.2092 - val_root_mean_squared_error: 31.2923\n",
            "Epoch 21/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 752.2852 - root_mean_squared_error: 27.4278 - val_loss: 982.3770 - val_root_mean_squared_error: 31.3429\n",
            "Epoch 22/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 757.3674 - root_mean_squared_error: 27.5203 - val_loss: 979.0718 - val_root_mean_squared_error: 31.2901\n",
            "Epoch 23/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 759.6256 - root_mean_squared_error: 27.5613 - val_loss: 979.8975 - val_root_mean_squared_error: 31.3033\n",
            "Epoch 24/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 761.6954 - root_mean_squared_error: 27.5988 - val_loss: 992.2515 - val_root_mean_squared_error: 31.5000\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "30.5268228854271\n",
            "Epoch 1/500\n",
            "241/241 [==============================] - 4s 8ms/step - loss: 1261.5385 - root_mean_squared_error: 35.5181 - val_loss: 1033.1821 - val_root_mean_squared_error: 32.1432\n",
            "Epoch 2/500\n",
            "  7/241 [..............................] - ETA: 1s - loss: 948.2027 - root_mean_squared_error: 30.7929 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "241/241 [==============================] - 2s 6ms/step - loss: 945.8702 - root_mean_squared_error: 30.7550 - val_loss: 2056.6865 - val_root_mean_squared_error: 45.3507\n",
            "Epoch 3/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 880.2855 - root_mean_squared_error: 29.6696 - val_loss: 878.8383 - val_root_mean_squared_error: 29.6452\n",
            "Epoch 4/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 832.4879 - root_mean_squared_error: 28.8529 - val_loss: 876.9957 - val_root_mean_squared_error: 29.6141\n",
            "Epoch 5/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 819.2654 - root_mean_squared_error: 28.6228 - val_loss: 857.5165 - val_root_mean_squared_error: 29.2834\n",
            "Epoch 6/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 775.0018 - root_mean_squared_error: 27.8389 - val_loss: 890.6502 - val_root_mean_squared_error: 29.8438\n",
            "Epoch 7/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 764.6990 - root_mean_squared_error: 27.6532 - val_loss: 874.8770 - val_root_mean_squared_error: 29.5783\n",
            "Epoch 8/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 748.2744 - root_mean_squared_error: 27.3546 - val_loss: 884.4458 - val_root_mean_squared_error: 29.7396\n",
            "Epoch 9/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 767.3524 - root_mean_squared_error: 27.7011 - val_loss: 881.8198 - val_root_mean_squared_error: 29.6954\n",
            "Epoch 10/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 756.3730 - root_mean_squared_error: 27.5022 - val_loss: 881.6888 - val_root_mean_squared_error: 29.6932\n",
            "Epoch 11/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 757.7805 - root_mean_squared_error: 27.5278 - val_loss: 890.8679 - val_root_mean_squared_error: 29.8474\n",
            "Epoch 12/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 755.8607 - root_mean_squared_error: 27.4929 - val_loss: 897.1818 - val_root_mean_squared_error: 29.9530\n",
            "Epoch 13/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 757.7600 - root_mean_squared_error: 27.5274 - val_loss: 887.1049 - val_root_mean_squared_error: 29.7843\n",
            "Epoch 14/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 764.0366 - root_mean_squared_error: 27.6412 - val_loss: 891.0193 - val_root_mean_squared_error: 29.8499\n",
            "Epoch 15/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 752.3418 - root_mean_squared_error: 27.4288 - val_loss: 890.2446 - val_root_mean_squared_error: 29.8370\n",
            "Epoch 16/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 755.1396 - root_mean_squared_error: 27.4798 - val_loss: 885.5008 - val_root_mean_squared_error: 29.7574\n",
            "Epoch 17/500\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 746.7202 - root_mean_squared_error: 27.3262 - val_loss: 881.7447 - val_root_mean_squared_error: 29.6942\n",
            "Epoch 18/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 750.1885 - root_mean_squared_error: 27.3896 - val_loss: 878.6033 - val_root_mean_squared_error: 29.6412\n",
            "Epoch 19/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 743.8215 - root_mean_squared_error: 27.2731 - val_loss: 882.0229 - val_root_mean_squared_error: 29.6989\n",
            "Epoch 20/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 760.3589 - root_mean_squared_error: 27.5746 - val_loss: 882.7905 - val_root_mean_squared_error: 29.7118\n",
            "Epoch 21/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 760.1188 - root_mean_squared_error: 27.5703 - val_loss: 884.8808 - val_root_mean_squared_error: 29.7469\n",
            "Epoch 22/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 761.8652 - root_mean_squared_error: 27.6019 - val_loss: 894.2996 - val_root_mean_squared_error: 29.9048\n",
            "Epoch 23/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 754.5518 - root_mean_squared_error: 27.4691 - val_loss: 891.2709 - val_root_mean_squared_error: 29.8542\n",
            "Epoch 24/500\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 760.8241 - root_mean_squared_error: 27.5830 - val_loss: 894.0216 - val_root_mean_squared_error: 29.9002\n",
            "Epoch 25/500\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 741.8101 - root_mean_squared_error: 27.2362 - val_loss: 887.2444 - val_root_mean_squared_error: 29.7866\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "29.28338426540503\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# Load MLM models\n",
        "mlm_models = [load_model(f'model_mlm_fold{i}.h5') for i in range(n_splits)]\n",
        "\n",
        "# Load HLM models\n",
        "hlm_models = [load_model(f'model_hlm_fold{i}.h5') for i in range(n_splits)]\n",
        "\n",
        "x_test = test[features].values\n",
        "\n",
        "mlm_predictions = []\n",
        "hlm_predictions = []\n",
        "\n",
        "for model_mlm, model_hlm in zip(mlm_models, hlm_models):\n",
        "    mlm_predictions.append(model_mlm.predict(x_test))\n",
        "    hlm_predictions.append(model_hlm.predict(x_test))\n",
        "\n",
        "# Convert prediction lists to numpy arrays\n",
        "mlm_predictions = np.array(mlm_predictions)\n",
        "hlm_predictions = np.array(hlm_predictions)\n",
        "\n",
        "mlm_ensemble_prediction = mlm_predictions.mean(axis=0)\n",
        "hlm_ensemble_prediction = hlm_predictions.mean(axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXjw42C4OJt8",
        "outputId": "94b5bc75-5a55-4624-9159-c78780086cbe"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_submission = pd.read_csv(\"/content/drive/MyDrive/metabolism_dacon/sample_submission.csv\")\n",
        "df_submission[\"MLM\"] = mlm_ensemble_prediction\n",
        "df_submission[\"HLM\"] = hlm_ensemble_prediction\n",
        "df_submission.to_csv(\"submission.csv\", index = False, encoding = \"utf-8-sig\")"
      ],
      "metadata": {
        "id": "lyLjdtWEOLqZ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_submission"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "xePr_yceOMVS",
        "outputId": "f0831f2d-48d4-4d91-b14b-79619ec23ec2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           id        MLM        HLM\n",
              "0    TEST_000  22.072287  49.431904\n",
              "1    TEST_001  67.795456  80.603355\n",
              "2    TEST_002  48.650043  63.674030\n",
              "3    TEST_003  49.560764  69.864143\n",
              "4    TEST_004  60.214588  75.319855\n",
              "..        ...        ...        ...\n",
              "478  TEST_478   6.380654  25.069542\n",
              "479  TEST_479  72.472137  86.032578\n",
              "480  TEST_480  38.472294  64.516289\n",
              "481  TEST_481  44.892677  71.460587\n",
              "482  TEST_482  25.280733  67.854874\n",
              "\n",
              "[483 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-629be6aa-febc-48f5-a3b4-afaae3ba3637\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>MLM</th>\n",
              "      <th>HLM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TEST_000</td>\n",
              "      <td>22.072287</td>\n",
              "      <td>49.431904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TEST_001</td>\n",
              "      <td>67.795456</td>\n",
              "      <td>80.603355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TEST_002</td>\n",
              "      <td>48.650043</td>\n",
              "      <td>63.674030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TEST_003</td>\n",
              "      <td>49.560764</td>\n",
              "      <td>69.864143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TEST_004</td>\n",
              "      <td>60.214588</td>\n",
              "      <td>75.319855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>478</th>\n",
              "      <td>TEST_478</td>\n",
              "      <td>6.380654</td>\n",
              "      <td>25.069542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>479</th>\n",
              "      <td>TEST_479</td>\n",
              "      <td>72.472137</td>\n",
              "      <td>86.032578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>480</th>\n",
              "      <td>TEST_480</td>\n",
              "      <td>38.472294</td>\n",
              "      <td>64.516289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>481</th>\n",
              "      <td>TEST_481</td>\n",
              "      <td>44.892677</td>\n",
              "      <td>71.460587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>482</th>\n",
              "      <td>TEST_482</td>\n",
              "      <td>25.280733</td>\n",
              "      <td>67.854874</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>483 rows √ó 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-629be6aa-febc-48f5-a3b4-afaae3ba3637')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-629be6aa-febc-48f5-a3b4-afaae3ba3637 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-629be6aa-febc-48f5-a3b4-afaae3ba3637');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f6252e75-c4df-49d7-9a2f-6df826bdaef9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f6252e75-c4df-49d7-9a2f-6df826bdaef9')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f6252e75-c4df-49d7-9a2f-6df826bdaef9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}